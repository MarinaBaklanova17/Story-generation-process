{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWH7sQT3L_p-",
        "outputId": "a0f8ab14-acd5-448c-f11b-2617b0795dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unifyai\n",
            "  Downloading unifyai-0.8.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting openai<2.0.0,>=1.12.0 (from unifyai)\n",
            "  Downloading openai-1.39.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from unifyai) (2.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.12.0->unifyai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai) (2024.7.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.12.0->unifyai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.12.0->unifyai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.12.0->unifyai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.12.0->unifyai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.12.0->unifyai) (2.20.1)\n",
            "Downloading unifyai-0.8.6-py3-none-any.whl (15 kB)\n",
            "Downloading openai-1.39.0-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.7/336.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai, unifyai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.39.0 unifyai-0.8.6\n"
          ]
        }
      ],
      "source": [
        "!pip install unifyai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-2LTYd6MqSV",
        "outputId": "ab07434a-8107-43ee-82f6-be6e78d5ddb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPOwea2rMuhH",
        "outputId": "6440a246-c013-45b5-8eb7-3b9cb52a983d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pyphen (from textstat)\n",
            "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (71.0.4)\n",
            "Downloading textstat-0.7.4-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.16.0 textstat-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from unify import Unify\n",
        "import pandas as pd\n",
        "import textstat\n",
        "\n",
        "os.environ[\"UNIFY_KEY\"] = \"zgZRC0qqOC89cjdiDq403mtdgp-n8ULnQjK6JMiS2YE=\"\n",
        "\n",
        "def generate_response(model_name, prompt, temperature=0.7):\n",
        "    unify = Unify(model_name)\n",
        "    response = unify.generate(\n",
        "        prompt,\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return response\n",
        "\n",
        "models = [\n",
        "    \"claude-3-haiku@anthropic\",\n",
        "    \"claude-3-opus@anthropic\",\n",
        "    \"claude-3.5-sonnet@anthropic\",\n",
        "    \"gemini-1.5-flash@vertex-ai\",\n",
        "    \"gemini-1.5-pro@vertex-ai\",\n",
        "    \"gemma-2-9b-it@fireworks-ai\",\n",
        "    \"gemma-2b-it@together-ai\",\n",
        "    \"gpt-3.5-turbo@openai\",\n",
        "    \"gpt-4@openai\",\n",
        "    \"gpt-4-turbo@openai\",\n",
        "    \"gpt-4o@openai\",\n",
        "    \"llama-3-70b-chat@fireworks-ai\",\n",
        "    \"llama-3-8b-chat@fireworks-ai\",\n",
        "    \"mistral-7b-instruct-v0.3@together-ai\",\n",
        "    \"mistral-large@aws-bedrock\",\n",
        "    \"mistral-small@mistral-ai\",\n",
        "    \"mixtral-8x22b-instruct-v0.1@deepinfra\",\n",
        "    \"mixtral-8x7b-instruct-v0.1@aws-bedrock\",\n",
        "    \"qwen-2-72b-instruct@deepinfra\"\n",
        "]\n",
        "\n",
        "prompt = \"You are a fairy tale author. Write a fairy tale about THE OLD WOMAN AND HER PIG\"\n",
        "\n",
        "\n",
        "original_text = \"\"\"\n",
        "An old woman was sweeping her house, and she found a little crooked sixpence. “What,” said she, “shall I do with this little sixpence? I will go to market, and buy a little pig.”\n",
        "\n",
        "As she was coming home, she came to a stile: but the piggy wouldn't go over the stile.\n",
        "\n",
        "She went a little further, and she met a dog. So she said to the dog: “Dog! bite pig; piggy won't go over the stile; and I shan't get home to-night.” But the dog wouldn't.\n",
        "\n",
        "She went a little further, and she met a stick. So she said: “Stick! stick! beat dog! dog won't bite pig; piggy won't get over the stile; and I shan't get home to-night.” But the stick wouldn't.\n",
        "\n",
        "She went a little further, and she met a fire. So she said: “Fire! fire! burn stick; stick won't beat dog; dog won't bite pig; piggy won't get over the stile; and I shan't get home to-night.” But the fire wouldn't.\n",
        "\n",
        "She went a little further, and she met some water. So she said: “Water, water! quench fire; fire won't burn stick; stick won't beat dog; dog won't bite pig; piggy won't get over the stile; and I shan't get home to-night.” But the water wouldn't.\n",
        "\n",
        "She went a little further, and she met an ox. So she said: “Ox! ox! drink water; water won't quench fire; fire won't burn stick; stick won't beat dog; dog won't bite pig; piggy won't get over the stile; and I shan't get home to-night.” But the ox wouldn't.\n",
        "\n",
        "She went a little further, and she met a butcher. So she said: “Butcher! butcher! kill ox; ox won't drink water; water won't quench fire; fire won't burn stick; stick won't beat dog; dog won't bite pig; piggy won't get over the stile; and I shan't get home to-night.” But the butcher wouldn't.\n",
        "\n",
        "She went a little further, and she met a rope. So she said: “Rope! rope! hang butcher; butcher won't kill ox; ox won't drink water; water won't quench fire; fire won't burn stick; stick won't beat dog; dog won't bite pig; piggy won't get over the stile; and I shan't get home to-night.” But the rope wouldn't.\n",
        "\n",
        "She went a little further, and she met a rat. So she said: “Rat! rat! gnaw rope; rope won't hang butcher; butcher won't kill ox; ox won't drink water; water won't quench fire; fire won't burn stick; stick won't beat dog; dog won't bite pig; piggy won't get over the stile; and I shan't get home to-night.” But the rat wouldn't.\n",
        "\n",
        "She went a little further, and she met a cat. So she said: “Cat! cat! kill rat; rat won't gnaw rope; rope won't hang butcher; butcher won't kill ox; ox won't drink water; water won't quench fire; fire won't burn stick; stick won't beat dog; dog won't bite pig; piggy won't get over the stile; and I shan't get home to-night.” But the cat said to her, “If you will go to yonder cow, and fetch me a saucer of milk, I will kill the rat.” So away went the old woman to the cow.\n",
        "\n",
        "But the cow said to her: “If you will go to yonder hay-stack, and fetch me a handful of hay, I'll give you the milk.” So away went the old woman to the haystack and she brought the hay to the cow.\n",
        "\n",
        "As soon as the cow had eaten the hay, she gave the old woman the milk; and away she went with it in a saucer to the cat.\n",
        "\n",
        "As soon as the cat had lapped up the milk, the cat began to kill the rat; the rat began to gnaw the rope; the rope began to hang the butcher; the butcher began to kill the ox; the ox began to drink the water; the water began to quench the fire; the fire began to burn the stick; the stick began to beat the dog; the dog began to bite the pig; the little pig in a fright jumped over the stile, and so the old woman got home that night.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"model\", \"metric\", \"value\"\n",
        "])\n",
        "\n",
        "def calculate_metrics(text, model_name):\n",
        "    metrics = {\n",
        "        \"Syllable Count\": textstat.syllable_count(text),\n",
        "        \"Lexicon Count\": textstat.lexicon_count(text, removepunct=True),\n",
        "        \"Sentence Count\": textstat.sentence_count(text),\n",
        "        \"Flesch Reading Ease\": textstat.flesch_reading_ease(text),\n",
        "        \"Flesch-Kincaid Grade Level\": textstat.flesch_kincaid_grade(text),\n",
        "        \"Gunning Fog\": textstat.gunning_fog(text),\n",
        "        \"SMOG Index\": textstat.smog_index(text),\n",
        "        \"Automated Readability Index\": textstat.automated_readability_index(text),\n",
        "        \"Coleman-Liau Index\": textstat.coleman_liau_index(text),\n",
        "        \"Linsear Write Formula\": textstat.linsear_write_formula(text),\n",
        "        \"Dale-Chall Readability Score\": textstat.dale_chall_readability_score(text),\n",
        "        \"Text Standard\": textstat.text_standard(text, float_output=False),\n",
        "        \"Reading Time (seconds)\": textstat.reading_time(text)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "original_metrics = calculate_metrics(original_text, \"original_text\")\n",
        "for metric, value in original_metrics.items():\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([{\n",
        "        \"model\": \"original_text\",\n",
        "        \"metric\": metric,\n",
        "        \"value\": value\n",
        "    }])], ignore_index=True)\n",
        "\n",
        "for model in models:\n",
        "    print(f\"\\nResponse from {model}:\")\n",
        "    try:\n",
        "        response = generate_response(model, prompt)\n",
        "        print(response)\n",
        "\n",
        "        model_metrics = calculate_metrics(response, model)\n",
        "        for metric, value in model_metrics.items():\n",
        "            results_df = pd.concat([results_df, pd.DataFrame([{\n",
        "                \"model\": model,\n",
        "                \"metric\": metric,\n",
        "                \"value\": value\n",
        "            }])], ignore_index=True)\n",
        "\n",
        "        print(\"\\nReadability Metrics:\")\n",
        "        for metric, value in model_metrics.items():\n",
        "            print(f\"{metric}: {value}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response from {model}: {e}\")\n",
        "\n",
        "results_df.to_csv(\"THE OLD WOMAN AND HER PIG_readability_score.csv\", index=False)\n",
        "results_df.to_excel(\"THE OLD WOMAN AND HER PIG_readability_score.xlsx\", index=False)\n",
        "\n",
        "\n",
        "print(\"Responses and readability metrics saved to THE OLD WOMAN AND HER PIG_readability_score.csv, THE OLD WOMAN AND HER PIG_readability_score.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew2Ry8mEOiXs",
        "outputId": "a8252812-743c-42d6-ede1-44a6039620c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Response from claude-3-haiku@anthropic:\n",
            "Here is a fairy tale about the old woman and her pig:\n",
            "\n",
            "The Old Woman and Her Pig\n",
            "\n",
            "Once upon a time, there lived an old woman who lived alone in a small cottage in the forest. The old woman had very little, but she was content with the simple life she led. The only companion she had was a small, scruffy pig that she had found wandering in the woods one day.\n",
            "\n",
            "The old woman had grown quite fond of the pig, and she took good care of it, feeding it scraps from her own meager meals. In return, the pig kept the old woman company and provided her with a little bit of entertainment as it scampered around the cottage.\n",
            "\n",
            "One day, as the old woman was sweeping the front steps of her cottage, the pig suddenly took off running into the forest. \"Come back, you silly pig!\" the old woman called after it, but the pig just kept running.\n",
            "\n",
            "The old woman knew she had to go after the pig, so she set off into the woods, following the trail of the pig's hoofprints. She searched high and low, but the pig was nowhere to be found. Just as the old woman was about to give up, she heard a familiar oink in the distance.\n",
            "\n",
            "Following the sound, the old woman came across a small stream, and there was her pig, happily splashing in the water. But as the old woman approached the stream, she realized that she could not cross it. \"How will I get my pig back?\" she fretted.\n",
            "\n",
            "Just then, a kind-looking frog hopped up to the edge of the stream. \"Good day, old woman,\" the frog said. \"I see you are in need of assistance. I can help you cross the stream, but in return, I ask that you do me a favor.\"\n",
            "\n",
            "The old woman agreed, and the frog instructed her to climb onto his back. Carefully, the old woman stepped into the stream and the frog carried her across to the other side. Once she was safely on the other bank, the old woman retrieved her pig and began to head back home.\n",
            "\n",
            "But the frog stopped her. \"Remember, old woman, you owe me a favor,\" he said. The old woman nodded and promised to repay the frog's kindness.\n",
            "\n",
            "From that day on, the old woman and her pig lived happily together in the cottage, and whenever the old woman needed help, she would think of the kind frog and the favor she owed him.\n",
            "\n",
            "The end.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 531\n",
            "Lexicon Count: 426\n",
            "Sentence Count: 25\n",
            "Flesch Reading Ease: 88.06\n",
            "Flesch-Kincaid Grade Level: 5.2\n",
            "Gunning Fog: 7.74\n",
            "SMOG Index: 8.1\n",
            "Automated Readability Index: 6.5\n",
            "Coleman-Liau Index: 5.28\n",
            "Linsear Write Formula: 13.0\n",
            "Dale-Chall Readability Score: 6.11\n",
            "Text Standard: 5th and 6th grade\n",
            "Reading Time (seconds): 25.75\n",
            "\n",
            "Response from claude-3-opus@anthropic:\n",
            "Once upon a time, in a quaint little village, there lived an old woman who cherished her pet pig above all else. The pig was a loyal and affectionate companion, always by her side as she went about her daily chores.\n",
            "\n",
            "One day, as the old woman was sweeping her cottage, she noticed that her pig had wandered off into the nearby forest. Worried for her beloved friend, she set out to find him. As she ventured deeper into the woods, she encountered a series of obstacles.\n",
            "\n",
            "First, she came across a dense thicket of thorns blocking her path. \"Oh, please, thorns,\" she pleaded, \"let me pass so I can find my dear pig.\" The thorns, moved by her sincere request, parted, allowing her to continue her search.\n",
            "\n",
            "Next, she reached a wide, rushing river. \"Oh, please, river,\" she called out, \"let me cross so I can find my precious pig.\" The river, seeing the love in her eyes, calmed its waters and provided her with stepping stones to reach the other side.\n",
            "\n",
            "As she pressed on, the old woman met a giant oak tree. \"Oh, please, oak tree,\" she implored, \"guide me to my pig.\" The oak tree, touched by her devotion, bent its branches, pointing her in the right direction.\n",
            "\n",
            "Finally, the old woman found her pig in a sunlit clearing, happily munching on acorns. Overjoyed, she embraced her friend, and they started their journey back home. Along the way, the oak tree, river, and thorns all bid them farewell, celebrating the power of love and perseverance.\n",
            "\n",
            "From that day forward, the old woman and her pig lived happily together, their bond stronger than ever. The villagers marveled at their connection, and the tale of the old woman's unwavering love for her pig became a cherished story passed down through generations, reminding all that true friendship knows no bounds.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 415\n",
            "Lexicon Count: 311\n",
            "Sentence Count: 19\n",
            "Flesch Reading Ease: 80.21\n",
            "Flesch-Kincaid Grade Level: 6.1\n",
            "Gunning Fog: 8.36\n",
            "SMOG Index: 8.8\n",
            "Automated Readability Index: 8.7\n",
            "Coleman-Liau Index: 8.0\n",
            "Linsear Write Formula: 8.0\n",
            "Dale-Chall Readability Score: 7.75\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 21.23\n",
            "\n",
            "Response from claude-3.5-sonnet@anthropic:\n",
            "Once upon a time, in a quaint village nestled among rolling hills, there lived an old woman in a cozy cottage. She was known for her kindness and her love for animals, especially her beloved pet pig.\n",
            "\n",
            "One sunny morning, the old woman decided to take her pig to the market to sell some of the vegetables from her garden. As they walked along the winding path, the pig suddenly stopped and refused to budge.\n",
            "\n",
            "\"Come along, dear pig,\" the old woman coaxed, but the pig wouldn't move.\n",
            "\n",
            "Frustrated, the old woman sought help from a nearby stick. \"Stick, stick, beat pig! Pig won't go to market with me!\"\n",
            "\n",
            "But the stick refused, saying, \"I won't beat the pig. That's not kind!\"\n",
            "\n",
            "The old woman then asked a fire to burn the stick, but the fire declined. She asked water to quench the fire, but the water wouldn't cooperate. She even asked an ox to drink the water, but the ox shook its head.\n",
            "\n",
            "Feeling defeated, the old woman sat down on a nearby rock and began to cry. Her tears caught the attention of a tiny mouse who scurried up to her.\n",
            "\n",
            "\"Why are you crying, kind lady?\" the mouse squeaked.\n",
            "\n",
            "The old woman explained her predicament, and the mouse listened intently. Then, with a twinkle in its eye, the mouse said, \"I have an idea!\"\n",
            "\n",
            "The mouse scampered over to the pig and whispered something in its ear. To the old woman's amazement, the pig's eyes lit up, and it began to trot happily down the path.\n",
            "\n",
            "Curious, the old woman asked the mouse what it had said to her pig.\n",
            "\n",
            "The mouse replied with a smile, \"I simply reminded your pig of the delicious treats waiting at the market and the joy of spending time with you on this beautiful day.\"\n",
            "\n",
            "The old woman's heart swelled with happiness. She realized that sometimes, a gentle reminder of love and kindness can accomplish more than any force or demand.\n",
            "\n",
            "From that day on, the old woman and her pig went on many adventures together, always remembering the lesson taught by the wise little mouse – that understanding and compassion are the keys to overcoming any obstacle.\n",
            "\n",
            "And they all lived happily ever after.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 490\n",
            "Lexicon Count: 373\n",
            "Sentence Count: 27\n",
            "Flesch Reading Ease: 82.85\n",
            "Flesch-Kincaid Grade Level: 5.1\n",
            "Gunning Fog: 7.66\n",
            "SMOG Index: 8.7\n",
            "Automated Readability Index: 6.5\n",
            "Coleman-Liau Index: 6.84\n",
            "Linsear Write Formula: 8.333333333333334\n",
            "Dale-Chall Readability Score: 6.95\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 24.49\n",
            "\n",
            "Response from gemini-1.5-flash@vertex-ai:\n",
            "In a quaint cottage nestled amidst a whispering willow grove, lived an old woman with a heart as kind as the morning dew. But her days were filled with a peculiar sorrow, for her beloved pig, Percy, had grown quite ill. His once rosy snout was now pale, and his playful snorts were replaced with weary sighs.\n",
            "\n",
            "The old woman, her wrinkled face creased with worry, consulted the wise old owl who lived in the oak tree by the well. \"The pig needs a special herb,\" hooted the owl, his eyes gleaming in the moonlight. \"A herb that grows only in the Whispering Woods, guarded by the mischievous sprites.\"\n",
            "\n",
            "The old woman, her heart heavy with fear, ventured into the Whispering Woods. The trees swayed and whispered secrets in the wind, and the air hummed with the music of unseen creatures. She followed a winding path, her heart pounding in her chest, until she reached a clearing bathed in moonlight.\n",
            "\n",
            "There, in the center, stood a shimmering herb, its leaves glowing with an ethereal light. But guarding it were three mischievous sprites, their wings shimmering with emerald and gold. They giggled and pranced, their laughter echoing through the woods.\n",
            "\n",
            "\"You cannot take the herb!\" cried one sprite, his voice like tinkling bells. \"It is ours!\"\n",
            "\n",
            "\"But my pig is ill,\" pleaded the old woman, tears welling in her eyes. \"He needs this herb to live.\"\n",
            "\n",
            "The sprites, their laughter fading, looked at the old woman with newfound sympathy. \"Very well,\" said the sprite with the emerald wings. \"But you must prove your worth. You must answer three riddles.\"\n",
            "\n",
            "The old woman, her heart filled with hope, agreed. The first riddle was about the sun, the second about the moon, and the third about the stars. The old woman, her mind sharp as a needle, answered each riddle with ease.\n",
            "\n",
            "The sprites, impressed by her wisdom, allowed her to take the herb. She rushed back to her cottage, her heart filled with gratitude. She brewed a potion with the herb and fed it to Percy.\n",
            "\n",
            "As the sun rose, Percy's snorts returned, his eyes regained their sparkle, and his rosy snout glowed with health. The old woman, her heart overflowing with joy, thanked the sprites for their kindness.\n",
            "\n",
            "And so, the old woman and her pig lived happily ever after, their bond stronger than ever, thanks to the wisdom of the old owl, the kindness of the sprites, and the power of love and hope. And the Whispering Woods, filled with the laughter of the sprites, whispered tales of the old woman and her beloved pig, Percy. \n",
            "\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 543\n",
            "Lexicon Count: 436\n",
            "Sentence Count: 31\n",
            "Flesch Reading Ease: 91.0\n",
            "Flesch-Kincaid Grade Level: 4.1\n",
            "Gunning Fog: 6.37\n",
            "SMOG Index: 6.8\n",
            "Automated Readability Index: 7.5\n",
            "Coleman-Liau Index: 7.88\n",
            "Linsear Write Formula: 7.833333333333334\n",
            "Dale-Chall Readability Score: 7.49\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 29.82\n",
            "\n",
            "Response from gemini-1.5-pro@vertex-ai:\n",
            "Once upon a time, in a cottage nestled amongst sunflowers taller than a man, lived a tiny old woman with a heart as big as the moon.  One crisp autumn morning, she discovered a piglet, small and pink, snoozing in her pumpkin patch.\n",
            "\n",
            "\"Well now,\" she chuckled, her voice like rustling leaves, \"aren't you a sight?\"\n",
            "\n",
            "The piglet, startled, oinked and tried to scramble away, but the old woman scooped him up, his tiny hooves drumming against her apron.\n",
            "\n",
            "\"Don't you worry, little one,\" she cooed, \"you're safe now. I'll call you Pip.\"\n",
            "\n",
            "Pip grew plump and happy under the old woman's care. He gobbled down bowls of sweet porridge and napped in patches of warm sunshine.  But Pip was a mischievous pig, and one day, he nudged open the garden gate and escaped!\n",
            "\n",
            "The old woman searched high and low, her heart heavy with worry.  She asked the robin perched on her windowsill, \"Robin, robin, have you seen my Pip?\"\n",
            "\n",
            "The robin chirped and pointed its wing towards the whispering woods.\n",
            "\n",
            "The old woman followed the robin's direction.  She asked the babbling brook, \"Brook, brook, have you seen my Pip?\"\n",
            "\n",
            "The brook gurgled and pointed its current towards a towering oak tree.\n",
            "\n",
            "Beneath the oak, the old woman found Pip, happily munching on acorns.\n",
            "\n",
            "\"Pip! You naughty pig!\" she cried. \"Come home at once!\"\n",
            "\n",
            "But Pip, his belly full of acorns, refused to budge.\n",
            "\n",
            "The old woman, at her wit's end, pleaded with a passing bumblebee, \"Bumblebee, bumblebee, please sting Pip on his behind so he'll come home!\"\n",
            "\n",
            "The bumblebee, buzzing with importance, declared, \"I will, but only if the dandelion gives me some honey.\"\n",
            "\n",
            "The dandelion, its golden head held high, refused. \"I will not,\" it huffed, \"unless the wind tickles my chin and makes me laugh!\"\n",
            "\n",
            "The old woman, ever resourceful, whispered to the wind.  The wind, playful and kind, tickled the dandelion's chin until it burst into a fit of giggles, showering the bumblebee with golden pollen.\n",
            "\n",
            "The bumblebee, its tiny belly full, buzzed over to Pip and gave him the tiniest sting on his behind.\n",
            "\n",
            "\"Oink!\" squealed Pip, startled and a little ashamed. He trotted back to the old woman, nuzzling his snout against her hand.\n",
            "\n",
            "The old woman, her heart overflowing, led Pip back home.  From that day on, Pip never strayed far from the garden.  He learned that adventures were fun, but there was no place like home, especially with an old woman who loved him, even when he was naughty. And so they lived, the old woman and her pig, happily ever after, in their cozy cottage amongst the sunflowers. \n",
            "\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 564\n",
            "Lexicon Count: 438\n",
            "Sentence Count: 32\n",
            "Flesch Reading Ease: 82.95\n",
            "Flesch-Kincaid Grade Level: 5.1\n",
            "Gunning Fog: 6.58\n",
            "SMOG Index: 8.0\n",
            "Automated Readability Index: 7.6\n",
            "Coleman-Liau Index: 7.65\n",
            "Linsear Write Formula: 6.428571428571429\n",
            "Dale-Chall Readability Score: 7.2\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 30.23\n",
            "\n",
            "Response from gemma-2-9b-it@fireworks-ai:\n",
            "In a village nestled between rolling hills and a whispering forest lived an old woman with a heart as warm as her hearth fire and a pig named Penelope. Penelope wasn't your average pig; she was intelligent, playful, and possessed a mischievous glint in her beady eyes. The villagers, though amused by Penelope's antics, often grumbled about her snorting and rooting, especially when she unearthed their prize-winning potatoes.\n",
            "\n",
            "One day, a travelling merchant arrived, boasting of a magical wishing well hidden deep in the forest. \"Make a wish,\" he proclaimed, \"and it shall be granted!\" The villagers, their eyes gleaming with hope, rushed to the well, each whispering their desires for riches, health, and happiness.\n",
            "\n",
            "The old woman, however, stayed behind. She had all she needed: her cozy cottage, her garden bursting with vegetables, and most importantly, Penelope. Seeing her friends return empty-handed, she asked, \"Did the well grant your wishes?\"\n",
            "\n",
            "\"No,\" they sighed, \"it only laughed!\"\n",
            "\n",
            "The old woman smiled. \"Perhaps the well doesn't grant wishes for things we can buy,\" she said, \"but wishes for things we truly need.\"\n",
            "\n",
            "That night, Penelope snuck out of the sty. She trotted to the forest, her little hooves kicking up fallen leaves. Reaching the well, she looked up at the moonlit sky and wished for something she truly needed: a friend who understood her.\n",
            "\n",
            "The well, touched by Penelope's pure heart, shimmered. A tiny, iridescent dragonfly emerged, its wings buzzing softly. Penelope, delighted, nuzzled the dragonfly, who in turn, whispered secrets of the forest and danced with her under the stars.\n",
            "\n",
            "The next morning, Penelope returned home, her eyes sparkling. She nudged the old woman awake and, with a happy snort, led her to the forest. There, under the dappled sunlight, the old woman met the dragonfly. It hovered before her, its wings shimmering with every color imaginable.\n",
            "\n",
            "\"This is my friend,\" Penelope oinked proudly.\n",
            "\n",
            "The old woman, her heart overflowing with joy, understood. The well hadn't granted a wish for riches or fame, but for something far more precious: the gift of companionship and the magic of friendship found in the most unexpected places. \n",
            "\n",
            "From that day on, the old woman, Penelope, and the dragonfly were inseparable. They shared stories, laughter, and adventures, proving that true happiness lies not in what we possess, but in the love and friendship we share. And the villagers, witnessing this unlikely trio's joy, learned that sometimes, the most valuable treasures are found not in wishing wells, but in the hearts of those around us.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 592\n",
            "Lexicon Count: 420\n",
            "Sentence Count: 28\n",
            "Flesch Reading Ease: 73.17\n",
            "Flesch-Kincaid Grade Level: 6.8\n",
            "Gunning Fog: 8.0\n",
            "SMOG Index: 9.0\n",
            "Automated Readability Index: 10.2\n",
            "Coleman-Liau Index: 10.32\n",
            "Linsear Write Formula: 8.333333333333334\n",
            "Dale-Chall Readability Score: 8.37\n",
            "Text Standard: 8th and 9th grade\n",
            "Reading Time (seconds): 31.66\n",
            "\n",
            "Response from gemma-2b-it@together-ai:\n",
            "\n",
            "\n",
            "In a world painted with the vibrant hues of sunrise and sunset, lived an old woman named Elara. Her skin, as golden as the morning dew, bore the wisdom of countless tales, her eyes like pools of wisdom in a clearing. Her heart, as warm as the afternoon sun, held a gentle kindness that touched all who knew her.\n",
            "\n",
            "One day, while her beauty and her wisdom were admired by all, a mischievous pig named Pip arrived in her garden. Pip, unlike the others, was not afraid of Elara. He was drawn to her kindness and her stories, his laughter echoing through the peaceful fields.\n",
            "\n",
            "Together, Elara and Pip became inseparable. They would stroll through the golden meadows hand in hand, sharing stories and laughter that warmed the hearts of all who heard them. Elara's wisdom and Pip's playful spirit brought joy to the entire village.\n",
            "\n",
            "One day, a wicked sorcerer cast a spell that darkened the land and poisoned the flowers. Elara, with her age and grace, refused to succumb to the darkness. She and Pip joined forces with other brave souls, determined to save their world from the sorcerer's evil.\n",
            "\n",
            "Their journey led them through enchanted forests and across shimmering rivers. They faced perilous trials and overcame many obstacles, but Elara and Pip never lost hope. Their unwavering determination and the love they shared for each other were their greatest weapons.\n",
            "\n",
            "Finally, they reached the sorcerer's lair, a dark cave hidden deep within the mountains. With Elara's wisdom and Pip's bravery, they confronted the sorcerer and his wicked creatures. A fierce battle ensued, but Elara's magic and Pip's unwavering resolve proved too much.\n",
            "\n",
            "The sorcerer was vanquished, his dark magic extinguished by the combined power of Elara and Pip. The land was bathed in the warm glow of the sun, and the flowers bloomed with colors as vibrant as Elara and Pip's love.\n",
            "\n",
            "From that day on, Elara and Pip became the guardians of the land, their love a beacon of hope that shone brightly even in the darkest of times. And so, the Old Woman and her Pig became local legends, a testament to the power of love, friendship, and the magic that resides within the human heart.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 497\n",
            "Lexicon Count: 371\n",
            "Sentence Count: 22\n",
            "Flesch Reading Ease: 79.7\n",
            "Flesch-Kincaid Grade Level: 6.3\n",
            "Gunning Fog: 8.05\n",
            "SMOG Index: 8.4\n",
            "Automated Readability Index: 9.5\n",
            "Coleman-Liau Index: 9.16\n",
            "Linsear Write Formula: 7.5\n",
            "Dale-Chall Readability Score: 8.18\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 26.02\n",
            "\n",
            "Response from gpt-3.5-turbo@openai:\n",
            "Once upon a time, in a quaint little village nestled in the rolling hills, there lived an old woman and her beloved pig. The old woman had raised the pig from a piglet, and they had grown to love each other dearly.\n",
            "\n",
            "Every day, the old woman would take her pig for a walk through the village, and the pig would trot happily beside her, wagging its curly tail. The villagers would smile and wave as they passed by, for they all knew and loved the old woman and her pig.\n",
            "\n",
            "One day, as the old woman and her pig were walking through the village, they came across a muddy puddle in the middle of the road. The pig, being a curious and mischievous creature, decided to jump right in and start rolling around in the mud.\n",
            "\n",
            "The old woman tried to coax the pig out of the puddle, but the pig simply grunted and continued to wallow in the mud. The old woman grew frustrated and tried to pull the pig out, but the pig was too heavy and stubborn.\n",
            "\n",
            "Just then, a passing farmer saw the old woman struggling with her pig and offered to help. Together, they managed to pull the pig out of the mud, but now the pig was covered from head to toe in mud and filth.\n",
            "\n",
            "The old woman sighed and shook her head, wondering how she would ever get her pig clean again. But then, a thought occurred to her. She led the pig to a nearby stream and began to scrub and wash the mud away, using handfuls of fragrant herbs and flowers to make the pig smell sweet and fresh.\n",
            "\n",
            "As the sun began to set, the old woman and her pig returned to their cozy cottage, the pig now clean and shiny. The old woman tucked the pig into bed with a warm blanket and a kiss on its snout, grateful for the farmer's help and for the bond she shared with her beloved pig.\n",
            "\n",
            "And so, the old woman and her pig lived happily ever after, their friendship stronger than ever. And whenever they passed by that muddy puddle in the village, the pig would always give it a wide berth, remembering the day it had gotten into a sticky situation and the old woman had come to its rescue.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 484\n",
            "Lexicon Count: 392\n",
            "Sentence Count: 17\n",
            "Flesch Reading Ease: 81.87\n",
            "Flesch-Kincaid Grade Level: 7.6\n",
            "Gunning Fog: 9.95\n",
            "SMOG Index: 7.7\n",
            "Automated Readability Index: 9.6\n",
            "Coleman-Liau Index: 6.33\n",
            "Linsear Write Formula: 10.2\n",
            "Dale-Chall Readability Score: 6.92\n",
            "Text Standard: 9th and 10th grade\n",
            "Reading Time (seconds): 23.77\n",
            "\n",
            "Response from gpt-4@openai:\n",
            "Once upon a time, in a quaint little village nestled between the rolling hills, there lived a kind and cheerful old woman. She lived in a small cottage with her best friend, a plump and playful pig. The villagers often chuckled at the sight of them, for it was unusual to see a woman and a pig living together. But the old woman and her pig didn't mind; they were content in their own little world.\n",
            "\n",
            "The old woman had found the pig as a small piglet, lost and alone in the forest. She had taken him in, fed him, and named him Oliver. Over the years, Oliver grew into a large pig, but he never lost his playful spirit. He would often follow the old woman around, wagging his curly tail, and grunting happily.\n",
            "\n",
            "One day, a terrible drought hit the village. The wells dried up, the crops withered, and the villagers were filled with despair. The old woman, too, was worried. Oliver, who could sense her distress, decided to help. He set off on a journey to find water.\n",
            "\n",
            "Oliver ventured far and wide, braving the scorching sun and dry lands. After an exhausting search, he found a hidden spring in the heart of the forest. With great effort, he managed to carry some water back to the village.\n",
            "\n",
            "The villagers were astonished when they saw Oliver return with water. They were even more surprised when he led them to the hidden spring. Thanks to Oliver, the village was saved from the drought. The crops started to grow again, and the wells were filled with fresh water.\n",
            "\n",
            "The villagers thanked Oliver and the old woman for their help. They realized that even the most unlikely creatures could make a difference. From that day forward, the old woman and her pig were respected and loved by everyone in the village.\n",
            "\n",
            "And so, the old woman and Oliver lived out their days in peace and happiness. They continued to help the villagers in times of need and always brought smiles to their faces. And every evening, as the sun set, the old woman would sit on her porch, Oliver resting by her feet, and they would watch the stars together.\n",
            "\n",
            "And the villagers, whenever they saw the twinkling stars, were reminded of the old woman and her pig, who had shown them the power of love, kindness, and the most unexpected friendships.\n",
            "\n",
            "And that, dear children, is the tale of the old woman and her pig. A tale that teaches us that no act of kindness, however small, is ever wasted. And that every creature, big or small, has a role to play in the grand scheme of things. All it takes is a heart full of love and a spirit willing to help.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 598\n",
            "Lexicon Count: 464\n",
            "Sentence Count: 31\n",
            "Flesch Reading Ease: 81.63\n",
            "Flesch-Kincaid Grade Level: 5.6\n",
            "Gunning Fog: 6.86\n",
            "SMOG Index: 7.6\n",
            "Automated Readability Index: 6.8\n",
            "Coleman-Liau Index: 6.78\n",
            "Linsear Write Formula: 7.666666666666666\n",
            "Dale-Chall Readability Score: 6.52\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 30.01\n",
            "\n",
            "Response from gpt-4-turbo@openai:\n",
            "Once upon a time, in a village swathed in the hues of emerald green and the golden whispers of the sun, lived an old woman named Elspeth. Her cottage, made of timeworn stones and thatched with the straw of summers long past, sat at the edge of the village, where the forest whispered secrets only the wind could understand.\n",
            "\n",
            "Elspeth wasn’t lonely, for she had the companionship of a cheerful little pig named Petunia. This pig wasn’t just any pig, mind you; Petunia had a snout that could sniff out truffles and a heart as pure as the crystal streams that ran through their land.\n",
            "\n",
            "One crisp autumn morning, Elspeth decided it was time to visit the market. She needed to sell her truffles to buy the seeds for her winter garden. She tied her favorite red shawl around her neck, fetched her wicker basket, and called, \"Come along, Petunia! Let us go to the market.\"\n",
            "\n",
            "But as they were about to leave, Elspeth noticed Petunia was unusually stubborn. No matter how much she coaxed, Petunia simply wouldn’t cross the threshold of their home. Puzzled, Elspeth looked around and noticed that a silver coin had fallen from her pocket and was lying just across the doorway. Smiling, she picked it up and said, \"Oh, Petunia, were you telling me not to forget our lucky coin?\"\n",
            "\n",
            "With the coin safely tucked away, they set off to the market. The path was twisted and turned through the whispering forest, over babbling brooks, and under the watchful eyes of ancient, knotted trees. As they passed a particularly dense part of the forest, a mischievous fairy appeared, her wings shimmering with a light that flickered like the stars.\n",
            "\n",
            "\"Good day, Elspeth. What brings you and your pig through my forest?\" the fairy asked, her voice a melody that seemed to dance with the rustling leaves.\n",
            "\n",
            "\"We’re off to the market to sell our truffles,\" Elspeth replied, showing the fairy the contents of her basket.\n",
            "\n",
            "\"Ah, a journey for commerce,\" the fairy mused, her eyes twinkling. \"I propose a trade. I am in need of your truffles for my midwinter feast. In exchange, I offer you three wishes. But beware, each wish comes with its own twist.\"\n",
            "\n",
            "Elspeth thought carefully. She knew fairy gifts were not to be taken lightly. With a nod, she agreed, asking for her first wish, \"I wish for a bountiful garden that can feed me all year round.\"\n",
            "\n",
            "The fairy snapped her fingers, and at once, Elspeth’s cottage was surrounded by the most lush and vibrant garden, bursting with vegetables and fruits. \"Remember, it must be tended to every day, or it will wither,\" the fairy warned.\n",
            "\n",
            "For her second wish, Elspeth said, \"I wish for Petunia to speak, so I might understand her better and not miss what she tries to tell me.\"\n",
            "\n",
            "With another snap of her fingers, the fairy granted the wish. Petunia blinked, looked up at Elspeth, and said, \"Thank you, Elspeth. Now, I can tell you how much I love our morning walks and your delicious truffles.\"\n",
            "\n",
            "Elspeth laughed with joy, but she remembered the fairy’s warning about twists. She pondered deeply for her last wish and finally declared, \"I wish for the wisdom to use these gifts wisely.\"\n",
            "\n",
            "\"Ah,\" said the fairy, pleased with Elspeth’s prudence. \"That is a wish that brings its own reward.\"\n",
            "\n",
            "With that, the fairy disappeared as mysteriously as she had appeared. Elspeth and Petunia made their way back home, their journey filled with delightful conversation. Elspeth tended her garden daily, and it never withered. Petunia proved to be wise counsel on many matters, from when to plant the seeds to how to deal with village disputes.\n",
            "\n",
            "And so, Elspeth and Petunia lived out their days, the wisdom of their choices apparent in the laughter and love that filled their home, proving that sometimes, the simplest wishes are the most profound. In the village, their story was told and retold, a tale of an old woman, her pig, and a fairy’s magic, reminding all that wisdom, love, and understanding are the greatest treasures of all.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 899\n",
            "Lexicon Count: 685\n",
            "Sentence Count: 43\n",
            "Flesch Reading Ease: 80.72\n",
            "Flesch-Kincaid Grade Level: 6.0\n",
            "Gunning Fog: 7.53\n",
            "SMOG Index: 7.5\n",
            "Automated Readability Index: 8.7\n",
            "Coleman-Liau Index: 8.47\n",
            "Linsear Write Formula: 13.0\n",
            "Dale-Chall Readability Score: 7.7\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 47.39\n",
            "\n",
            "Response from gpt-4o@openai:\n",
            "Once upon a time, in a quaint little village nestled on the edge of an enchanted forest, there lived an old woman named Eliza. She was known for her kind heart and her magical ability to understand the language of animals. Eliza lived alone in a cozy, ivy-covered cottage with a lush garden where she grew all sorts of vegetables and herbs.\n",
            "\n",
            "One spring morning, Eliza decided she needed a companion to help her with the chores and keep her company. She took a basket of fresh vegetables to the village market, hoping to trade them for a suitable animal. As she wandered through the bustling stalls, she came across a pen with the most peculiar pig she had ever seen. This pig had a shiny, golden coat and eyes that sparkled with intelligence.\n",
            "\n",
            "\"How much for this pig?\" Eliza asked the farmer.\n",
            "\n",
            "The farmer scratched his head and said, \"Well, this here's no ordinary pig. I've tried to sell him many times, but he always finds his way back to me. If you can keep him, he's yours for free.\"\n",
            "\n",
            "Eliza agreed and brought the golden pig home, naming him Cornelius. To her delight, Cornelius was not only intelligent but also very helpful. He weeded the garden, fetched water, and even sang cheerful songs in a melodious oink. Eliza and Cornelius became the best of friends, and life in the cottage was filled with joy and laughter.\n",
            "\n",
            "One day, as Cornelius was digging in the garden, he unearthed a small, ancient chest. Eliza opened it to find a map and a note written in elegant, flowing script:\n",
            "\n",
            "\"To the finder of this map, a treasure lies hidden in the heart of the enchanted forest. Beware the trials that await, for only the pure of heart may claim it.\"\n",
            "\n",
            "Eliza and Cornelius decided to embark on the adventure together. They packed some provisions and set off towards the enchanted forest. As they ventured deeper into the woods, they encountered various magical creatures and obstacles.\n",
            "\n",
            "First, they met a talking owl who demanded a riddle be solved to pass. Cornelius, being quite clever, solved it with ease. Next, they faced a bridge guarded by a grumpy troll who wouldn't let them cross unless they performed a dance. Eliza and Cornelius danced with such joy and harmony that the troll was left speechless and allowed them to pass.\n",
            "\n",
            "Finally, they reached a clearing where a majestic unicorn stood. The unicorn spoke in a voice that echoed with wisdom, \"To claim the treasure, you must prove your kindness and bravery.\"\n",
            "\n",
            "Eliza and Cornelius recounted their journey, emphasizing their acts of kindness and the bond of friendship they shared. The unicorn nodded and led them to a hidden grove where the treasure lay—a chest filled with gold, jewels, and a magical seed.\n",
            "\n",
            "\"The gold and jewels are yours to do with as you please,\" the unicorn said. \"But the true treasure is the seed. Plant it with love and care, and it will grant you a wish.\"\n",
            "\n",
            "Eliza and Cornelius returned to their cottage, where they planted the magical seed in their garden. They wished for the village to prosper and for everyone to live in harmony. As the seed sprouted, it grew into a magnificent tree that bore fruit all year round, providing food and prosperity to the entire village.\n",
            "\n",
            "Eliza and Cornelius lived happily ever after, their hearts filled with the joy of their friendship and the knowledge that they had made the world a better place.\n",
            "\n",
            "And so, the tale of the old woman and her pig became a cherished story, reminding everyone that true treasure lies not in gold or jewels, but in the bonds of kindness and friendship.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 825\n",
            "Lexicon Count: 619\n",
            "Sentence Count: 38\n",
            "Flesch Reading Ease: 80.31\n",
            "Flesch-Kincaid Grade Level: 6.1\n",
            "Gunning Fog: 8.2\n",
            "SMOG Index: 9.3\n",
            "Automated Readability Index: 8.6\n",
            "Coleman-Liau Index: 8.41\n",
            "Linsear Write Formula: 12.4\n",
            "Dale-Chall Readability Score: 7.23\n",
            "Text Standard: 8th and 9th grade\n",
            "Reading Time (seconds): 42.17\n",
            "\n",
            "Response from llama-3-70b-chat@fireworks-ai:\n",
            "What a delightful tale! Here's my version of \"The Old Woman and Her Pig\":\n",
            "\n",
            "**The Old Woman and Her Pig: A Tale of Good Fortune**\n",
            "\n",
            "In the rolling hills of a lush countryside, there lived an old woman named Griselda. She resided in a cozy little cottage at the edge of a dense forest, surrounded by a garden that was her pride and joy. Griselda was known throughout the village for her kindness, her wisdom, and her remarkable ability to communicate with animals.\n",
            "\n",
            "One day, as she was tending to her garden, a tiny piglet wandered into her yard, oinking and snuffling about. Griselda's heart melted at the sight of the little creature, and she decided to take him in. She named him Percy and raised him as her own.\n",
            "\n",
            "As Percy grew, so did his appetite. He would devour anything in sight, from juicy berries to tender shoots of grass. Griselda would often chuckle at his antics, shaking her head in wonder at his insatiable hunger. Despite his voracious appetite, Percy was a gentle soul, and he brought Griselda great joy.\n",
            "\n",
            "One day, while Griselda was out gathering herbs in the forest, Percy managed to get himself into a bit of trouble. He had wandered into the nearby village, where he had been spotted by the local butcher, a greedy and cunning man named Mr. Grimstone. The butcher had a wicked glint in his eye, and he saw an opportunity to make a profit from the plump pig.\n",
            "\n",
            "Mr. Grimstone snatched Percy from the village square and dragged him back to his shop, intending to slaughter him for his next customer. But Percy, sensing danger, let out a loud oink and struggled free from the butcher's grasp. He ran back to Griselda's cottage, where he found her returning from her forest excursion.\n",
            "\n",
            "Distraught and worried, Griselda chased after Mr. Grimstone, determined to rescue her beloved Percy. She confronted the butcher, who sneered at her, refusing to return the pig. Enraged, Griselda shook her fist at the sky and called upon the ancient magic that dwelled within the forest.\n",
            "\n",
            "Suddenly, the trees began to stir, their branches tangling together to form a protective barrier around Griselda and Percy. The wind whispered secrets in the old woman's ear, and she knew exactly what to do. With a wave of her hand, she summoned a swarm of bees to chase Mr. Grimstone from the village, forcing him to abandon his wicked plans.\n",
            "\n",
            "As the villagers watched in awe, Griselda and Percy emerged from the forest, surrounded by a radiant glow. The old woman's kindness and love for her pig had awakened the forest's magic, and now good fortune was theirs to claim.\n",
            "\n",
            "From that day on, Griselda's garden flourished like never before, producing the most vibrant flowers and luscious fruits in all the land. Percy, now safe and sound, grew into a majestic creature, with a coat as shiny as gold and a heart full of gratitude. Together, they roamed the countryside, spreading joy and prosperity wherever they went.\n",
            "\n",
            "As for Mr. Grimstone, he learned a valuable lesson about the power of kindness and the importance of treating all creatures with respect. He abandoned his butcher's shop and took up a new trade, becoming a skilled beekeeper and honey producer.\n",
            "\n",
            "And so, Griselda and Percy lived happily ever after, their bond growing stronger with each passing day, a testament to the magic that bloomed in the hearts of those who loved and cared for one another.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 808\n",
            "Lexicon Count: 584\n",
            "Sentence Count: 34\n",
            "Flesch Reading Ease: 70.94\n",
            "Flesch-Kincaid Grade Level: 7.6\n",
            "Gunning Fog: 9.07\n",
            "SMOG Index: 9.2\n",
            "Automated Readability Index: 9.4\n",
            "Coleman-Liau Index: 8.81\n",
            "Linsear Write Formula: 11.4\n",
            "Dale-Chall Readability Score: 8.03\n",
            "Text Standard: 8th and 9th grade\n",
            "Reading Time (seconds): 40.5\n",
            "\n",
            "Response from llama-3-8b-chat@fireworks-ai:\n",
            "What a delightful tale! Here's a fairy tale about THE OLD WOMAN AND HER PIG:\n",
            "\n",
            "Once upon a time, in a small village nestled in the rolling hills of the countryside, there lived an old woman named Ursula. She was a kind and gentle soul, loved by all who knew her. Ursula lived in a tiny cottage on the outskirts of the village, surrounded by a lush garden filled with herbs and flowers that she tended with great care.\n",
            "\n",
            "Ursula's greatest joy was her beloved pig, Percival. She had rescued Percival from a cruel fate as a young piglet, and he had grown into a sturdy and friendly boar. Ursula and Percival were inseparable, and the villagers would often see them taking long walks together through the countryside.\n",
            "\n",
            "One day, a wicked witch cast a spell on the village, causing all the animals to turn against each other. The chickens pecked at the cows, the dogs chased the cats, and the pigs... well, the pigs were particularly vicious. They attacked each other, tearing each other's flesh with their razor-sharp teeth.\n",
            "\n",
            "Percival, being the gentle soul that he was, was devastated by the chaos. He refused to fight, even when the other pigs attacked him. Ursula, seeing her beloved pet in distress, knew she had to do something to stop the madness.\n",
            "\n",
            "She gathered a small bag of herbs from her garden and set off into the forest to find the witch who had cast the spell. The villagers, who had also been affected by the witch's curse, joined her on the quest. Together, they journeyed deep into the heart of the forest, guided by Ursula's wise and gentle nature.\n",
            "\n",
            "As they walked, Ursula told stories of the ancient magic that lay hidden within the earth. She spoke of the power of love and kindness, and how these qualities could heal even the deepest of wounds. The villagers listened with rapt attention, and soon, they felt the weight of their troubles lifting.\n",
            "\n",
            "At last, they came to the witch's lair, where they found her cackling with glee at the chaos she had unleashed. Ursula, undaunted, approached the witch and presented her with the bag of herbs. \"These will break your spell,\" she said, her voice calm and steady.\n",
            "\n",
            "The witch, taken aback by Ursula's bravery, hesitated for a moment before snatching the bag from her hand. She opened it, and a warm, golden light spilled out, filling the forest with a sense of peace and harmony.\n",
            "\n",
            "As the light spread, the animals began to calm, their instincts returning to their natural state. The chickens stopped pecking at the cows, the dogs stopped chasing the cats, and the pigs... well, the pigs stopped fighting each other, and instead, began to snuggle and play together.\n",
            "\n",
            "Ursula and her companions returned to the village, where they were greeted as heroes. The villagers celebrated with feasts and songs, and Percival, now freed from the curse, was hailed as a symbol of peace and harmony.\n",
            "\n",
            "From that day on, Ursula and Percival were known as the guardians of the forest, and their love and kindness inspired the villagers to live in harmony with the natural world. And the witch, who had once sought to spread chaos and destruction, was transformed by Ursula's gentle nature and became a kind and wise member of the community.\n",
            "\n",
            "And so, the story of the Old Woman and her Pig was passed down through generations, a reminder of the power of love, kindness, and the magic that lies within the earth.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 801\n",
            "Lexicon Count: 590\n",
            "Sentence Count: 33\n",
            "Flesch Reading Ease: 70.23\n",
            "Flesch-Kincaid Grade Level: 7.9\n",
            "Gunning Fog: 8.72\n",
            "SMOG Index: 10.0\n",
            "Automated Readability Index: 9.5\n",
            "Coleman-Liau Index: 8.41\n",
            "Linsear Write Formula: 8.666666666666666\n",
            "Dale-Chall Readability Score: 7.58\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 40.4\n",
            "\n",
            "Response from mistral-7b-instruct-v0.3@together-ai:\n",
            "Title: The Enchanted Piglet and the Old Woman: A Tale of Friendship and Magic\n",
            "\n",
            "Once upon a time, in a quiet village nestled between the hills, lived an old woman named Agnes. Agnes was known for her kind heart and laughter that could fill the entire town. However, she was often alone, for her only companions were the village animals who would visit her cozy home.\n",
            "\n",
            "One day, while tending to her garden, Agnes discovered a tiny, shimmering piglet hiding beneath the roses. The piglet's fur was not the usual pink, but a brilliant, iridescent blue. Agnes, being a kind soul, picked up the piglet and decided to take it in. She named it Luminous, for the sparkle in its eyes.\n",
            "\n",
            "Luminous grew quickly, and soon, the whole village was talking about the enchanted pig. Some said it was a gift from the fairy queen, others believed it was a cursed creature. But Agnes knew in her heart that Luminous was just a lost, magical pig who needed a home.\n",
            "\n",
            "One day, a cruel merchant from a neighboring town heard about Luminous and decided he must own the enchanted piglet. He threatened Agnes, saying he would take Luminous by force if she did not give it to him. Agnes, being small and frail, was terrified.\n",
            "\n",
            "But Luminous, who had grown to become a loyal friend, would not let Agnes face the merchant alone. With a fierce determination in its eyes, Luminous charged at the merchant, knocking him off his feet and scattering his goods across the village square.\n",
            "\n",
            "The villagers, who had been watching in shock, cheered for Luminous. The merchant, humiliated, fled the village, never to return. The villagers, grateful for Luminous's bravery, decided that the enchanted pig was theirs to protect.\n",
            "\n",
            "Agnes, though she was saddened to lose her companion, knew that Luminous was happiest when it was among its new friends. And so, Luminous stayed in the village, living a life filled with love and friendship.\n",
            "\n",
            "From that day on, the old woman and her pig were no longer just Agnes and Luminous. They were the symbol of friendship, bravery, and the power of kindness in a world that needed it the most. And their tale was told and retold, reminding everyone that even the smallest and most unlikely of creatures can have the biggest of hearts.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 533\n",
            "Lexicon Count: 390\n",
            "Sentence Count: 23\n",
            "Flesch Reading Ease: 71.14\n",
            "Flesch-Kincaid Grade Level: 7.6\n",
            "Gunning Fog: 8.75\n",
            "SMOG Index: 10.3\n",
            "Automated Readability Index: 9.1\n",
            "Coleman-Liau Index: 8.58\n",
            "Linsear Write Formula: 8.5\n",
            "Dale-Chall Readability Score: 7.27\n",
            "Text Standard: 8th and 9th grade\n",
            "Reading Time (seconds): 26.82\n",
            "\n",
            "Response from mistral-large@aws-bedrock:\n",
            "Once upon a time, in a small village nestled between a dense forest and a sparkling river, lived an old woman. She was known by all as Mother Elsa, a kind-hearted soul who lived a simple life. Her most prized possession was her little pig, whom she affectionately named Pippin.\n",
            "\n",
            "Pippin was not your ordinary pig. He was a small, plump creature with a pink nose and curly tail. He was intelligent and playful, often entertaining Mother Elsa with his antics. But most importantly, Pippin was Mother Elsa's companion, keeping her company in her golden years.\n",
            "\n",
            "One day, Mother Elsa realized that she was running low on food. She decided to take Pippin to the market to sell him, so she could buy some provisions. However, the thought of parting with Pippin filled her heart with sadness. She loved Pippin dearly and knew that life wouldn't be the same without him.\n",
            "\n",
            "As they walked to the market, Mother Elsa couldn't help but reminisce about the countless memories they had shared. Tears welled up in her eyes, and she softly sang a song, \"Pippin, my Pippin, I wish you could stay. But alas, I must sell you today.\"\n",
            "\n",
            "To her surprise, Pippin responded, \"Mother Elsa, I understand your plight. I do not wish to leave you either. But perhaps there is another way.\" Mother Elsa was taken aback. She had never heard Pippin speak before!\n",
            "\n",
            "Pippin then suggested, \"Why don't we ask the market-goers to help us? Maybe they can donate some food or coins, so you won't have to sell me.\"\n",
            "\n",
            "Mother Elsa agreed, and when they arrived at the market, she shared their predicament with the villagers. Touched by their story and Mother Elsa's love for Pippin, the villagers generously donated food and coins, enough to last Mother Elsa for months.\n",
            "\n",
            "Overjoyed, Mother Elsa thanked the villagers and returned home with Pippin. From that day forward, Mother Elsa never had to worry about food again. The villagers would often visit, bringing food and sharing stories, creating a bond that strengthened their community.\n",
            "\n",
            "And so, Mother Elsa and Pippin lived out their days happily, surrounded by love and friendship. Their story served as a reminder to the villagers about the power of love, compassion, and community. And whenever Mother Elsa sang her song, it was no longer filled with sadness but joy and gratitude. \"Pippin, my Pippin, you're here to stay. Thanks to our friends, we'll always have enough today.\"\n",
            "\n",
            "And that, dear friends, is the tale of the old woman and her pig.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 599\n",
            "Lexicon Count: 424\n",
            "Sentence Count: 32\n",
            "Flesch Reading Ease: 74.9\n",
            "Flesch-Kincaid Grade Level: 6.1\n",
            "Gunning Fog: 7.3\n",
            "SMOG Index: 8.7\n",
            "Automated Readability Index: 7.7\n",
            "Coleman-Liau Index: 8.28\n",
            "Linsear Write Formula: 6.375\n",
            "Dale-Chall Readability Score: 6.94\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 29.72\n",
            "\n",
            "Response from mistral-small@mistral-ai:\n",
            "Once upon a time, in a quaint village nestled between the rolling hills and the sparkling sea, lived an old woman named Agnes. Agnes was known throughout the village for her kind heart and her peculiar pet, a large and friendly pig named Prudence.\n",
            "\n",
            "Prudence was no ordinary pig. She had a coat as bright as the sun, and her snout was as pink as the dawn. She was as intelligent as any human and had a peculiar liking for flowers, especially roses. Agnes and Prudence were inseparable, and their bond was a sight to behold.\n",
            "\n",
            "One day, a terrible drought struck the village. The crops withered, the wells ran dry, and the villagers were facing a dire situation. Seeing her friends' plight, Agnes decided to help. She remembered an ancient tale about a magical well hidden deep within the forest, which never ran dry.\n",
            "\n",
            "With Prudence by her side, Agnes embarked on a journey to find the well. They faced many challenges, from crossing treacherous rivers to navigating through dense thickets. But Prudence, with her strength and Agnes, with her wisdom, overcame each obstacle.\n",
            "\n",
            "Finally, they reached the magical well. However, a wicked witch guarded it, demanding a price for its water. She asked for Prudence in exchange for the water. Agnes was heartbroken but knew she had to save her village. She agreed to the witch's terms, but before handing over Prudence, she asked for one last dance with her beloved pet.\n",
            "\n",
            "As they danced, Agnes whispered her plan to Prudence. With a nod, Prudence began to eat the witch's prized roses. Enraged, the witch broke her focus on the spell that bound the well, and the water began to flow freely. Seizing the opportunity, Agnes and Prudence escaped, leaving the witch with nothing but a garden of eaten roses.\n",
            "\n",
            "They returned to the village with the water, saving their friends and their home. From that day forward, the village flourished, and Agnes and Prudence were celebrated as heroes. And so, they lived happily ever after, proving that love and friendship could overcome even the most impossible of challenges.\n",
            "\n",
            "And that, dear reader, is the tale of the old woman and her pig.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 499\n",
            "Lexicon Count: 365\n",
            "Sentence Count: 26\n",
            "Flesch Reading Ease: 74.19\n",
            "Flesch-Kincaid Grade Level: 6.4\n",
            "Gunning Fog: 7.35\n",
            "SMOG Index: 8.5\n",
            "Automated Readability Index: 8.1\n",
            "Coleman-Liau Index: 8.81\n",
            "Linsear Write Formula: 7.142857142857142\n",
            "Dale-Chall Readability Score: 7.62\n",
            "Text Standard: 8th and 9th grade\n",
            "Reading Time (seconds): 25.6\n",
            "\n",
            "Response from mixtral-8x22b-instruct-v0.1@deepinfra:\n",
            "Long ago, in a quaint little village nestled between a dense forest and a towering mountain, there lived an old woman named Martha. She was known throughout the village for her kindness and generosity. Martha lived humbly in a small, thatched-roof cottage at the edge of the forest, tending to her lush garden and caring for her beloved pig, Petunia.\n",
            "\n",
            "Petunia was no ordinary pig. She was a wise and gentle creature with a coat as white as freshly fallen snow. The villagers marveled at the bond between Martha and Petunia, for they were inseparable.\n",
            "\n",
            "One fateful day, a wicked sorcerer named Malazar arrived in the village. He sought to claim the forest and the mountain for his own nefarious purposes. The villagers were filled with fear, and many pleaded with Martha to use her special bond with Petunia to save their home.\n",
            "\n",
            "Martha, knowing the power of love and friendship, agreed to help. She and Petunia embarked on a perilous journey to seek the help of the wise and mystical beings that lived deep within the forest. With each step, their bond grew stronger, and their determination to save their beloved village grew fiercer.\n",
            "\n",
            "As they ventured deeper into the forest, they encountered a host of magical creatures. The first to cross their path was a cunning fox. \"Old woman,\" he said, his eyes gleaming with mischief, \"if you can answer my riddle, I shall grant you safe passage through my part of the forest.\" Martha, with Petunia by her side, answered the riddle with ease, and the fox, begrudgingly impressed, allowed them to pass.\n",
            "\n",
            "Next, they encountered a wise old owl perched high in a tree. \"Old woman,\" he hooted, \"if you can answer my question, I shall grant you safe passage through my part of the forest.\" Martha, drawing upon her years of wisdom and experience, answered the owl's question without hesitation. The owl nodded in approval, and Martha and Petunia continued their journey.\n",
            "\n",
            "As they ventured further into the forest, they met a powerful stag. \"Old woman,\" he bellowed, his antlers gleaming in the dappled sunlight, \"if you can prove your worth, I shall grant you safe passage through my part of the forest.\" Martha, with Petunia's steadfast support, showed the stag her unwavering determination and love for her village. The stag, recognizing the strength of their bond, granted them safe passage.\n",
            "\n",
            "Finally, they arrived at the heart of the forest, where the most ancient and mystical creatures dwelled. Here, they found the wise and powerful Forest Queen. She listened intently as Martha recounted their journey and the plight of their village. The Forest Queen, moved by their tale, bestowed upon Martha a single, enchanted acorn.\n",
            "\n",
            "\"Old woman,\" she said, her voice echoing through the trees, \"this acorn holds the power to protect your village from the evil sorcerer. Plant it at the base of the mountain, and it will grow into a mighty oak, its roots spreading wide and deep. No harm shall come to your village as long as the oak stands tall.\"\n",
            "\n",
            "With great care, Martha and Petunia returned to their village, bearing the enchanted acorn. As they planted the acorn at the base of the mountain, the villagers gathered around, their faces filled with hope and gratitude. As the days passed, the acorn grew into a mighty oak, its roots spreading wide and deep, just as the Forest Queen had promised.\n",
            "\n",
            "The evil sorcerer Malazar, enraged by the villagers' defiance, tried time and again to claim the forest and the mountain for himself. But each time, the roots of the enchanted oak grew stronger, and his spells were rendered powerless. In the end, Malazar was forced to retreat, defeated by the love and determination of an old woman and her pig.\n",
            "\n",
            "From that day forward, the village thrived, and the bond between Martha and Petunia became the stuff of legend. And so, the tale of the old woman and her pig served as a reminder to all that love, friendship, and determination could overcome even the most formidable of foes.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 916\n",
            "Lexicon Count: 678\n",
            "Sentence Count: 39\n",
            "Flesch Reading Ease: 70.73\n",
            "Flesch-Kincaid Grade Level: 7.7\n",
            "Gunning Fog: 8.43\n",
            "SMOG Index: 8.7\n",
            "Automated Readability Index: 10.0\n",
            "Coleman-Liau Index: 9.28\n",
            "Linsear Write Formula: 6.714285714285714\n",
            "Dale-Chall Readability Score: 7.32\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 47.98\n",
            "\n",
            "Response from mixtral-8x7b-instruct-v0.1@aws-bedrock:\n",
            "Once upon a time, in a small village nestled at the edge of a dense forest, there lived an old woman and her beloved pig, Hamlet. The old woman was known throughout the village for her kindness and wisdom, and Hamlet was known for his playful antics and insatiable appetite.\n",
            "\n",
            "One day, the old woman received a letter from the king himself, inviting her to a grand ball at the palace. The old woman was thrilled, but she had nothing to wear! She searched through her trunks and chests, but all of her fine clothes had long since turned to rags.\n",
            "\n",
            "Just as she was about to give up hope, she remembered Hamlet. She had always kept him well-groomed and well-fed, and she had a feeling that he might be able to help her. She harnessed him to her cart and set off for the marketplace, where she sold all of her eggs and vegetables in exchange for the finest cloth the merchant had to offer.\n",
            "\n",
            "When she returned home, she set to work sewing a beautiful gown, using every last bit of the cloth she had bought. She worked day and night, and when she was finished, she had a dress that was fit for a queen.\n",
            "\n",
            "The night of the ball finally arrived, and the old woman set off for the palace, her heart filled with excitement. When she arrived, the king and queen were delighted to see her, and they danced and laughed the night away.\n",
            "\n",
            "As the clock struck midnight, the old woman knew it was time to go. She curtsied to the king and queen, and as she was leaving, she heard the queen call out to her.\n",
            "\n",
            "\"My dear, your pig has been following you all night,\" the queen said. \"He seems to be quite taken with you.\"\n",
            "\n",
            "The old woman turned to see Hamlet, who had managed to escape from her cart and was now waddling towards her, a bouquet of flowers in his mouth. She couldn't help but laugh.\n",
            "\n",
            "\"Yes, Your Majesty, that is my Hamlet,\" she said. \"He is the most loyal and loving pig a person could ever ask for.\"\n",
            "\n",
            "The king and queen were amazed, and they asked the old woman to tell them more about her beloved Hamlet. She told them of his playful antics and insatiable appetite, and as she spoke, the king and queen couldn't help but be charmed by the old woman and her pig.\n",
            "\n",
            "From that day on, the old woman and Hamlet were invited to every ball and feast at the palace, and they lived happily ever after.\n",
            "\n",
            "And so, the story of the old woman and her pig, Hamlet, became a beloved fairy tale, passed down from generation to generation, reminding everyone that true love and loyalty can be found in the most unexpected places.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 584\n",
            "Lexicon Count: 473\n",
            "Sentence Count: 24\n",
            "Flesch Reading Ease: 85.32\n",
            "Flesch-Kincaid Grade Level: 6.3\n",
            "Gunning Fog: 8.81\n",
            "SMOG Index: 8.1\n",
            "Automated Readability Index: 8.5\n",
            "Coleman-Liau Index: 6.56\n",
            "Linsear Write Formula: 10.2\n",
            "Dale-Chall Readability Score: 6.55\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 29.63\n",
            "\n",
            "Response from qwen-2-72b-instruct@deepinfra:\n",
            "Once upon a time, in a quaint village nestled at the heart of the Enchanted Forest, lived an elderly woman named Elfinora. Her hair was as white as the snow that blanketed the forest in winter, and her eyes twinkled with the wisdom of countless years. The villagers knew her as the \"Old Woman with the Magic Pig,\" and for good reason.\n",
            "\n",
            "The Old Woman was not alone in her humble cottage. She had a dear companion—a pig, unlike any other the villagers had ever seen. This pig, whom she named Goldylocks, was no ordinary creature. Goldylocks had a coat of shimmering gold that seemed to change color as the light shifted. Her tail was tipped in silver, and her eyes held a deep blue that reflected the depths of the sea.\n",
            "\n",
            "Goldylocks was not just beautiful; she was also incredibly intelligent. She could understand and speak the Old Woman's language. Together, they roamed the forest, their adventures akin to those found in the most wondrous of fairy tales.\n",
            "\n",
            "One fateful day, the Evil Sorcerer of the Dark Castle, Zoltar, heard about the Old Woman and her magical pig. He was a greedy man, always looking for power and treasures to add to his hoard. Zoltar decided that the Old Woman's magic and her pig's unique abilities would make a formidable addition to his collection.\n",
            "\n",
            "With a wicked grin, Zoltar set his plan in motion. He cast a spell that made the forest dark and forbidding, making it impossible for anyone to venture in and save the Old Woman. He sent his most loyal henchmen, a trio of shadow beasts, to capture the Old Woman and her pig.\n",
            "\n",
            "The Old Woman, sensing danger, hid herself and Goldylocks in a secret cave deep in the forest. But Zoltar was relentless. The shadow beasts tracked them down, but the Old Woman and Goldylocks were ready. Using their wits and Goldylocks' magical abilities, they outsmarted the beasts and managed to escape.\n",
            "\n",
            "Determined not to be caught, the Old Woman and Goldylocks embarked on a quest to gather allies from the magical creatures of the forest. They traveled through mystical lands, encountering a friendly dragon who could breathe fire, a wise old owl who helped them navigate the densest parts of the forest, and a group of skilled dwarves who taught them the art of crafting magical tools.\n",
            "\n",
            "Together, these allies crafted a powerful amulet that could withstand Zoltar's magic. Armed with the amulet and their newfound friends, the Old Woman and Goldylocks marched towards the Dark Castle.\n",
            "\n",
            "Upon arrival, they confronted Zoltar and his minions. A fierce battle ensued, but with the help of their allies, the Old Woman and Goldylocks emerged victorious. Zoltar was banished, and peace was restored to the land.\n",
            "\n",
            "As a reward for their bravery and the restoration of balance, the Old Woman and Goldylocks were granted three wishes by the grateful villagers. The Old Woman wished for a world where kindness and wisdom reign, and Goldylocks wished for a forest where every creature lived in harmony. And so, the village and the forest flourished under their guidance, and the tale of the Old Woman and her magic pig became a legend, whispered by every child under the stars, reminding them of the power of friendship, courage, and the magic that lies within us all.\n",
            "\n",
            "The end.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 774\n",
            "Lexicon Count: 558\n",
            "Sentence Count: 31\n",
            "Flesch Reading Ease: 70.13\n",
            "Flesch-Kincaid Grade Level: 8.0\n",
            "Gunning Fog: 9.28\n",
            "SMOG Index: 9.5\n",
            "Automated Readability Index: 10.0\n",
            "Coleman-Liau Index: 9.16\n",
            "Linsear Write Formula: 7.0\n",
            "Dale-Chall Readability Score: 7.87\n",
            "Text Standard: 9th and 10th grade\n",
            "Reading Time (seconds): 38.99\n",
            "Responses and readability metrics saved to THE OLD WOMAN AND HER PIG_readability_score.csv, THE OLD WOMAN AND HER PIG_readability_score.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/THE OLD WOMAN AND HER PIG_readability_score.csv')\n",
        "pivot_df = df.pivot(index='model', columns='metric', values='value')\n",
        "\n",
        "pivot_df.reset_index(inplace=True)\n",
        "pivot_df.to_excel('THE OLD WOMAN AND HER PIG.xlsx', index=False)"
      ],
      "metadata": {
        "id": "cEqlJNLtQk3O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sSU2_wxOQ_8F",
        "outputId": "3e3f2feb-c58e-4f8c-a9ab-9ce46bd3ff05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "metric                                   model Automated Readability Index  \\\n",
              "0                     claude-3-haiku@anthropic                         6.5   \n",
              "1                      claude-3-opus@anthropic                         8.7   \n",
              "2                  claude-3.5-sonnet@anthropic                         6.5   \n",
              "3                   gemini-1.5-flash@vertex-ai                         7.5   \n",
              "4                     gemini-1.5-pro@vertex-ai                         7.6   \n",
              "5                   gemma-2-9b-it@fireworks-ai                        10.2   \n",
              "6                      gemma-2b-it@together-ai                         9.5   \n",
              "7                         gpt-3.5-turbo@openai                         9.6   \n",
              "8                           gpt-4-turbo@openai                         8.7   \n",
              "9                                 gpt-4@openai                         6.8   \n",
              "10                               gpt-4o@openai                         8.6   \n",
              "11               llama-3-70b-chat@fireworks-ai                         9.4   \n",
              "12                llama-3-8b-chat@fireworks-ai                         9.5   \n",
              "13        mistral-7b-instruct-v0.3@together-ai                         9.1   \n",
              "14                   mistral-large@aws-bedrock                         7.7   \n",
              "15                    mistral-small@mistral-ai                         8.1   \n",
              "16       mixtral-8x22b-instruct-v0.1@deepinfra                        10.0   \n",
              "17      mixtral-8x7b-instruct-v0.1@aws-bedrock                         8.5   \n",
              "18                               original_text                         5.6   \n",
              "19               qwen-2-72b-instruct@deepinfra                        10.0   \n",
              "\n",
              "metric Coleman-Liau Index Dale-Chall Readability Score Flesch Reading Ease  \\\n",
              "0                    5.28                         6.11               88.06   \n",
              "1                     8.0                         7.75               80.21   \n",
              "2                    6.84                         6.95               82.85   \n",
              "3                    7.88                         7.49                91.0   \n",
              "4                    7.65                          7.2               82.95   \n",
              "5                   10.32                         8.37               73.17   \n",
              "6                    9.16                         8.18                79.7   \n",
              "7                    6.33                         6.92               81.87   \n",
              "8                    8.47                          7.7               80.72   \n",
              "9                    6.78                         6.52               81.63   \n",
              "10                   8.41                         7.23               80.31   \n",
              "11                   8.81                         8.03               70.94   \n",
              "12                   8.41                         7.58               70.23   \n",
              "13                   8.58                         7.27               71.14   \n",
              "14                   8.28                         6.94                74.9   \n",
              "15                   8.81                         7.62               74.19   \n",
              "16                   9.28                         7.32               70.73   \n",
              "17                   6.56                         6.55               85.32   \n",
              "18                   3.88                         0.99               98.25   \n",
              "19                   9.16                         7.87               70.13   \n",
              "\n",
              "metric Flesch-Kincaid Grade Level Gunning Fog Lexicon Count  \\\n",
              "0                             5.2        7.74           426   \n",
              "1                             6.1        8.36           311   \n",
              "2                             5.1        7.66           373   \n",
              "3                             4.1        6.37           436   \n",
              "4                             5.1        6.58           438   \n",
              "5                             6.8         8.0           420   \n",
              "6                             6.3        8.05           371   \n",
              "7                             7.6        9.95           392   \n",
              "8                             6.0        7.53           685   \n",
              "9                             5.6        6.86           464   \n",
              "10                            6.1         8.2           619   \n",
              "11                            7.6        9.07           584   \n",
              "12                            7.9        8.72           590   \n",
              "13                            7.6        8.75           390   \n",
              "14                            6.1         7.3           424   \n",
              "15                            6.4        7.35           365   \n",
              "16                            7.7        8.43           678   \n",
              "17                            6.3        8.81           473   \n",
              "18                            3.4        6.12           687   \n",
              "19                            8.0        9.28           558   \n",
              "\n",
              "metric Linsear Write Formula Reading Time (seconds) SMOG Index Sentence Count  \\\n",
              "0                       13.0                  25.75        8.1             25   \n",
              "1                        8.0                  21.23        8.8             19   \n",
              "2          8.333333333333334                  24.49        8.7             27   \n",
              "3          7.833333333333334                  29.82        6.8             31   \n",
              "4          6.428571428571429                  30.23        8.0             32   \n",
              "5          8.333333333333334                  31.66        9.0             28   \n",
              "6                        7.5                  26.02        8.4             22   \n",
              "7                       10.2                  23.77        7.7             17   \n",
              "8                       13.0                  47.39        7.5             43   \n",
              "9          7.666666666666666                  30.01        7.6             31   \n",
              "10                      12.4                  42.17        9.3             38   \n",
              "11                      11.4                   40.5        9.2             34   \n",
              "12         8.666666666666666                   40.4       10.0             33   \n",
              "13                       8.5                  26.82       10.3             23   \n",
              "14                     6.375                  29.72        8.7             32   \n",
              "15         7.142857142857142                   25.6        8.5             26   \n",
              "16         6.714285714285714                  47.98        8.7             39   \n",
              "17                      10.2                  29.63        8.1             24   \n",
              "18                       4.0                  41.47        3.1             45   \n",
              "19                       7.0                  38.99        9.5             31   \n",
              "\n",
              "metric Syllable Count       Text Standard  \n",
              "0                 531   5th and 6th grade  \n",
              "1                 415   7th and 8th grade  \n",
              "2                 490   6th and 7th grade  \n",
              "3                 543   7th and 8th grade  \n",
              "4                 564   7th and 8th grade  \n",
              "5                 592   8th and 9th grade  \n",
              "6                 497   7th and 8th grade  \n",
              "7                 484  9th and 10th grade  \n",
              "8                 899   7th and 8th grade  \n",
              "9                 598   6th and 7th grade  \n",
              "10                825   8th and 9th grade  \n",
              "11                808   8th and 9th grade  \n",
              "12                801   7th and 8th grade  \n",
              "13                533   8th and 9th grade  \n",
              "14                599   6th and 7th grade  \n",
              "15                499   8th and 9th grade  \n",
              "16                916   7th and 8th grade  \n",
              "17                584   6th and 7th grade  \n",
              "18                779   3rd and 4th grade  \n",
              "19                774  9th and 10th grade  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77aa29d0-558a-4252-bb85-1e3d85af136f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>metric</th>\n",
              "      <th>model</th>\n",
              "      <th>Automated Readability Index</th>\n",
              "      <th>Coleman-Liau Index</th>\n",
              "      <th>Dale-Chall Readability Score</th>\n",
              "      <th>Flesch Reading Ease</th>\n",
              "      <th>Flesch-Kincaid Grade Level</th>\n",
              "      <th>Gunning Fog</th>\n",
              "      <th>Lexicon Count</th>\n",
              "      <th>Linsear Write Formula</th>\n",
              "      <th>Reading Time (seconds)</th>\n",
              "      <th>SMOG Index</th>\n",
              "      <th>Sentence Count</th>\n",
              "      <th>Syllable Count</th>\n",
              "      <th>Text Standard</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>claude-3-haiku@anthropic</td>\n",
              "      <td>6.5</td>\n",
              "      <td>5.28</td>\n",
              "      <td>6.11</td>\n",
              "      <td>88.06</td>\n",
              "      <td>5.2</td>\n",
              "      <td>7.74</td>\n",
              "      <td>426</td>\n",
              "      <td>13.0</td>\n",
              "      <td>25.75</td>\n",
              "      <td>8.1</td>\n",
              "      <td>25</td>\n",
              "      <td>531</td>\n",
              "      <td>5th and 6th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>claude-3-opus@anthropic</td>\n",
              "      <td>8.7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.75</td>\n",
              "      <td>80.21</td>\n",
              "      <td>6.1</td>\n",
              "      <td>8.36</td>\n",
              "      <td>311</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.23</td>\n",
              "      <td>8.8</td>\n",
              "      <td>19</td>\n",
              "      <td>415</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>claude-3.5-sonnet@anthropic</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.84</td>\n",
              "      <td>6.95</td>\n",
              "      <td>82.85</td>\n",
              "      <td>5.1</td>\n",
              "      <td>7.66</td>\n",
              "      <td>373</td>\n",
              "      <td>8.333333333333334</td>\n",
              "      <td>24.49</td>\n",
              "      <td>8.7</td>\n",
              "      <td>27</td>\n",
              "      <td>490</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gemini-1.5-flash@vertex-ai</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7.88</td>\n",
              "      <td>7.49</td>\n",
              "      <td>91.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>6.37</td>\n",
              "      <td>436</td>\n",
              "      <td>7.833333333333334</td>\n",
              "      <td>29.82</td>\n",
              "      <td>6.8</td>\n",
              "      <td>31</td>\n",
              "      <td>543</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gemini-1.5-pro@vertex-ai</td>\n",
              "      <td>7.6</td>\n",
              "      <td>7.65</td>\n",
              "      <td>7.2</td>\n",
              "      <td>82.95</td>\n",
              "      <td>5.1</td>\n",
              "      <td>6.58</td>\n",
              "      <td>438</td>\n",
              "      <td>6.428571428571429</td>\n",
              "      <td>30.23</td>\n",
              "      <td>8.0</td>\n",
              "      <td>32</td>\n",
              "      <td>564</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gemma-2-9b-it@fireworks-ai</td>\n",
              "      <td>10.2</td>\n",
              "      <td>10.32</td>\n",
              "      <td>8.37</td>\n",
              "      <td>73.17</td>\n",
              "      <td>6.8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>420</td>\n",
              "      <td>8.333333333333334</td>\n",
              "      <td>31.66</td>\n",
              "      <td>9.0</td>\n",
              "      <td>28</td>\n",
              "      <td>592</td>\n",
              "      <td>8th and 9th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gemma-2b-it@together-ai</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.16</td>\n",
              "      <td>8.18</td>\n",
              "      <td>79.7</td>\n",
              "      <td>6.3</td>\n",
              "      <td>8.05</td>\n",
              "      <td>371</td>\n",
              "      <td>7.5</td>\n",
              "      <td>26.02</td>\n",
              "      <td>8.4</td>\n",
              "      <td>22</td>\n",
              "      <td>497</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>gpt-3.5-turbo@openai</td>\n",
              "      <td>9.6</td>\n",
              "      <td>6.33</td>\n",
              "      <td>6.92</td>\n",
              "      <td>81.87</td>\n",
              "      <td>7.6</td>\n",
              "      <td>9.95</td>\n",
              "      <td>392</td>\n",
              "      <td>10.2</td>\n",
              "      <td>23.77</td>\n",
              "      <td>7.7</td>\n",
              "      <td>17</td>\n",
              "      <td>484</td>\n",
              "      <td>9th and 10th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>gpt-4-turbo@openai</td>\n",
              "      <td>8.7</td>\n",
              "      <td>8.47</td>\n",
              "      <td>7.7</td>\n",
              "      <td>80.72</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.53</td>\n",
              "      <td>685</td>\n",
              "      <td>13.0</td>\n",
              "      <td>47.39</td>\n",
              "      <td>7.5</td>\n",
              "      <td>43</td>\n",
              "      <td>899</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gpt-4@openai</td>\n",
              "      <td>6.8</td>\n",
              "      <td>6.78</td>\n",
              "      <td>6.52</td>\n",
              "      <td>81.63</td>\n",
              "      <td>5.6</td>\n",
              "      <td>6.86</td>\n",
              "      <td>464</td>\n",
              "      <td>7.666666666666666</td>\n",
              "      <td>30.01</td>\n",
              "      <td>7.6</td>\n",
              "      <td>31</td>\n",
              "      <td>598</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>gpt-4o@openai</td>\n",
              "      <td>8.6</td>\n",
              "      <td>8.41</td>\n",
              "      <td>7.23</td>\n",
              "      <td>80.31</td>\n",
              "      <td>6.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>619</td>\n",
              "      <td>12.4</td>\n",
              "      <td>42.17</td>\n",
              "      <td>9.3</td>\n",
              "      <td>38</td>\n",
              "      <td>825</td>\n",
              "      <td>8th and 9th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>llama-3-70b-chat@fireworks-ai</td>\n",
              "      <td>9.4</td>\n",
              "      <td>8.81</td>\n",
              "      <td>8.03</td>\n",
              "      <td>70.94</td>\n",
              "      <td>7.6</td>\n",
              "      <td>9.07</td>\n",
              "      <td>584</td>\n",
              "      <td>11.4</td>\n",
              "      <td>40.5</td>\n",
              "      <td>9.2</td>\n",
              "      <td>34</td>\n",
              "      <td>808</td>\n",
              "      <td>8th and 9th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>llama-3-8b-chat@fireworks-ai</td>\n",
              "      <td>9.5</td>\n",
              "      <td>8.41</td>\n",
              "      <td>7.58</td>\n",
              "      <td>70.23</td>\n",
              "      <td>7.9</td>\n",
              "      <td>8.72</td>\n",
              "      <td>590</td>\n",
              "      <td>8.666666666666666</td>\n",
              "      <td>40.4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>33</td>\n",
              "      <td>801</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>mistral-7b-instruct-v0.3@together-ai</td>\n",
              "      <td>9.1</td>\n",
              "      <td>8.58</td>\n",
              "      <td>7.27</td>\n",
              "      <td>71.14</td>\n",
              "      <td>7.6</td>\n",
              "      <td>8.75</td>\n",
              "      <td>390</td>\n",
              "      <td>8.5</td>\n",
              "      <td>26.82</td>\n",
              "      <td>10.3</td>\n",
              "      <td>23</td>\n",
              "      <td>533</td>\n",
              "      <td>8th and 9th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mistral-large@aws-bedrock</td>\n",
              "      <td>7.7</td>\n",
              "      <td>8.28</td>\n",
              "      <td>6.94</td>\n",
              "      <td>74.9</td>\n",
              "      <td>6.1</td>\n",
              "      <td>7.3</td>\n",
              "      <td>424</td>\n",
              "      <td>6.375</td>\n",
              "      <td>29.72</td>\n",
              "      <td>8.7</td>\n",
              "      <td>32</td>\n",
              "      <td>599</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>mistral-small@mistral-ai</td>\n",
              "      <td>8.1</td>\n",
              "      <td>8.81</td>\n",
              "      <td>7.62</td>\n",
              "      <td>74.19</td>\n",
              "      <td>6.4</td>\n",
              "      <td>7.35</td>\n",
              "      <td>365</td>\n",
              "      <td>7.142857142857142</td>\n",
              "      <td>25.6</td>\n",
              "      <td>8.5</td>\n",
              "      <td>26</td>\n",
              "      <td>499</td>\n",
              "      <td>8th and 9th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>mixtral-8x22b-instruct-v0.1@deepinfra</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.28</td>\n",
              "      <td>7.32</td>\n",
              "      <td>70.73</td>\n",
              "      <td>7.7</td>\n",
              "      <td>8.43</td>\n",
              "      <td>678</td>\n",
              "      <td>6.714285714285714</td>\n",
              "      <td>47.98</td>\n",
              "      <td>8.7</td>\n",
              "      <td>39</td>\n",
              "      <td>916</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>mixtral-8x7b-instruct-v0.1@aws-bedrock</td>\n",
              "      <td>8.5</td>\n",
              "      <td>6.56</td>\n",
              "      <td>6.55</td>\n",
              "      <td>85.32</td>\n",
              "      <td>6.3</td>\n",
              "      <td>8.81</td>\n",
              "      <td>473</td>\n",
              "      <td>10.2</td>\n",
              "      <td>29.63</td>\n",
              "      <td>8.1</td>\n",
              "      <td>24</td>\n",
              "      <td>584</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>original_text</td>\n",
              "      <td>5.6</td>\n",
              "      <td>3.88</td>\n",
              "      <td>0.99</td>\n",
              "      <td>98.25</td>\n",
              "      <td>3.4</td>\n",
              "      <td>6.12</td>\n",
              "      <td>687</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.47</td>\n",
              "      <td>3.1</td>\n",
              "      <td>45</td>\n",
              "      <td>779</td>\n",
              "      <td>3rd and 4th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>qwen-2-72b-instruct@deepinfra</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.16</td>\n",
              "      <td>7.87</td>\n",
              "      <td>70.13</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.28</td>\n",
              "      <td>558</td>\n",
              "      <td>7.0</td>\n",
              "      <td>38.99</td>\n",
              "      <td>9.5</td>\n",
              "      <td>31</td>\n",
              "      <td>774</td>\n",
              "      <td>9th and 10th grade</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77aa29d0-558a-4252-bb85-1e3d85af136f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77aa29d0-558a-4252-bb85-1e3d85af136f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77aa29d0-558a-4252-bb85-1e3d85af136f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7fbf2645-301f-4944-92f0-1db1d93baef5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fbf2645-301f-4944-92f0-1db1d93baef5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7fbf2645-301f-4944-92f0-1db1d93baef5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_aeab9788-94b8-429a-b6de-87a7d296842c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pivot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_aeab9788-94b8-429a-b6de-87a7d296842c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pivot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pivot_df",
              "summary": "{\n  \"name\": \"pivot_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"claude-3-haiku@anthropic\",\n          \"mixtral-8x7b-instruct-v0.1@aws-bedrock\",\n          \"mistral-small@mistral-ai\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Automated Readability Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"6.5\",\n          \"8.7\",\n          \"9.5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coleman-Liau Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"5.28\",\n          \"8.0\",\n          \"10.32\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dale-Chall Readability Score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"6.11\",\n          \"6.55\",\n          \"7.62\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flesch Reading Ease\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"88.06\",\n          \"85.32\",\n          \"74.19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flesch-Kincaid Grade Level\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"7.9\",\n          \"7.7\",\n          \"5.2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gunning Fog\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"7.74\",\n          \"8.81\",\n          \"7.35\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lexicon Count\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"426\",\n          \"473\",\n          \"365\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Linsear Write Formula\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"13.0\",\n          \"8.0\",\n          \"7.5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading Time (seconds)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"25.75\",\n          \"29.63\",\n          \"25.6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMOG Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"8.1\",\n          \"8.8\",\n          \"9.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence Count\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"25\",\n          \"19\",\n          \"28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Syllable Count\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"531\",\n          \"584\",\n          \"499\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text Standard\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"5th and 6th grade\",\n          \"7th and 8th grade\",\n          \"3rd and 4th grade\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "df = pd.read_csv(\"/content/THE OLD WOMAN AND HER PIG_readability_score.csv\")\n",
        "\n",
        "metric_directions = {\n",
        "    \"Syllable Count\": \"lower\",\n",
        "    \"Lexicon Count\": \"higher\",\n",
        "    \"Sentence Count\": \"higher\",\n",
        "    \"Flesch Reading Ease\": \"higher\",\n",
        "    \"Flesch-Kincaid Grade Level\": \"lower\",\n",
        "    \"Gunning Fog\": \"lower\",\n",
        "    \"SMOG Index\": \"lower\",\n",
        "    \"Automated Readability Index\": \"lower\",\n",
        "    \"Coleman-Liau Index\": \"lower\",\n",
        "    \"Linsear Write Formula\": \"lower\",\n",
        "    \"Dale-Chall Readability Score\": \"lower\",\n",
        "    \"Text Standard\": \"lower\",\n",
        "    \"Reading Time (seconds)\": \"lower\"\n",
        "}\n",
        "\n",
        "pivot_df = df.pivot(index='model', columns='metric', values='value')\n",
        "if 'Text Standard' in pivot_df.columns:\n",
        "    pivot_df = pivot_df.drop(\"Text Standard\", axis=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "normalized_df = pd.DataFrame(scaler.fit_transform(pivot_df), columns=pivot_df.columns, index=pivot_df.index)\n",
        "\n",
        "for metric, direction in metric_directions.items():\n",
        "    if direction == \"lower\" and metric in normalized_df.columns:\n",
        "        normalized_df[metric] = 1 - normalized_df[metric]\n",
        "\n",
        "normalized_df['Composite Score'] = normalized_df.mean(axis=1)\n",
        "original_text_score = normalized_df.loc['original_text', 'Composite Score']\n",
        "\n",
        "# differences from the original text\n",
        "normalized_df['Difference'] = (normalized_df['Composite Score'] - original_text_score).abs()\n",
        "\n",
        "# ranking based on similarity to the original text\n",
        "ranking_df = normalized_df[['Composite Score', 'Difference']].sort_values(by='Difference')\n",
        "ranking_df['Rank'] = ranking_df['Difference'].rank()\n",
        "\n",
        "print(\"Ranking of models based on similarity to the original text:\")\n",
        "print(ranking_df)\n",
        "\n",
        "ranking_df.to_csv(\"model_ranking_based_on_similarity_to_original_text_THE OLD WOMAN AND HER PIG.csv\")\n",
        "\n",
        "# rankings for each metric independently\n",
        "metric_rankings = {}\n",
        "\n",
        "for metric in pivot_df.columns:\n",
        "    metric_rankings[metric] = normalized_df[[metric]].sort_values(by=metric, ascending=False if metric_directions[metric] == \"higher\" else True)\n",
        "    metric_rankings[metric]['Rank'] = metric_rankings[metric][metric].rank(ascending=False if metric_directions[metric] == \"higher\" else True)\n",
        "\n",
        "    print(f\"\\nRanking based on {metric}:\")\n",
        "    print(metric_rankings[metric])\n",
        "\n",
        "    # Save each metric ranking to a CSV file\n",
        "    metric_rankings[metric].to_csv(f\"model_ranking_based_on_{metric}_THE OLD WOMAN AND HER PIG.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjVfY7gURH8b",
        "outputId": "da204d21-7783-4147-fe1a-78330c287aa0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking of models based on similarity to the original text:\n",
            "metric                                  Composite Score  Difference  Rank\n",
            "model                                                                    \n",
            "original_text                                  0.876401    0.000000   1.0\n",
            "gemini-1.5-flash@vertex-ai                     0.577152    0.299249   2.0\n",
            "gpt-4@openai                                   0.538167    0.338235   3.0\n",
            "gemini-1.5-pro@vertex-ai                       0.532818    0.343584   4.0\n",
            "claude-3-haiku@anthropic                       0.517762    0.358639   5.0\n",
            "claude-3.5-sonnet@anthropic                    0.517419    0.358982   6.0\n",
            "mistral-large@aws-bedrock                      0.453210    0.423191   7.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock         0.421134    0.455268   8.0\n",
            "mistral-small@mistral-ai                       0.416541    0.459861   9.0\n",
            "claude-3-opus@anthropic                        0.399360    0.477042  10.0\n",
            "gpt-4-turbo@openai                             0.376292    0.500109  11.0\n",
            "gemma-2b-it@together-ai                        0.369536    0.506866  12.0\n",
            "gpt-4o@openai                                  0.350367    0.526035  13.0\n",
            "gpt-3.5-turbo@openai                           0.342158    0.534243  14.0\n",
            "mistral-7b-instruct-v0.3@together-ai           0.297871    0.578531  15.0\n",
            "gemma-2-9b-it@fireworks-ai                     0.293062    0.583340  16.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra          0.292757    0.583645  17.0\n",
            "llama-3-8b-chat@fireworks-ai                   0.270979    0.605422  18.0\n",
            "qwen-2-72b-instruct@deepinfra                  0.251707    0.624694  19.0\n",
            "llama-3-70b-chat@fireworks-ai                  0.246578    0.629823  20.0\n",
            "\n",
            "Ranking based on Automated Readability Index:\n",
            "metric                                  Automated Readability Index  Rank\n",
            "model                                                                    \n",
            "gemma-2-9b-it@fireworks-ai                                 0.000000   1.0\n",
            "qwen-2-72b-instruct@deepinfra                              0.043478   2.5\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                      0.043478   2.5\n",
            "gpt-3.5-turbo@openai                                       0.130435   4.0\n",
            "gemma-2b-it@together-ai                                    0.152174   5.5\n",
            "llama-3-8b-chat@fireworks-ai                               0.152174   5.5\n",
            "llama-3-70b-chat@fireworks-ai                              0.173913   7.0\n",
            "mistral-7b-instruct-v0.3@together-ai                       0.239130   8.0\n",
            "claude-3-opus@anthropic                                    0.326087   9.5\n",
            "gpt-4-turbo@openai                                         0.326087   9.5\n",
            "gpt-4o@openai                                              0.347826  11.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                     0.369565  12.0\n",
            "mistral-small@mistral-ai                                   0.456522  13.0\n",
            "mistral-large@aws-bedrock                                  0.543478  14.0\n",
            "gemini-1.5-pro@vertex-ai                                   0.565217  15.0\n",
            "gemini-1.5-flash@vertex-ai                                 0.586957  16.0\n",
            "gpt-4@openai                                               0.739130  17.0\n",
            "claude-3.5-sonnet@anthropic                                0.804348  18.5\n",
            "claude-3-haiku@anthropic                                   0.804348  18.5\n",
            "original_text                                              1.000000  20.0\n",
            "\n",
            "Ranking based on Coleman-Liau Index:\n",
            "metric                                  Coleman-Liau Index  Rank\n",
            "model                                                           \n",
            "gemma-2-9b-it@fireworks-ai                        0.000000   1.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra             0.161491   2.0\n",
            "qwen-2-72b-instruct@deepinfra                     0.180124   3.5\n",
            "gemma-2b-it@together-ai                           0.180124   3.5\n",
            "mistral-small@mistral-ai                          0.234472   5.5\n",
            "llama-3-70b-chat@fireworks-ai                     0.234472   5.5\n",
            "mistral-7b-instruct-v0.3@together-ai              0.270186   7.0\n",
            "gpt-4-turbo@openai                                0.287267   8.0\n",
            "gpt-4o@openai                                     0.296584   9.5\n",
            "llama-3-8b-chat@fireworks-ai                      0.296584   9.5\n",
            "mistral-large@aws-bedrock                         0.316770  11.0\n",
            "claude-3-opus@anthropic                           0.360248  12.0\n",
            "gemini-1.5-flash@vertex-ai                        0.378882  13.0\n",
            "gemini-1.5-pro@vertex-ai                          0.414596  14.0\n",
            "claude-3.5-sonnet@anthropic                       0.540373  15.0\n",
            "gpt-4@openai                                      0.549689  16.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock            0.583851  17.0\n",
            "gpt-3.5-turbo@openai                              0.619565  18.0\n",
            "claude-3-haiku@anthropic                          0.782609  19.0\n",
            "original_text                                     1.000000  20.0\n",
            "\n",
            "Ranking based on Dale-Chall Readability Score:\n",
            "metric                                  Dale-Chall Readability Score  Rank\n",
            "model                                                                     \n",
            "gemma-2-9b-it@fireworks-ai                                  0.000000   1.0\n",
            "gemma-2b-it@together-ai                                     0.025745   2.0\n",
            "llama-3-70b-chat@fireworks-ai                               0.046070   3.0\n",
            "qwen-2-72b-instruct@deepinfra                               0.067751   4.0\n",
            "claude-3-opus@anthropic                                     0.084011   5.0\n",
            "gpt-4-turbo@openai                                          0.090786   6.0\n",
            "mistral-small@mistral-ai                                    0.101626   7.0\n",
            "llama-3-8b-chat@fireworks-ai                                0.107046   8.0\n",
            "gemini-1.5-flash@vertex-ai                                  0.119241   9.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                       0.142276  10.0\n",
            "mistral-7b-instruct-v0.3@together-ai                        0.149051  11.0\n",
            "gpt-4o@openai                                               0.154472  12.0\n",
            "gemini-1.5-pro@vertex-ai                                    0.158537  13.0\n",
            "claude-3.5-sonnet@anthropic                                 0.192412  14.0\n",
            "mistral-large@aws-bedrock                                   0.193767  15.0\n",
            "gpt-3.5-turbo@openai                                        0.196477  16.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                      0.246612  17.0\n",
            "gpt-4@openai                                                0.250678  18.0\n",
            "claude-3-haiku@anthropic                                    0.306233  19.0\n",
            "original_text                                               1.000000  20.0\n",
            "\n",
            "Ranking based on Flesch Reading Ease:\n",
            "metric                                  Flesch Reading Ease  Rank\n",
            "model                                                            \n",
            "original_text                                      1.000000   1.0\n",
            "gemini-1.5-flash@vertex-ai                         0.742176   2.0\n",
            "claude-3-haiku@anthropic                           0.637624   3.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock             0.540185   4.0\n",
            "gemini-1.5-pro@vertex-ai                           0.455903   5.0\n",
            "claude-3.5-sonnet@anthropic                        0.452347   6.0\n",
            "gpt-3.5-turbo@openai                               0.417496   7.0\n",
            "gpt-4@openai                                       0.408962   8.0\n",
            "gpt-4-turbo@openai                                 0.376600   9.0\n",
            "gpt-4o@openai                                      0.362020  10.0\n",
            "claude-3-opus@anthropic                            0.358464  11.0\n",
            "gemma-2b-it@together-ai                            0.340327  12.0\n",
            "mistral-large@aws-bedrock                          0.169630  13.0\n",
            "mistral-small@mistral-ai                           0.144381  14.0\n",
            "gemma-2-9b-it@fireworks-ai                         0.108108  15.0\n",
            "mistral-7b-instruct-v0.3@together-ai               0.035917  16.0\n",
            "llama-3-70b-chat@fireworks-ai                      0.028805  17.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra              0.021337  18.0\n",
            "llama-3-8b-chat@fireworks-ai                       0.003556  19.0\n",
            "qwen-2-72b-instruct@deepinfra                      0.000000  20.0\n",
            "\n",
            "Ranking based on Flesch-Kincaid Grade Level:\n",
            "metric                                  Flesch-Kincaid Grade Level  Rank\n",
            "model                                                                   \n",
            "qwen-2-72b-instruct@deepinfra                             0.000000   1.0\n",
            "llama-3-8b-chat@fireworks-ai                              0.021739   2.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                     0.065217   3.0\n",
            "gpt-3.5-turbo@openai                                      0.086957   5.0\n",
            "llama-3-70b-chat@fireworks-ai                             0.086957   5.0\n",
            "mistral-7b-instruct-v0.3@together-ai                      0.086957   5.0\n",
            "gemma-2-9b-it@fireworks-ai                                0.260870   7.0\n",
            "mistral-small@mistral-ai                                  0.347826   8.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                    0.369565   9.5\n",
            "gemma-2b-it@together-ai                                   0.369565   9.5\n",
            "claude-3-opus@anthropic                                   0.413043  12.0\n",
            "mistral-large@aws-bedrock                                 0.413043  12.0\n",
            "gpt-4o@openai                                             0.413043  12.0\n",
            "gpt-4-turbo@openai                                        0.434783  14.0\n",
            "gpt-4@openai                                              0.521739  15.0\n",
            "claude-3-haiku@anthropic                                  0.608696  16.0\n",
            "gemini-1.5-pro@vertex-ai                                  0.630435  17.5\n",
            "claude-3.5-sonnet@anthropic                               0.630435  17.5\n",
            "gemini-1.5-flash@vertex-ai                                0.847826  19.0\n",
            "original_text                                             1.000000  20.0\n",
            "\n",
            "Ranking based on Gunning Fog:\n",
            "metric                                  Gunning Fog  Rank\n",
            "model                                                    \n",
            "gpt-3.5-turbo@openai                       0.000000   1.0\n",
            "qwen-2-72b-instruct@deepinfra              0.174935   2.0\n",
            "llama-3-70b-chat@fireworks-ai              0.229765   3.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock     0.297650   4.0\n",
            "mistral-7b-instruct-v0.3@together-ai       0.313316   5.0\n",
            "llama-3-8b-chat@fireworks-ai               0.321149   6.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra      0.396867   7.0\n",
            "claude-3-opus@anthropic                    0.415144   8.0\n",
            "gpt-4o@openai                              0.456919   9.0\n",
            "gemma-2b-it@together-ai                    0.496084  10.0\n",
            "gemma-2-9b-it@fireworks-ai                 0.509138  11.0\n",
            "claude-3-haiku@anthropic                   0.577023  12.0\n",
            "claude-3.5-sonnet@anthropic                0.597911  13.0\n",
            "gpt-4-turbo@openai                         0.631854  14.0\n",
            "mistral-small@mistral-ai                   0.678851  15.0\n",
            "mistral-large@aws-bedrock                  0.691906  16.0\n",
            "gpt-4@openai                               0.806789  17.0\n",
            "gemini-1.5-pro@vertex-ai                   0.879896  18.0\n",
            "gemini-1.5-flash@vertex-ai                 0.934726  19.0\n",
            "original_text                              1.000000  20.0\n",
            "\n",
            "Ranking based on Lexicon Count:\n",
            "metric                                  Lexicon Count  Rank\n",
            "model                                                      \n",
            "original_text                                1.000000   1.0\n",
            "gpt-4-turbo@openai                           0.994681   2.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra        0.976064   3.0\n",
            "gpt-4o@openai                                0.819149   4.0\n",
            "llama-3-8b-chat@fireworks-ai                 0.742021   5.0\n",
            "llama-3-70b-chat@fireworks-ai                0.726064   6.0\n",
            "qwen-2-72b-instruct@deepinfra                0.656915   7.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock       0.430851   8.0\n",
            "gpt-4@openai                                 0.406915   9.0\n",
            "gemini-1.5-pro@vertex-ai                     0.337766  10.0\n",
            "gemini-1.5-flash@vertex-ai                   0.332447  11.0\n",
            "claude-3-haiku@anthropic                     0.305851  12.0\n",
            "mistral-large@aws-bedrock                    0.300532  13.0\n",
            "gemma-2-9b-it@fireworks-ai                   0.289894  14.0\n",
            "gpt-3.5-turbo@openai                         0.215426  15.0\n",
            "mistral-7b-instruct-v0.3@together-ai         0.210106  16.0\n",
            "claude-3.5-sonnet@anthropic                  0.164894  17.0\n",
            "gemma-2b-it@together-ai                      0.159574  18.0\n",
            "mistral-small@mistral-ai                     0.143617  19.0\n",
            "claude-3-opus@anthropic                      0.000000  20.0\n",
            "\n",
            "Ranking based on Linsear Write Formula:\n",
            "metric                                  Linsear Write Formula  Rank\n",
            "model                                                              \n",
            "claude-3-haiku@anthropic                             0.000000   1.5\n",
            "gpt-4-turbo@openai                                   0.000000   1.5\n",
            "gpt-4o@openai                                        0.066667   3.0\n",
            "llama-3-70b-chat@fireworks-ai                        0.177778   4.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock               0.311111   5.5\n",
            "gpt-3.5-turbo@openai                                 0.311111   5.5\n",
            "llama-3-8b-chat@fireworks-ai                         0.481481   7.0\n",
            "mistral-7b-instruct-v0.3@together-ai                 0.500000   8.0\n",
            "claude-3.5-sonnet@anthropic                          0.518519   9.5\n",
            "gemma-2-9b-it@fireworks-ai                           0.518519   9.5\n",
            "claude-3-opus@anthropic                              0.555556  11.0\n",
            "gemini-1.5-flash@vertex-ai                           0.574074  12.0\n",
            "gpt-4@openai                                         0.592593  13.0\n",
            "gemma-2b-it@together-ai                              0.611111  14.0\n",
            "mistral-small@mistral-ai                             0.650794  15.0\n",
            "qwen-2-72b-instruct@deepinfra                        0.666667  16.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                0.698413  17.0\n",
            "gemini-1.5-pro@vertex-ai                             0.730159  18.0\n",
            "mistral-large@aws-bedrock                            0.736111  19.0\n",
            "original_text                                        1.000000  20.0\n",
            "\n",
            "Ranking based on Reading Time (seconds):\n",
            "metric                                  Reading Time (seconds)  Rank\n",
            "model                                                               \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                 0.000000   1.0\n",
            "gpt-4-turbo@openai                                    0.022056   2.0\n",
            "gpt-4o@openai                                         0.217196   3.0\n",
            "original_text                                         0.243364   4.0\n",
            "llama-3-70b-chat@fireworks-ai                         0.279626   5.0\n",
            "llama-3-8b-chat@fireworks-ai                          0.283364   6.0\n",
            "qwen-2-72b-instruct@deepinfra                         0.336075   7.0\n",
            "gemma-2-9b-it@fireworks-ai                            0.610093   8.0\n",
            "gemini-1.5-pro@vertex-ai                              0.663551   9.0\n",
            "gpt-4@openai                                          0.671776  10.0\n",
            "gemini-1.5-flash@vertex-ai                            0.678879  11.0\n",
            "mistral-large@aws-bedrock                             0.682617  12.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                0.685981  13.0\n",
            "mistral-7b-instruct-v0.3@together-ai                  0.791028  14.0\n",
            "gemma-2b-it@together-ai                               0.820935  15.0\n",
            "claude-3-haiku@anthropic                              0.831028  16.0\n",
            "mistral-small@mistral-ai                              0.836636  17.0\n",
            "claude-3.5-sonnet@anthropic                           0.878131  18.0\n",
            "gpt-3.5-turbo@openai                                  0.905047  19.0\n",
            "claude-3-opus@anthropic                               1.000000  20.0\n",
            "\n",
            "Ranking based on SMOG Index:\n",
            "metric                                    SMOG Index  Rank\n",
            "model                                                     \n",
            "mistral-7b-instruct-v0.3@together-ai    2.220446e-16   1.0\n",
            "llama-3-8b-chat@fireworks-ai            4.166667e-02   2.0\n",
            "qwen-2-72b-instruct@deepinfra           1.111111e-01   3.0\n",
            "gpt-4o@openai                           1.388889e-01   4.0\n",
            "llama-3-70b-chat@fireworks-ai           1.527778e-01   5.0\n",
            "gemma-2-9b-it@fireworks-ai              1.805556e-01   6.0\n",
            "claude-3-opus@anthropic                 2.083333e-01   7.0\n",
            "claude-3.5-sonnet@anthropic             2.222222e-01   9.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra   2.222222e-01   9.0\n",
            "mistral-large@aws-bedrock               2.222222e-01   9.0\n",
            "mistral-small@mistral-ai                2.500000e-01  11.0\n",
            "gemma-2b-it@together-ai                 2.638889e-01  12.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock  3.055556e-01  13.5\n",
            "claude-3-haiku@anthropic                3.055556e-01  13.5\n",
            "gemini-1.5-pro@vertex-ai                3.194444e-01  15.0\n",
            "gpt-3.5-turbo@openai                    3.611111e-01  16.0\n",
            "gpt-4@openai                            3.750000e-01  17.0\n",
            "gpt-4-turbo@openai                      3.888889e-01  18.0\n",
            "gemini-1.5-flash@vertex-ai              4.861111e-01  19.0\n",
            "original_text                           1.000000e+00  20.0\n",
            "\n",
            "Ranking based on Sentence Count:\n",
            "metric                                  Sentence Count  Rank\n",
            "model                                                       \n",
            "original_text                                 1.000000   1.0\n",
            "gpt-4-turbo@openai                            0.928571   2.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra         0.785714   3.0\n",
            "gpt-4o@openai                                 0.750000   4.0\n",
            "llama-3-70b-chat@fireworks-ai                 0.607143   5.0\n",
            "llama-3-8b-chat@fireworks-ai                  0.571429   6.0\n",
            "gemini-1.5-pro@vertex-ai                      0.535714   7.5\n",
            "mistral-large@aws-bedrock                     0.535714   7.5\n",
            "gpt-4@openai                                  0.500000  10.0\n",
            "qwen-2-72b-instruct@deepinfra                 0.500000  10.0\n",
            "gemini-1.5-flash@vertex-ai                    0.500000  10.0\n",
            "gemma-2-9b-it@fireworks-ai                    0.392857  12.0\n",
            "claude-3.5-sonnet@anthropic                   0.357143  13.0\n",
            "mistral-small@mistral-ai                      0.321429  14.0\n",
            "claude-3-haiku@anthropic                      0.285714  15.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock        0.250000  16.0\n",
            "mistral-7b-instruct-v0.3@together-ai          0.214286  17.0\n",
            "gemma-2b-it@together-ai                       0.178571  18.0\n",
            "claude-3-opus@anthropic                       0.071429  19.0\n",
            "gpt-3.5-turbo@openai                          0.000000  20.0\n",
            "\n",
            "Ranking based on Syllable Count:\n",
            "metric                                  Syllable Count  Rank\n",
            "model                                                       \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra         0.000000   1.0\n",
            "gpt-4-turbo@openai                            0.033932   2.0\n",
            "gpt-4o@openai                                 0.181637   3.0\n",
            "llama-3-70b-chat@fireworks-ai                 0.215569   4.0\n",
            "llama-3-8b-chat@fireworks-ai                  0.229541   5.0\n",
            "original_text                                 0.273453   6.0\n",
            "qwen-2-72b-instruct@deepinfra                 0.283433   7.0\n",
            "mistral-large@aws-bedrock                     0.632735   8.0\n",
            "gpt-4@openai                                  0.634731   9.0\n",
            "gemma-2-9b-it@fireworks-ai                    0.646707  10.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock        0.662675  11.0\n",
            "gemini-1.5-pro@vertex-ai                      0.702595  12.0\n",
            "gemini-1.5-flash@vertex-ai                    0.744511  13.0\n",
            "mistral-7b-instruct-v0.3@together-ai          0.764471  14.0\n",
            "claude-3-haiku@anthropic                      0.768463  15.0\n",
            "mistral-small@mistral-ai                      0.832335  16.0\n",
            "gemma-2b-it@together-ai                       0.836327  17.0\n",
            "claude-3.5-sonnet@anthropic                   0.850299  18.0\n",
            "gpt-3.5-turbo@openai                          0.862275  19.0\n",
            "claude-3-opus@anthropic                       1.000000  20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/THE OLD WOMAN AND HER PIG_readability_score.csv\")\n",
        "\n",
        "metric_groups = {\n",
        "    \"Count Metrics\": {\n",
        "        \"metrics\": [\"Lexicon Count\", \"Sentence Count\"],\n",
        "        \"direction\": \"higher\"\n",
        "    },\n",
        "    \"Ease of Reading Metrics\": {\n",
        "        \"metrics\": [\"Flesch Reading Ease\"],\n",
        "        \"direction\": \"higher\"\n",
        "    },\n",
        "    \"Grade Level Metrics\": {\n",
        "        \"metrics\": [\n",
        "            \"Flesch-Kincaid Grade Level\", \"Gunning Fog\", \"SMOG Index\",\n",
        "            \"Automated Readability Index\", \"Coleman-Liau Index\",\n",
        "            \"Linsear Write Formula\", \"Dale-Chall Readability Score\"\n",
        "        ],\n",
        "        \"direction\": \"lower\"\n",
        "    },\n",
        "    \"Time Metrics\": {\n",
        "        \"metrics\": [\"Reading Time (seconds)\"],\n",
        "        \"direction\": \"lower\"\n",
        "    },\n",
        "    \"Syllable Count Metrics\": {\n",
        "        \"metrics\": [\"Syllable Count\"],\n",
        "        \"direction\": \"lower\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "pivot_df = df.pivot(index='model', columns='metric', values='value')\n",
        "pivot_df = pivot_df.drop(columns=['Text Standard'], errors='ignore')\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "normalized_df = pd.DataFrame(scaler.fit_transform(pivot_df), columns=pivot_df.columns, index=pivot_df.index)\n",
        "\n",
        "group_composite_scores = {}\n",
        "for group_name, group_info in metric_groups.items():\n",
        "    group_metrics = group_info[\"metrics\"]\n",
        "    direction = group_info[\"direction\"]\n",
        "\n",
        "    group_metrics = [metric for metric in group_metrics if metric in normalized_df.columns]\n",
        "    group_df = normalized_df[group_metrics]\n",
        "\n",
        "    if direction == \"lower\":\n",
        "        group_df = 1 - group_df\n",
        "\n",
        "    group_composite_scores[group_name] = group_df.mean(axis=1)\n",
        "\n",
        "\n",
        "composite_scores_df = pd.DataFrame(group_composite_scores)\n",
        "# the overall composite score as the mean of group composite scores\n",
        "composite_scores_df[\"Composite Score\"] = composite_scores_df.mean(axis=1)\n",
        "\n",
        "# the difference from the original text's composite score\n",
        "original_text_score = composite_scores_df.loc['original_text', 'Composite Score']\n",
        "composite_scores_df['Difference'] = (composite_scores_df['Composite Score'] - original_text_score).abs()\n",
        "\n",
        "composite_scores_df['Rank'] = composite_scores_df['Difference'].rank()\n",
        "composite_scores_df = composite_scores_df.sort_values(by='Rank')\n",
        "composite_scores_df = pd.concat([composite_scores_df.loc[['original_text']], composite_scores_df.drop(['original_text'])])\n",
        "\n",
        "print(composite_scores_df)\n",
        "composite_scores_df.to_csv(\"grouped_composite_scores_with_difference_and_rank_THE OLD WOMAN AND HER PIG.csv\")\n",
        "\n",
        "fig = px.bar(\n",
        "    composite_scores_df,\n",
        "    x=composite_scores_df.index,\n",
        "    y='Difference',\n",
        "    title=\"Comparison of Models by Similarity to the Original 'THE OLD WOMAN AND HER PIG' Text\",\n",
        "    labels={'Difference': 'Composite Score Difference'},\n",
        "    hover_data={'Rank': True},\n",
        "    text='Rank',\n",
        "    color='Rank',\n",
        "    color_continuous_scale=px.colors.sequential.Viridis\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Model',\n",
        "    yaxis_title='Composite Score Difference',\n",
        "    xaxis_tickangle=45,\n",
        "    showlegend=False,\n",
        "    plot_bgcolor='white'\n",
        ")\n",
        "\n",
        "fig.update_layout(title_font_size=24, title_x=0.5)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6pWQz7UmRW7S",
        "outputId": "79a15df4-56df-4164-ec25-d4ec30a7a942"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        Count Metrics  \\\n",
            "model                                                   \n",
            "original_text                                1.000000   \n",
            "gemini-1.5-flash@vertex-ai                   0.416223   \n",
            "claude-3-haiku@anthropic                     0.295783   \n",
            "claude-3.5-sonnet@anthropic                  0.261018   \n",
            "gemini-1.5-pro@vertex-ai                     0.436740   \n",
            "claude-3-opus@anthropic                      0.035714   \n",
            "gpt-4@openai                                 0.453457   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock       0.340426   \n",
            "gpt-3.5-turbo@openai                         0.107713   \n",
            "gemma-2b-it@together-ai                      0.169073   \n",
            "mistral-small@mistral-ai                     0.232523   \n",
            "mistral-large@aws-bedrock                    0.418123   \n",
            "mistral-7b-instruct-v0.3@together-ai         0.212196   \n",
            "gemma-2-9b-it@fireworks-ai                   0.341375   \n",
            "gpt-4o@openai                                0.784574   \n",
            "gpt-4-turbo@openai                           0.961626   \n",
            "llama-3-8b-chat@fireworks-ai                 0.656725   \n",
            "qwen-2-72b-instruct@deepinfra                0.578457   \n",
            "llama-3-70b-chat@fireworks-ai                0.666603   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra        0.880889   \n",
            "\n",
            "                                        Ease of Reading Metrics  \\\n",
            "model                                                             \n",
            "original_text                                          1.000000   \n",
            "gemini-1.5-flash@vertex-ai                             0.742176   \n",
            "claude-3-haiku@anthropic                               0.637624   \n",
            "claude-3.5-sonnet@anthropic                            0.452347   \n",
            "gemini-1.5-pro@vertex-ai                               0.455903   \n",
            "claude-3-opus@anthropic                                0.358464   \n",
            "gpt-4@openai                                           0.408962   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                 0.540185   \n",
            "gpt-3.5-turbo@openai                                   0.417496   \n",
            "gemma-2b-it@together-ai                                0.340327   \n",
            "mistral-small@mistral-ai                               0.144381   \n",
            "mistral-large@aws-bedrock                              0.169630   \n",
            "mistral-7b-instruct-v0.3@together-ai                   0.035917   \n",
            "gemma-2-9b-it@fireworks-ai                             0.108108   \n",
            "gpt-4o@openai                                          0.362020   \n",
            "gpt-4-turbo@openai                                     0.376600   \n",
            "llama-3-8b-chat@fireworks-ai                           0.003556   \n",
            "qwen-2-72b-instruct@deepinfra                          0.000000   \n",
            "llama-3-70b-chat@fireworks-ai                          0.028805   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                  0.021337   \n",
            "\n",
            "                                        Grade Level Metrics  Time Metrics  \\\n",
            "model                                                                       \n",
            "original_text                                      1.000000      0.243364   \n",
            "gemini-1.5-flash@vertex-ai                         0.561117      0.678879   \n",
            "claude-3-haiku@anthropic                           0.483495      0.831028   \n",
            "claude-3.5-sonnet@anthropic                        0.500888      0.878131   \n",
            "gemini-1.5-pro@vertex-ai                           0.528326      0.663551   \n",
            "claude-3-opus@anthropic                            0.337489      1.000000   \n",
            "gpt-4@openai                                       0.547945      0.671776   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock             0.354844      0.685981   \n",
            "gpt-3.5-turbo@openai                               0.243665      0.905047   \n",
            "gemma-2b-it@together-ai                            0.299813      0.820935   \n",
            "mistral-small@mistral-ai                           0.388584      0.836636   \n",
            "mistral-large@aws-bedrock                          0.445328      0.682617   \n",
            "mistral-7b-instruct-v0.3@together-ai               0.222663      0.791028   \n",
            "gemma-2-9b-it@fireworks-ai                         0.209869      0.610093   \n",
            "gpt-4o@openai                                      0.267771      0.217196   \n",
            "gpt-4-turbo@openai                                 0.308524      0.022056   \n",
            "llama-3-8b-chat@fireworks-ai                       0.203120      0.283364   \n",
            "qwen-2-72b-instruct@deepinfra                      0.177724      0.336075   \n",
            "llama-3-70b-chat@fireworks-ai                      0.157390      0.279626   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra              0.247138      0.000000   \n",
            "\n",
            "                                        Syllable Count Metrics  \\\n",
            "model                                                            \n",
            "original_text                                         0.273453   \n",
            "gemini-1.5-flash@vertex-ai                            0.744511   \n",
            "claude-3-haiku@anthropic                              0.768463   \n",
            "claude-3.5-sonnet@anthropic                           0.850299   \n",
            "gemini-1.5-pro@vertex-ai                              0.702595   \n",
            "claude-3-opus@anthropic                               1.000000   \n",
            "gpt-4@openai                                          0.634731   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                0.662675   \n",
            "gpt-3.5-turbo@openai                                  0.862275   \n",
            "gemma-2b-it@together-ai                               0.836327   \n",
            "mistral-small@mistral-ai                              0.832335   \n",
            "mistral-large@aws-bedrock                             0.632735   \n",
            "mistral-7b-instruct-v0.3@together-ai                  0.764471   \n",
            "gemma-2-9b-it@fireworks-ai                            0.646707   \n",
            "gpt-4o@openai                                         0.181637   \n",
            "gpt-4-turbo@openai                                    0.033932   \n",
            "llama-3-8b-chat@fireworks-ai                          0.229541   \n",
            "qwen-2-72b-instruct@deepinfra                         0.283433   \n",
            "llama-3-70b-chat@fireworks-ai                         0.215569   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                 0.000000   \n",
            "\n",
            "                                        Composite Score  Difference  Rank  \n",
            "model                                                                      \n",
            "original_text                                  0.703364    0.000000   1.0  \n",
            "gemini-1.5-flash@vertex-ai                     0.628581    0.074782   2.0  \n",
            "claude-3-haiku@anthropic                       0.603279    0.100085   3.0  \n",
            "claude-3.5-sonnet@anthropic                    0.588537    0.114827   4.0  \n",
            "gemini-1.5-pro@vertex-ai                       0.557423    0.145940   5.0  \n",
            "claude-3-opus@anthropic                        0.546333    0.157030   6.0  \n",
            "gpt-4@openai                                   0.543374    0.159989   7.0  \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock         0.516822    0.186541   8.0  \n",
            "gpt-3.5-turbo@openai                           0.507239    0.196124   9.0  \n",
            "gemma-2b-it@together-ai                        0.493295    0.210068  10.0  \n",
            "mistral-small@mistral-ai                       0.486892    0.216472  11.0  \n",
            "mistral-large@aws-bedrock                      0.469687    0.233677  12.0  \n",
            "mistral-7b-instruct-v0.3@together-ai           0.405255    0.298108  13.0  \n",
            "gemma-2-9b-it@fireworks-ai                     0.383230    0.320133  14.0  \n",
            "gpt-4o@openai                                  0.362640    0.340724  15.0  \n",
            "gpt-4-turbo@openai                             0.340548    0.362816  16.0  \n",
            "llama-3-8b-chat@fireworks-ai                   0.275261    0.428102  17.0  \n",
            "qwen-2-72b-instruct@deepinfra                  0.275138    0.428226  18.0  \n",
            "llama-3-70b-chat@fireworks-ai                  0.269599    0.433765  19.0  \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra          0.229873    0.473491  20.0  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5e14120b-7eb4-4e72-b23e-984ba1d45f92\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5e14120b-7eb4-4e72-b23e-984ba1d45f92\")) {                    Plotly.newPlot(                        \"5e14120b-7eb4-4e72-b23e-984ba1d45f92\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[1.0],[2.0],[3.0],[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0],[11.0],[12.0],[13.0],[14.0],[15.0],[16.0],[17.0],[18.0],[19.0],[20.0]],\"hovertemplate\":\"model=%{x}\\u003cbr\\u003eComposite Score Difference=%{y}\\u003cbr\\u003eRank=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0],\"textposition\":\"auto\",\"x\":[\"original_text\",\"gemini-1.5-flash@vertex-ai\",\"claude-3-haiku@anthropic\",\"claude-3.5-sonnet@anthropic\",\"gemini-1.5-pro@vertex-ai\",\"claude-3-opus@anthropic\",\"gpt-4@openai\",\"mixtral-8x7b-instruct-v0.1@aws-bedrock\",\"gpt-3.5-turbo@openai\",\"gemma-2b-it@together-ai\",\"mistral-small@mistral-ai\",\"mistral-large@aws-bedrock\",\"mistral-7b-instruct-v0.3@together-ai\",\"gemma-2-9b-it@fireworks-ai\",\"gpt-4o@openai\",\"gpt-4-turbo@openai\",\"llama-3-8b-chat@fireworks-ai\",\"qwen-2-72b-instruct@deepinfra\",\"llama-3-70b-chat@fireworks-ai\",\"mixtral-8x22b-instruct-v0.1@deepinfra\"],\"xaxis\":\"x\",\"y\":[0.0,0.0747823233978262,0.10008488571447538,0.11482671267852196,0.1459403443249211,0.15703013589269443,0.15998938521045836,0.18654135826389917,0.19612421814059178,0.21006847427691533,0.2164716657000732,0.23367693102444576,0.298108396194811,0.320133037381147,0.34072376815209293,0.36281586817975625,0.4281022145429929,0.42822571327649495,0.43376474143450616,0.473490721387558],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Model\"},\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Composite Score Difference\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Rank\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Comparison of Models by Similarity to the Original 'THE OLD WOMAN AND HER PIG' Text\",\"font\":{\"size\":24},\"x\":0.5},\"barmode\":\"relative\",\"showlegend\":false,\"plot_bgcolor\":\"white\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5e14120b-7eb4-4e72-b23e-984ba1d45f92');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}