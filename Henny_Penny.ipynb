{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta1sZXjuC5Rn",
        "outputId": "e297eb8e-4d32-4505-ab18-bafaf975c441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unifyai in /usr/local/lib/python3.10/dist-packages (0.8.6)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from unifyai) (1.39.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from unifyai) (2.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai) (2024.7.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.12.0->unifyai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.12.0->unifyai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.12.0->unifyai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.12.0->unifyai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.12.0->unifyai) (2.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install unifyai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rQRy_4kDCvj",
        "outputId": "44d0d675-b19b-45c1-e0bd-79c003019e98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csWaWCevDFWL",
        "outputId": "e1e2de47-cadb-43c6-972b-d98edaa55546"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.4)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (71.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from unify import Unify\n",
        "import pandas as pd\n",
        "import textstat\n",
        "\n",
        "os.environ[\"UNIFY_KEY\"] = \"zgZRC0qqOC89cjdiDq403mtdgp-n8ULnQjK6JMiS2YE=\"\n",
        "\n",
        "def generate_response(model_name, prompt, temperature=0.7):\n",
        "    unify = Unify(model_name)\n",
        "    response = unify.generate(\n",
        "        prompt,\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return response\n",
        "\n",
        "models = [\n",
        "    \"claude-3-haiku@anthropic\",\n",
        "    \"claude-3-opus@anthropic\",\n",
        "    \"claude-3.5-sonnet@anthropic\",\n",
        "    \"gemini-1.5-flash@vertex-ai\",\n",
        "    \"gemini-1.5-pro@vertex-ai\",\n",
        "    \"gemma-2-9b-it@fireworks-ai\",\n",
        "    \"gemma-2b-it@together-ai\",\n",
        "    \"gpt-3.5-turbo@openai\",\n",
        "    \"gpt-4@openai\",\n",
        "    \"gpt-4-turbo@openai\",\n",
        "    \"gpt-4o@openai\",\n",
        "    \"llama-3-70b-chat@fireworks-ai\",\n",
        "    \"llama-3-8b-chat@fireworks-ai\",\n",
        "    \"mistral-7b-instruct-v0.3@together-ai\",\n",
        "    \"mistral-large@aws-bedrock\",\n",
        "    \"mistral-small@mistral-ai\",\n",
        "    \"mixtral-8x22b-instruct-v0.1@deepinfra\",\n",
        "    \"mixtral-8x7b-instruct-v0.1@aws-bedrock\",\n",
        "    \"qwen-2-72b-instruct@deepinfra\"\n",
        "]\n",
        "\n",
        "prompt = \"You are a fairy tale author. Write a fairy tale about Henny-Penny\"\n",
        "\n",
        "\n",
        "original_text = \"\"\"\n",
        "One day Henny-penny was picking up corn in the cornyard when—whack!—something hit her upon the head. \"Goodness gracious me!\" said Henny-penny; \"the sky's a-going to fall; I must go and tell the king.\"\n",
        "So she went along, and she went along, and she went along till she met Cocky-locky. \"Where are you going, Henny-penny?\" says Cocky-locky. \"Oh! I'm going to tell the king the sky's a-falling,\" says Henny-penny. \"May I come with you?\" says Cocky-locky. \"Certainly,\" says Henny-penny. So Henny-penny and Cocky-locky went to tell the king the sky was a-falling.\n",
        "They went along, and they went along, and they went along, till they met Ducky-daddles. \"Where are you going to, Henny-penny and Cocky-locky?\" says Ducky-daddles. \"Oh! we're going to tell the king the sky's a-falling,\" said Henny-penny and Cocky-locky. \"May I come with you?\" says Ducky-daddles. \"Certainly,\" said Henny-penny and Cocky-locky. So Henny-penny, Cocky-locky, and Ducky-daddles went to tell the king the sky was a-falling.\n",
        "So they went along, and they went along, and they went along, till they met Goosey-poosey. \"Where are you going to, Henny-penny, Cocky-locky, and Ducky-daddles?\" said Goosey-poosey. \"Oh! we're going to tell the king the sky's a-falling,\" said Henny-penny and Cocky-locky and Ducky-daddles. \"May I come with you?\" said Goosey-poosey. \"Certainly,\" said Henny-penny, Cocky-locky, and Ducky-daddles. So Henny-penny, Cocky-locky, Ducky-daddles, and Goosey-poosey went to tell the king the sky was a-falling.\n",
        "So they went along, and they went along, and they went along, till they met Turkey-lurkey. \"Where are you going, Henny-penny, Cocky-locky, Ducky-daddles, and Goosey-poosey?\" says Turkey-lurkey. \"Oh! we're going to tell the king the sky's a-falling,\" said Henny-penny, Cocky-locky, Ducky-daddles, and Goosey-poosey. \"May I come with you, Henny-penny, Cocky-locky, Ducky-daddles, and Goosey-poosey?\" said Turkey-lurkey. \"Oh, certainly, Turkey-lurkey,\" said Henny-penny, Cocky-locky, Ducky-daddles, and Goosey-poosey. So Henny-penny, Cocky-locky, Ducky-[59]daddles, Goosey-poosey, and Turkey-lurkey all went to tell the king the sky was a-falling.\n",
        "So they went along, and they went along, and they went along, till they met Foxy-woxy, and Foxy-woxy said to Henny-penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey: \"Where are you going, Henny-penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey?\" And Henny-penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey said to Foxy-woxy: \"We're going to tell the king the sky's a-falling.\" \"Oh! but this is not the way to the king, Henny-penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey,\" says Foxy-woxy; \"I know the proper way; shall I show it you?\" \"Oh, certainly, Foxy-woxy,\" said Henny-Penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey. So Henny-penny, Cocky-locky, Ducky-daddles, Goosey-poosey, Turkey-lurkey, and Foxy-woxy all went to tell the king the sky was a-falling.\n",
        "So they went along, and they went along, and they went along, till they came to a narrow and dark hole. Now this was the door of Foxy-woxy's cave. But Foxy-woxy said to Henny-penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey: \"This is the short way to the king's palace; you'll soon get there if you follow me. I will go first and you come after, Henny-Penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey.\" \"Why of course, certainly, without doubt, why not?\" said Henny-penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey.\n",
        "So Foxy-woxy went into his cave, and he didn't go very far, but turned round to wait for Henny-penny, Cocky-locky, Ducky-daddles, Goosey-poosey, and Turkey-lurkey. So at last at first Turkey-lurkey went through the dark hole into the cave. He hadn't got far when \"Hrumph,\" Foxy-woxy snapped off Turkey-lurkey's head and threw his body over his left shoulder. Then Goosey-poosey went in, and \"Hrumph,\" off went her head and Goosey-poosey was thrown beside Turkey-lurkey. Then Ducky-daddles waddled down, and \"Hrumph,\" snapped Foxy-woxy, and Ducky-daddles' head was off and Ducky-daddles was thrown alongside Turkey-lurkey and Goosey-poosey. Then Cocky-locky strutted down into the cave, and he hadn't gone far when \"Snap, Hrumph!\" went Foxy-woxy and Cocky-locky was thrown alongside of Turkey-lurkey, Goosey-poosey, and Ducky-daddles.\n",
        "But Foxy-woxy had made two bites at Cocky-locky, and when the first snap only hurt Cocky-locky, but didn't kill him, he called out to Henny-penny. But she turned tail and off she ran home, so she never told the king the sky was a-falling.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "results_df = pd.DataFrame(columns=[\n",
        "    \"model\", \"metric\", \"value\"\n",
        "])\n",
        "\n",
        "def calculate_metrics(text, model_name):\n",
        "    metrics = {\n",
        "        \"Syllable Count\": textstat.syllable_count(text),\n",
        "        \"Lexicon Count\": textstat.lexicon_count(text, removepunct=True),\n",
        "        \"Sentence Count\": textstat.sentence_count(text),\n",
        "        \"Flesch Reading Ease\": textstat.flesch_reading_ease(text),\n",
        "        \"Flesch-Kincaid Grade Level\": textstat.flesch_kincaid_grade(text),\n",
        "        \"Gunning Fog\": textstat.gunning_fog(text),\n",
        "        \"SMOG Index\": textstat.smog_index(text),\n",
        "        \"Automated Readability Index\": textstat.automated_readability_index(text),\n",
        "        \"Coleman-Liau Index\": textstat.coleman_liau_index(text),\n",
        "        \"Linsear Write Formula\": textstat.linsear_write_formula(text),\n",
        "        \"Dale-Chall Readability Score\": textstat.dale_chall_readability_score(text),\n",
        "        \"Text Standard\": textstat.text_standard(text, float_output=False),\n",
        "        \"Reading Time (seconds)\": textstat.reading_time(text)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "original_metrics = calculate_metrics(original_text, \"original_text\")\n",
        "for metric, value in original_metrics.items():\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([{\n",
        "        \"model\": \"original_text\",\n",
        "        \"metric\": metric,\n",
        "        \"value\": value\n",
        "    }])], ignore_index=True)\n",
        "\n",
        "for model in models:\n",
        "    print(f\"\\nResponse from {model}:\")\n",
        "    try:\n",
        "        response = generate_response(model, prompt)\n",
        "        print(response)\n",
        "\n",
        "        model_metrics = calculate_metrics(response, model)\n",
        "        for metric, value in model_metrics.items():\n",
        "            results_df = pd.concat([results_df, pd.DataFrame([{\n",
        "                \"model\": model,\n",
        "                \"metric\": metric,\n",
        "                \"value\": value\n",
        "            }])], ignore_index=True)\n",
        "\n",
        "        print(\"\\nReadability Metrics:\")\n",
        "        for metric, value in model_metrics.items():\n",
        "            print(f\"{metric}: {value}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response from {model}: {e}\")\n",
        "\n",
        "results_df.to_csv(\"Henny-Penny_readability_score.csv\", index=False)\n",
        "results_df.to_excel(\"Henny-Penny_readability_score.xlsx\", index=False)\n",
        "\n",
        "\n",
        "print(\"Responses and readability metrics saved to Henny-Penny_readability_score.csv, Henny-Penny_readability_score.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nroj6AWJDKLE",
        "outputId": "612ede39-48c3-41bf-fc37-14f84d4f35c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Response from claude-3-haiku@anthropic:\n",
            "Here is an original fairy tale about Henny-Penny:\n",
            "\n",
            "Once upon a time, there was a little hen named Henny-Penny who lived on a farm. Henny-Penny was a kind and curious hen who loved exploring the farmyard and pecking at the ground for tasty morsels.\n",
            "\n",
            "One day, as Henny-Penny was scratching in the dirt, something fell on her head. \"Ouch!\" she exclaimed. Henny-Penny looked up to see an acorn had fallen from the tree above. \n",
            "\n",
            "\"Goodness gracious me!\" cried Henny-Penny. \"The sky is falling! I must go and tell the king!\"\n",
            "\n",
            "So Henny-Penny set off down the path, clucking and flapping her wings in a panic. Soon she met her friend Ducky-Lucky.\n",
            "\n",
            "\"Ducky-Lucky, the sky is falling! I must go and tell the king!\" said Henny-Penny.\n",
            "\n",
            "\"The sky is falling?\" said Ducky-Lucky, a look of concern on his face. \"Then I will come with you.\"\n",
            "\n",
            "The two friends continued down the path, meeting Goosey-Loosey next.\n",
            "\n",
            "\"Goosey-Loosey, the sky is falling! I must go and tell the king!\" cried Henny-Penny.\n",
            "\n",
            "\"The sky is falling?\" said Goosey-Loosey. \"How dreadful! I will come with you.\"\n",
            "\n",
            "And so the trio of birds hurried along the path, telling every animal they met that the sky was falling and they must go tell the king.\n",
            "\n",
            "Eventually they came across Foxy-Loxy.\n",
            "\n",
            "\"Why, where are you all rushing off to?\" asked Foxy-Loxy.\n",
            "\n",
            "\"The sky is falling! We must go tell the king!\" they all exclaimed.\n",
            "\n",
            "\"The sky is falling, you say?\" said Foxy-Loxy, his eyes gleaming. \"Well, I know a shortcut to the king's castle. Follow me!\"\n",
            "\n",
            "Henny-Penny, Ducky-Lucky, and Goosey-Loosey trusted Foxy-Loxy and followed him down a narrow path through the woods. But Foxy-Loxy was actually leading them to his den, not the king's castle.\n",
            "\n",
            "As they approached Foxy-Loxy's home, the clever fox turned to the birds and said, \"You know, I don't think the sky is really falling. I think you've been tricked!\"\n",
            "\n",
            "The birds realized too late that Foxy-Loxy had lured them into a trap. They tried to flee, but Foxy-Loxy caught them one by one and carried them off to his den.\n",
            "\n",
            "From that day on, Henny-Penny, Ducky-Lucky, and Goosey-Loosey were much more cautious about trusting strangers, especially ones who claimed the sky was falling. They learned that it's important to think for yourself and not always believe what you're told, no matter how dire the news may seem.\n",
            "\n",
            "The moral of the story is: don't be too quick to believe the sky is falling!\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 532\n",
            "Lexicon Count: 410\n",
            "Sentence Count: 37\n",
            "Flesch Reading Ease: 85.59\n",
            "Flesch-Kincaid Grade Level: 4.1\n",
            "Gunning Fog: 5.22\n",
            "SMOG Index: 8.0\n",
            "Automated Readability Index: 6.6\n",
            "Coleman-Liau Index: 7.23\n",
            "Linsear Write Formula: 6.5\n",
            "Dale-Chall Readability Score: 6.46\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 28.7\n",
            "\n",
            "Response from claude-3-opus@anthropic:\n",
            "Here is a fairy tale I wrote about Henny-Penny:\n",
            "\n",
            "Once upon a time, there was a little hen named Henny-Penny. One day, while pecking at the ground for food, an acorn fell from a tree and hit Henny-Penny on the head. \n",
            "\n",
            "\"Oh my goodness!\" Henny-Penny exclaimed. \"The sky must be falling! I must go tell the king at once!\"\n",
            "\n",
            "So Henny-Penny set off down the road to see the king. Before long, she came across her friend Cocky-Locky the rooster. \n",
            "\n",
            "\"Cocky-Locky!\" cried Henny-Penny. \"The sky is falling and I'm going to tell the king!\"\n",
            "\n",
            "\"The sky is falling?\" said Cocky-Locky. \"I better come with you then!\" And so the two continued on.\n",
            "\n",
            "Soon they met Ducky-Lucky. Henny-Penny and Cocky-Locky told Ducky-Lucky that the sky was falling, so Ducky-Lucky joined them on their journey to tell the king. \n",
            "\n",
            "The three friends then came across Goosey-Loosey. After hearing the terrible news, Goosey-Loosey also decided to go with them to see the king about the falling sky.\n",
            "\n",
            "Finally, the group of worried birds met Foxy-Loxy. The sly fox asked where they were all going in such a hurry. \n",
            "\n",
            "\"The sky is falling and we must tell the king!\" they cried.\n",
            "\n",
            "Foxy-Loxy saw an opportunity for an easy meal. \"I know a shortcut to get to the king,\" he said with a grin. \"Follow me!\"\n",
            "\n",
            "But clever Foxy-Loxy did not lead the birds to the king's castle. Instead, he led them straight to his den, planning to have them for dinner. Just as they arrived at the entrance to his den, Henny-Penny suddenly realized they had been tricked!\n",
            "\n",
            "\"Run, everyone!\" Henny-Penny shouted. \"Foxy-Loxy means to eat us, not help us!\"\n",
            "\n",
            "The birds scattered and flew off as fast as their wings could carry them. They returned safely home, realizing the sky wasn't really falling after all. Henny-Penny felt a little silly, but was relieved they had narrowly escaped the jaws of Foxy-Loxy. And from that day on, Henny-Penny always made sure to look up and double-check before running off to tell the king the sky might be falling.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 459\n",
            "Lexicon Count: 344\n",
            "Sentence Count: 28\n",
            "Flesch Reading Ease: 84.37\n",
            "Flesch-Kincaid Grade Level: 4.5\n",
            "Gunning Fog: 5.73\n",
            "SMOG Index: 8.9\n",
            "Automated Readability Index: 6.8\n",
            "Coleman-Liau Index: 7.24\n",
            "Linsear Write Formula: 5.555555555555555\n",
            "Dale-Chall Readability Score: 5.99\n",
            "Text Standard: 5th and 6th grade\n",
            "Reading Time (seconds): 23.67\n",
            "\n",
            "Response from claude-3.5-sonnet@anthropic:\n",
            "Once upon a time, in a cozy little farm nestled at the edge of a lush forest, there lived a plump and cheerful hen named Henny-Penny. She was known throughout the barnyard for her beautiful golden feathers and her kind heart.\n",
            "\n",
            "One sunny morning, as Henny-Penny pecked at the ground searching for tasty seeds, she felt something small and hard hit her on the head. \"Oh my!\" she exclaimed, looking up at the clear blue sky. \"The sky must be falling! I must go tell the king at once!\"\n",
            "\n",
            "Determined to warn everyone, Henny-Penny set off on a journey to the king's castle. As she waddled along the path, she met her friend Cocky-Locky the rooster.\n",
            "\n",
            "\"Where are you going in such a hurry, Henny-Penny?\" asked Cocky-Locky.\n",
            "\n",
            "\"Oh, Cocky-Locky!\" Henny-Penny replied, \"The sky is falling, and I'm going to tell the king!\"\n",
            "\n",
            "Cocky-Locky, concerned for his friend, decided to join her on her quest. As they continued their journey, they met Ducky-Lucky the duck, Goosey-Loosey the goose, and Turkey-Lurkey the turkey. Each time, Henny-Penny shared her worrying news, and her friends joined the group.\n",
            "\n",
            "As they neared the edge of the forest, they encountered Foxy-Loxy, a sly and cunning fox. \"Where are you all going?\" he asked with a glint in his eye.\n",
            "\n",
            "\"We're going to tell the king that the sky is falling!\" Henny-Penny explained.\n",
            "\n",
            "Foxy-Loxy, seeing an opportunity, said, \"Oh, but I know a shortcut to the castle. Follow me!\"\n",
            "\n",
            "The group of birds, trusting Foxy-Loxy, followed him into a dark cave. But just as they entered, wise old Owl-Fowl swooped down and hooted, \"Stop! That's Foxy-Loxy's den!\"\n",
            "\n",
            "Realizing their mistake, the birds quickly turned and ran out of the cave, narrowly escaping Foxy-Loxy's sharp teeth.\n",
            "\n",
            "Safe outside, Owl-Fowl asked Henny-Penny why she thought the sky was falling. When Henny-Penny explained what had happened, Owl-Fowl chuckled kindly and said, \"My dear Henny-Penny, it wasn't the sky falling. It was merely an acorn that fell from the old oak tree.\"\n",
            "\n",
            "Henny-Penny and her friends laughed at their silly mistake. They thanked Owl-Fowl for his wisdom and headed back to the farm, having learned an important lesson about not jumping to conclusions and the value of seeking wisdom before acting.\n",
            "\n",
            "From that day on, whenever something unexpected happened, Henny-Penny would remember to stop, think, and ask for help before assuming the worst. And she lived happily ever after with her barnyard friends, always ready for a new adventure.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 567\n",
            "Lexicon Count: 408\n",
            "Sentence Count: 29\n",
            "Flesch Reading Ease: 74.08\n",
            "Flesch-Kincaid Grade Level: 6.4\n",
            "Gunning Fog: 6.82\n",
            "SMOG Index: 9.5\n",
            "Automated Readability Index: 9.1\n",
            "Coleman-Liau Index: 9.16\n",
            "Linsear Write Formula: 7.0\n",
            "Dale-Chall Readability Score: 7.04\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 29.84\n",
            "\n",
            "Response from gemini-1.5-flash@vertex-ai:\n",
            "Once upon a time, in a land where the sky was the colour of a robin's egg and the grass was as green as a spring leaf, lived a little hen named Henny-Penny. Henny-Penny was a kind and curious hen, but she was also very easily scared.\n",
            "\n",
            "One sunny morning, Henny-Penny was pecking at the ground, searching for the juiciest worms, when a tiny acorn fell from the sky, landing right on her head with a soft \"thump.\"\n",
            "\n",
            "\"Oh dear!\" squawked Henny-Penny, her feathers ruffled in alarm. \"The sky is falling! The sky is falling!\"\n",
            "\n",
            "She fluttered her wings, her heart pounding like a drum. She knew just what to do. She would go and tell the King!\n",
            "\n",
            "She ran as fast as her little legs could carry her, her tiny feet kicking up dust clouds in her wake. She met Cocky-Locky, a proud rooster with a bright red comb, strutting along the path.\n",
            "\n",
            "\"Cocky-Locky, Cocky-Locky, the sky is falling!\" cried Henny-Penny, her voice trembling.\n",
            "\n",
            "Cocky-Locky raised an eyebrow, his comb quivering. \"Nonsense, Henny-Penny,\" he scoffed. \"It was just an acorn. The sky is not falling.\"\n",
            "\n",
            "Henny-Penny, her fear undeterred, continued on her way. She met Ducky-Ducky, a plump duck paddling in a nearby stream.\n",
            "\n",
            "\"Ducky-Ducky, Ducky-Ducky, the sky is falling!\" she cried, her voice growing louder.\n",
            "\n",
            "Ducky-Ducky, with a splash of his webbed feet, replied, \"Don't be silly, Henny-Penny. It was just a leaf. The sky is not falling.\"\n",
            "\n",
            "Disheartened but determined, Henny-Penny pressed on. She met Goosey-Goosey, a stately goose with a long, elegant neck.\n",
            "\n",
            "\"Goosey-Goosey, Goosey-Goosey, the sky is falling!\" she squawked, her voice now a high-pitched shriek.\n",
            "\n",
            "Goosey-Goosey, with a dignified nod, said, \"My dear Henny-Penny, it was just a feather. The sky is not falling.\"\n",
            "\n",
            "Henny-Penny, exhausted and confused, was about to give up when she spotted a wise old owl perched on a tree branch.\n",
            "\n",
            "\"Wise old owl, wise old owl,\" she called out, her voice barely a whisper. \"The sky is falling!\"\n",
            "\n",
            "The owl, with a knowing twinkle in his eye, flew down to her. \"Little Henny-Penny,\" he said gently, \"the sky is not falling. It was just an acorn, a leaf, and a feather.\"\n",
            "\n",
            "He then explained to Henny-Penny that it was important to think before she acted. Sometimes, things weren't as scary as they seemed.\n",
            "\n",
            "Henny-Penny, understanding at last, felt a wave of relief wash over her. She thanked the wise old owl and, with a newfound confidence, turned around and headed back home.\n",
            "\n",
            "From that day forward, Henny-Penny learned to be less hasty and more observant. She still loved to explore, but she always took a moment to think before she jumped to conclusions. And she never again believed the sky was falling. \n",
            "\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 598\n",
            "Lexicon Count: 453\n",
            "Sentence Count: 43\n",
            "Flesch Reading Ease: 86.2\n",
            "Flesch-Kincaid Grade Level: 3.8\n",
            "Gunning Fog: 5.44\n",
            "SMOG Index: 8.5\n",
            "Automated Readability Index: 6.5\n",
            "Coleman-Liau Index: 7.4\n",
            "Linsear Write Formula: 7.0\n",
            "Dale-Chall Readability Score: 6.84\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 31.99\n",
            "\n",
            "Response from gemini-1.5-pro@vertex-ai:\n",
            "Once upon a time, in a meadow dappled with sunshine and buzzing with bees, lived a hen named Henny-Penny. Unlike her sisters, who clucked and scratched with simple pleasure, Henny-Penny possessed a heart prone to worry. A fallen leaf, a passing cloud – everything spelled disaster in her eyes.\n",
            "\n",
            "One crisp autumn day, as Henny-Penny pecked at the ground, something hard bounced off her head. She squawked in alarm, her feathers ruffled. Examining the culprit – a small, smooth acorn – she felt a familiar dread creep in. \"The sky is falling!\" she shrieked. \"An acorn just hit my head! We must warn the king!\"\n",
            "\n",
            "Without a second thought, Henny-Penny set off, her little heart thumping like a drum. She ran past her sisters, ignoring their confused clucking, and soon encountered Cocky-Locky, strutting with his usual swagger. \"Cocky-Locky!\" cried Henny-Penny, \"The sky is falling! We must warn the king!\"\n",
            "\n",
            "Now, Cocky-Locky, though vain, wasn't heartless. He joined Henny-Penny, more out of curiosity than concern. Along their way, they met Ducky-Lucky, swimming in a puddle. \"The sky is falling!\" they exclaimed, and Ducky-Lucky, easily swayed, waddled after them.\n",
            "\n",
            "Their journey continued, and with each telling, Henny-Penny's story grew more dramatic. By the time they met Goosey-Loosey, she was describing a sky cracking open, with giant acorns raining down. Goosey-Loosey, known for her gossiping, honked in alarm and joined the procession.\n",
            "\n",
            "Finally, they reached the palace, a magnificent structure of gold and marble. The guards, initially amused by the sight of a frantic hen, a preening rooster, a dripping duck, and a flapping goose, were soon taken aback by their urgent cries. The king, a wise but indulgent ruler, agreed to see them.\n",
            "\n",
            "Henny-Penny, breathless and frantic, told her tale, each word dripping with fear. The king listened patiently, his wise eyes twinkling. When she finished, he simply smiled. \"My dear Henny-Penny,\" he said, \"what you felt was not the sky falling, but a simple acorn. It is autumn, and the oak trees are shedding their bounty.\"\n",
            "\n",
            "He then led them to the window and pointed. There, bathed in the golden light of the setting sun, stood a mighty oak, its branches laden with acorns. Henny-Penny stared, her eyes wide. The king was right! The sky wasn't falling. Relief washed over her, followed by a wave of sheepishness.\n",
            "\n",
            "The king, chuckling, offered them tea and cakes. As they enjoyed the unexpected treat, he imparted a valuable lesson: \"It is good to be cautious, my friends, but fear can cloud our judgment. Always seek the truth before jumping to conclusions.\"\n",
            "\n",
            "Henny-Penny, humbled and wiser, returned home that day. The fallen leaves and passing clouds still made her nervous, but now, she took a moment to observe, to think, and most importantly, to ask for help from her friends. And though she never lived down the tale of the falling sky, it became a legend in the meadow, a reminder to all that even the smallest acorn can seem like a disaster if we let fear rule our hearts. \n",
            "\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 687\n",
            "Lexicon Count: 502\n",
            "Sentence Count: 41\n",
            "Flesch Reading Ease: 76.01\n",
            "Flesch-Kincaid Grade Level: 5.7\n",
            "Gunning Fog: 6.55\n",
            "SMOG Index: 8.8\n",
            "Automated Readability Index: 8.3\n",
            "Coleman-Liau Index: 9.15\n",
            "Linsear Write Formula: 6.125\n",
            "Dale-Chall Readability Score: 7.95\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 36.92\n",
            "\n",
            "Response from gemma-2-9b-it@fireworks-ai:\n",
            "Once upon a time, in a sun-dappled meadow, lived a plump little hen named Henny-Penny. Now, Henny-Penny was a creature of habit, content with her daily routine of pecking for seeds, gossiping with the other hens, and dreaming of plump, juicy worms.\n",
            "\n",
            "One blustery morning, as Henny-Penny scratched amongst the clover, a strange thing happened. A single acorn, plump and brown, tumbled from a towering oak, landing with a resounding *thump* right beside her. Henny-Penny, startled, let out a squawk.\n",
            "\n",
            "\"The sky is falling!\" she cried, her voice trembling. \"The sky is falling!\"\n",
            "\n",
            "The other hens, startled by her panicked cry, gathered around. \"The sky is falling?\" clucked Ducky-Lucky, her feathers ruffled. \"Nonsense, Henny-Penny! The sky is always up there.\"\n",
            "\n",
            "But Henny-Penny was convinced. \"I saw it with my own eyes!\" she insisted. \"An acorn fell from the sky, and that means the whole sky is coming down!\"\n",
            "\n",
            "Fearful of the impending doom, Henny-Penny took off running, her cry echoing across the meadow. \"The sky is falling! The sky is falling!\"\n",
            "\n",
            "Ducky-Lucky, ever loyal, followed close behind. \"Calm down, Henny-Penny,\" she quacked. \"Let's find someone who can help.\"\n",
            "\n",
            "They soon encountered Goosey-Loosey, who was leisurely nibbling on some juicy grass. \"The sky is falling!\" shrieked Henny-Penny. \"We need your help!\"\n",
            "\n",
            "Goosey-Loosey, startled by their frantic cries, dropped her mouthful of grass. \"The sky is falling?\" she honked. \"That's preposterous! The sky is always where it should be.\"\n",
            "\n",
            "But Henny-Penny wouldn't be swayed. \"It's true!\" she insisted. \"An acorn fell, and that means the end is near!\"\n",
            "\n",
            "Goosey-Loosey, not wanting to be left behind in the face of disaster, joined their frantic procession. \"The sky is falling! The sky is falling!\" they cried together, their voices growing louder with each step.\n",
            "\n",
            "They bumped into Foxy-Loxy, who was basking in the sun, his tail twitching with amusement. \"The sky is falling!\" squawked Henny-Penny. \"Help us!\"\n",
            "\n",
            "Foxy-Loxy, his eyes gleaming, feigned concern. \"Oh dear, the sky is falling! What a terrible misfortune!\"\n",
            "\n",
            "He slyly suggested, \"Follow me, my friends. I know a safe place where you can hide from the falling sky.\"\n",
            "\n",
            "Henny-Penny, Ducky-Lucky, and Goosey-Loosey, blinded by fear, followed Foxy-Loxy deeper and deeper into the woods.\n",
            "\n",
            "But Foxy-Loxy, his cunning plan in motion, had no intention of protecting them. He led them straight to his den, where he planned to make a delicious feast of the three frightened friends.\n",
            "\n",
            "As they approached the den, Henny-Penny, her fear momentarily replaced by suspicion, noticed something peculiar. \"This doesn't look like a safe place,\" she clucked nervously.\n",
            "\n",
            "\"Nonsense, my dear,\" Foxy-Loxy purred, his voice dripping with false kindness. \"This is the safest place in the whole world.\"\n",
            "\n",
            "But Ducky-Lucky, her sharp eyes noticing the glint of hunger in Foxy-Loxy's eyes, squawked, \"He's going to eat us!\"\n",
            "\n",
            "Goosey-Loosey, finally realizing the danger, honked in alarm. \"Run!\"\n",
            "\n",
            "They turned and fled, their cries echoing through the woods, as Foxy-Loxy gave chase.\n",
            "\n",
            "They ran and ran, dodging trees and leaping over fallen logs, until they finally reached the edge of the meadow.\n",
            "\n",
            "Safe at last, Henny-Penny, Ducky-Lucky, and Goosey-Loosey collapsed in exhaustion.\n",
            "\n",
            "\"The sky wasn't falling at all,\" sighed Henny-Penny, her feathers ruffled. \"It was just an acorn.\"\n",
            "\n",
            "\"And we almost became Foxy-Loxy's dinner,\" added Goosey-Loosey, her voice trembling.\n",
            "\n",
            "\"We should have listened to our own instincts,\" said Ducky-Lucky, shaking her head. \"Sometimes, the truth is right in front of us.\"\n",
            "\n",
            "From that day forward, Henny-Penny, Ducky-Lucky, and Goosey-Loosey learned a valuable lesson: not everything that seems frightening is actually dangerous, and it's important to trust your own judgment. And as for Foxy-Loxy, he learned that sometimes, even the cleverest fox can be outsmarted by a little common sense.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 860\n",
            "Lexicon Count: 611\n",
            "Sentence Count: 59\n",
            "Flesch Reading Ease: 77.84\n",
            "Flesch-Kincaid Grade Level: 5.0\n",
            "Gunning Fog: 5.67\n",
            "SMOG Index: 8.6\n",
            "Automated Readability Index: 8.9\n",
            "Coleman-Liau Index: 9.72\n",
            "Linsear Write Formula: 5.444444444444445\n",
            "Dale-Chall Readability Score: 7.31\n",
            "Text Standard: 8th and 9th grade\n",
            "Reading Time (seconds): 47.92\n",
            "\n",
            "Response from gemma-2b-it@together-ai:\n",
            "\n",
            "\n",
            "Once upon a time, in a land painted with wildflowers and singing birds, lived Henny-Penny, a tiny penny with a heart as big as her tiny frame. She was always hungry, her tiny mouth constantly searching for something to munch on.\n",
            "\n",
            "One sunny afternoon, Henny-Penny set off to explore the forest. She tiptoed through the leaves, her tiny legs carrying her along like a butterfly's wings. She popped her head under a bush, searching for food, and her eyes fell upon a juicy strawberry.\n",
            "\n",
            "\"Oh, what a treat!\" she whispered, her tiny voice. \"But I'm all out of luck.\"\n",
            "\n",
            "Just then, a wise old owl flew down from a nearby branch. \"Little one, why the long face?\" he asked.\n",
            "\n",
            "Henny-Penny explained her predicament, her tiny voice trembling with excitement and fear. The owl smiled kindly. \"Fear not, my dear penny. A full belly is a happy belly, and I know just the thing to help you.\"\n",
            "\n",
            "He then pointed to a nearby meadow where a beautiful flower bloomed with the most vibrant blue petals. \"Pick a few ripe strawberries, and let them hang and ripen on the branch.\"\n",
            "\n",
            "As the sun began to set, Henny-Penny scurried back to the forest, her heart pounding with anticipation. She picked a handful of plump strawberries and hung them on the owl's branch.\n",
            "\n",
            "The owl then took a bite of the strawberries and smiled. \"There, my child, you shall have a feast fit for a princess.\"\n",
            "\n",
            "And so, Henny-Penny enjoyed the sweetest strawberries of her life. Her tiny mouth danced with joy, and her heart swelled with happiness. She knew that even though she was small, she could be lucky and kind.\n",
            "\n",
            "From that day on, Henny-Penny became the happiest penny in the forest. She shared her sweet treats with the animals and grew a reputation for generosity. She was a reminder that even the smallest of creatures can make a big difference in the world.\n",
            "\n",
            "And so, the tale of Henny-Penny, the little penny with a heart as big as her tiny frame, was passed down through generations, inspiring all who heard it that even the smallest of us can achieve great things.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 467\n",
            "Lexicon Count: 360\n",
            "Sentence Count: 27\n",
            "Flesch Reading Ease: 83.36\n",
            "Flesch-Kincaid Grade Level: 4.9\n",
            "Gunning Fog: 6.76\n",
            "SMOG Index: 8.9\n",
            "Automated Readability Index: 6.9\n",
            "Coleman-Liau Index: 7.24\n",
            "Linsear Write Formula: 6.25\n",
            "Dale-Chall Readability Score: 6.71\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 24.28\n",
            "\n",
            "Response from gpt-3.5-turbo@openai:\n",
            "Once upon a time, in a peaceful village nestled in the heart of the enchanted forest, there lived a sweet and kind-hearted hen named Henny-Penny. Henny-Penny was known throughout the land for her gentle nature and her beautiful golden feathers that shimmered in the sunlight.\n",
            "\n",
            "One bright and sunny morning, as Henny-Penny was out pecking for seeds in the meadow, she heard a loud and thunderous noise coming from the sky. Looking up, she saw a great shadow looming overhead and realized with a start that it was the sky falling down upon them.\n",
            "\n",
            "Filled with fear and worry for her friends and neighbors, Henny-Penny knew she had to do something to save them all. With a brave heart and a determined spirit, she set off on a journey to warn the king of the impending disaster.\n",
            "\n",
            "Along the way, Henny-Penny met a host of other animals who were also filled with fear and uncertainty. There was Ducky-Lucky, who was quacking in distress, and Goosey-Loosey, who was honking in panic. But Henny-Penny reassured them all that together, they could overcome any obstacle that stood in their way.\n",
            "\n",
            "As they journeyed through the forest, they encountered many challenges and obstacles, but Henny-Penny's unwavering courage and determination inspired her friends to keep going. And finally, after much hardship and struggle, they reached the king's palace and delivered their urgent warning.\n",
            "\n",
            "The king was grateful for Henny-Penny's bravery and quick thinking, and he immediately called upon his royal advisors to come up with a plan to save the kingdom. With the help of Henny-Penny and her friends, they were able to stop the sky from falling and restore peace and harmony to the land once more.\n",
            "\n",
            "From that day on, Henny-Penny was hailed as a hero throughout the kingdom, and her name was remembered for generations to come. And though she may have been just a humble hen, Henny-Penny had proven that even the smallest of creatures could make a big difference in the world when they had courage and determination in their hearts. And so, she lived happily ever after, knowing that she had made a difference in the lives of those around her.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 513\n",
            "Lexicon Count: 362\n",
            "Sentence Count: 16\n",
            "Flesch Reading Ease: 65.46\n",
            "Flesch-Kincaid Grade Level: 9.7\n",
            "Gunning Fog: 11.25\n",
            "SMOG Index: 12.2\n",
            "Automated Readability Index: 12.8\n",
            "Coleman-Liau Index: 10.33\n",
            "Linsear Write Formula: 11.6\n",
            "Dale-Chall Readability Score: 7.59\n",
            "Text Standard: 11th and 12th grade\n",
            "Reading Time (seconds): 25.85\n",
            "\n",
            "Response from gpt-4@openai:\n",
            "Once upon a time, in a far-off farm filled with luscious green fields, there lived a little, red hen named Henny-Penny. Henny-Penny was known throughout the farm for her cheerful personality and abundant kindness. She would spend her days pecking at the grains, clucking happily and spreading joy among her fellow farm friends.\n",
            "\n",
            "One sunny day, as Henny-Penny was pecking at the ground looking for her lunch, she felt something fall on her head. She looked up and saw nothing but the clear blue sky. Frightened, she began to believe that the sky was falling.\n",
            "\n",
            "Henny-Penny hurried back to the farm to warn her friends. \"The sky is falling!\" she cried out. \"We must tell the king!\" Her friends, Cocky-Locky, Ducky-Daddles, and Turkey-Lurkey, were startled by her panic and decided to join her on the journey to inform the king.\n",
            "\n",
            "As they traveled through the woods, they came across a cunning fox named Foxy-Loxy. Smiling slyly, he asked, \"Where are you all going in such a hurry?\" When they told him about their mission, Foxy-Loxy saw a chance to trick the innocent animals.\n",
            "\n",
            "\"Why, the king is at my den. Follow me, and I'll bring you to him,\" he lied smoothly. Trusting Foxy-Loxy, the group continued their journey, not realizing the danger that lay ahead.\n",
            "\n",
            "However, Henny-Penny, with her keen senses, started to feel uneasy. She noticed the fox's sly smile and his eyes glinting with mischief. Sensing something was amiss, she decided to act.\n",
            "\n",
            "\"Look, friends!\" she cried suddenly, pointing at a bush. \"I think I see the king's castle right there!\" The animals, including Foxy-Loxy, turned to look. Seizing the moment, Henny-Penny led her friends away from the fox, back towards their home.\n",
            "\n",
            "When they were safely away, Henny-Penny explained her suspicions about Foxy-Loxy. Her friends thanked her for her quick thinking and praised her bravery. From that day forward, they all promised to be more wary of strangers.\n",
            "\n",
            "As for Henny-Penny, she learned not to jump to conclusions without proper evidence. She realized that the sky wasn't falling; it was just an acorn that had hit her head. She laughed at her previous panic and shared her newfound wisdom with her friends.\n",
            "\n",
            "In the end, the farm was peaceful once again, and Henny-Penny continued to spread joy and laughter among her friends. Her tale served as a reminder for all the animals on the farm to be cautious, wise, and not to believe everything they hear without proof.\n",
            "\n",
            "And so, they all lived happily ever after, spreading the tale of Henny-Penny, the wise and brave little hen.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 579\n",
            "Lexicon Count: 430\n",
            "Sentence Count: 33\n",
            "Flesch Reading Ease: 83.66\n",
            "Flesch-Kincaid Grade Level: 4.8\n",
            "Gunning Fog: 6.41\n",
            "SMOG Index: 8.8\n",
            "Automated Readability Index: 8.1\n",
            "Coleman-Liau Index: 8.63\n",
            "Linsear Write Formula: 7.0\n",
            "Dale-Chall Readability Score: 7.29\n",
            "Text Standard: 8th and 9th grade\n",
            "Reading Time (seconds): 30.8\n",
            "\n",
            "Response from gpt-4-turbo@openai:\n",
            "Once upon a time, in a quiet corner of a sun-dappled forest, there lived a little hen named Henny-Penny. She was a cheerful bird, with feathers as bright as the dawn and a spirit filled with curiosity about the world.\n",
            "\n",
            "One warm and breezy afternoon, as Henny-Penny pecked around the forest floor searching for seeds and small insects, something most unusual happened. A tiny acorn fell from a tall oak tree and landed with a soft \"thud\" right on her head.\n",
            "\n",
            "Startled, Henny-Penny looked around. Seeing no one and nothing except the little acorn, she immediately jumped to a conclusion. \"The sky is falling! The sky is falling!\" she squawked in alarm. \"I must go and tell the king!\"\n",
            "\n",
            "So off she went, hurrying down the dusty path that led to the royal palace. As she scurried along, she met Cocky-Locky, a rooster with a fine red comb.\n",
            "\n",
            "\"Where are you going in such a hurry, Henny-Penny?\" Cocky-Locky asked.\n",
            "\n",
            "\"Oh, Cocky-Locky!\" cried Henny-Penny. \"The sky is falling! I felt it hit my head, and I am going to tell the king!\"\n",
            "\n",
            "Cocky-Locky, who was sometimes prone to excitement himself, didn't doubt Henny-Penny's story. \"This is dreadful! I will come with you,\" he declared.\n",
            "\n",
            "Together, they continued along the path, and soon they met Ducky-Lucky, a gentle duck who was heading to the pond.\n",
            "\n",
            "\"Where are you two off to in such a rush?\" Ducky-Lucky inquired, fluffing her feathers.\n",
            "\n",
            "\"The sky is falling,\" Henny-Penny explained breathlessly. \"We're going to tell the king!\"\n",
            "\n",
            "Ducky-Lucky, who didn’t want to miss an adventure, joined them, and the trio hurried onwards. Before long, they met Goosey-Loosey and Turkey-Lurkey, and soon, the whole group was convinced that they needed to inform the king about the falling sky.\n",
            "\n",
            "As they neared the edge of the forest, they stumbled upon a dark, eerie cave. Out from the shadows slinked Foxy-Loxy, a sly fox with a gleam in his eye.\n",
            "\n",
            "\"Where are you all going in such a state?\" asked Foxy-Loxy smoothly.\n",
            "\n",
            "\"The sky is falling, and we are off to tell the king!\" explained Henny-Penny, still quite panicked.\n",
            "\n",
            "Foxy-Loxy thought for a moment and then, with a crafty grin, said, \"Oh, my dear friends, the king has moved his chambers. He now resides in this very cave. Follow me, and I shall lead you to him.\"\n",
            "\n",
            "The group, naive and trusting, followed Foxy-Loxy into the cave. However, just as they were about to enter the darkest depths, Henny-Penny stopped. A sudden flutter of wings caught her eye, and she noticed a wise old owl perched on a branch above.\n",
            "\n",
            "\"Owl, is it true? Has the king really moved his palace here?\" she called out to him.\n",
            "\n",
            "The wise old owl hooted softly, \"Oh, no, dear Henny-Penny. The king's palace is still by the crystal lake. This fox is leading you astray!\"\n",
            "\n",
            "Henny-Penny turned to her friends. \"We must not go into the cave. It’s a trick!\" she declared. The animals quickly scattered from the cave's entrance, Foxy-Loxy’s sly plan foiled.\n",
            "\n",
            "Relieved and wiser, the group decided to return home, realizing that jumping to conclusions could lead them into trouble. As they walked back, the wise old owl explained to them about the acorns that fall in the autumn and how important it is to seek the truth.\n",
            "\n",
            "And so, Henny-Penny and her friends learned to be more discerning and cautious. They often retold their adventure to others, reminding everyone in the forest to never panic over an acorn and always question what they hear.\n",
            "\n",
            "From that day on, whenever an acorn would fall, Henny-Penny would look up, smile, and continue her day, unafraid, for she knew the sky was not falling at all.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 815\n",
            "Lexicon Count: 615\n",
            "Sentence Count: 52\n",
            "Flesch Reading Ease: 84.88\n",
            "Flesch-Kincaid Grade Level: 4.4\n",
            "Gunning Fog: 5.7\n",
            "SMOG Index: 8.4\n",
            "Automated Readability Index: 6.8\n",
            "Coleman-Liau Index: 7.53\n",
            "Linsear Write Formula: 8.833333333333334\n",
            "Dale-Chall Readability Score: 6.94\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 42.73\n",
            "\n",
            "Response from gpt-4o@openai:\n",
            "Once upon a time, in a peaceful meadow surrounded by whispering trees and singing brooks, there lived a little hen named Henny-Penny. Henny-Penny was a kind-hearted but somewhat anxious little hen. She was always bustling about, tending to her chores and looking after her friends. Her bright red feathers and curious eyes made her a charming sight, but her habit of worrying over the smallest things often got her into trouble.\n",
            "\n",
            "One sunny morning, as Henny-Penny pecked around the meadow looking for seeds, she felt a sudden thump on her head. Startled, she looked around and saw an acorn lying on the ground. In her excitement, she cried out, \"Oh dear, oh dear! The sky is falling! I must tell the king!\"\n",
            "\n",
            "Without a moment's hesitation, Henny-Penny fluttered her wings and set off towards the royal palace. On her way, she met her friend Cocky-Locky, the proud rooster.\n",
            "\n",
            "\"Where are you rushing off to, Henny-Penny?\" asked Cocky-Locky.\n",
            "\n",
            "\"Oh, Cocky-Locky, the sky is falling! I must tell the king!\" she exclaimed, her eyes wide with worry.\n",
            "\n",
            "Cocky-Locky, always eager for a bit of excitement, decided to join her. \"Let's go together, Henny-Penny. The king must be informed!\"\n",
            "\n",
            "As they hurried along, they encountered Ducky-Lucky, waddling by the pond.\n",
            "\n",
            "\"Where are you going in such a hurry?\" quacked Ducky-Lucky.\n",
            "\n",
            "\"The sky is falling, Ducky-Lucky! We're going to tell the king!\" Henny-Penny and Cocky-Locky chorused.\n",
            "\n",
            "Ducky-Lucky, a curious and adventurous duck, quickly joined the group. The trio continued their journey until they met Goosey-Loosey, who was gracefully swimming in the stream.\n",
            "\n",
            "\"What's the rush?\" honked Goosey-Loosey.\n",
            "\n",
            "\"The sky is falling, Goosey-Loosey! We're going to tell the king!\" they all chimed in.\n",
            "\n",
            "Goosey-Loosey, though skeptical, decided to accompany them for the sake of her friends. Soon, they came across Turkey-Lurkey, who was foraging in the underbrush.\n",
            "\n",
            "\"Why the haste?\" gobbled Turkey-Lurkey.\n",
            "\n",
            "\"The sky is falling, Turkey-Lurkey! We're going to tell the king!\" the group exclaimed in unison.\n",
            "\n",
            "Turkey-Lurkey, always up for an adventure, joined the growing party. As they traveled together, they came upon Foxy-Loxy, who was lounging by the edge of the forest.\n",
            "\n",
            "\"Where are you all heading so fast?\" asked Foxy-Loxy, with a sly glint in his eye.\n",
            "\n",
            "\"The sky is falling, Foxy-Loxy! We're going to tell the king!\" they replied.\n",
            "\n",
            "Foxy-Loxy, who was always looking for an opportunity to cause mischief, saw a chance to trick the naive group. \"Oh my dear friends, the path to the palace is dangerous and treacherous. I know a shortcut through the forest. Follow me, and we will reach the king in no time!\"\n",
            "\n",
            "Trusting Foxy-Loxy, the group followed him into the dense forest. As they ventured deeper, the shadows grew longer, and the air turned cooler. Henny-Penny began to feel uneasy.\n",
            "\n",
            "\"Are you sure this is the right way, Foxy-Loxy?\" she asked, her voice trembling.\n",
            "\n",
            "\"Of course, dear Henny-Penny. Trust me,\" replied Foxy-Loxy, hiding his cunning smile.\n",
            "\n",
            "Just as Foxy-Loxy was about to lead them into his den, a wise old owl named Wise-Whisper flew down from the trees.\n",
            "\n",
            "\"Stop, my friends!\" Wise-Whisper hooted. \"Foxy-Loxy is leading you astray. The sky is not falling. An acorn simply fell on your head, Henny-Penny.\"\n",
            "\n",
            "Realizing their mistake, Henny-Penny and her friends thanked Wise-Whisper for saving them. They turned to Foxy-Loxy, who was already slinking away, disappointed that his plan had been foiled.\n",
            "\n",
            "With a sigh of relief, Henny-Penny and her friends made their way back to the meadow. They laughed at their overreaction and learned a valuable lesson that day: not to jump to conclusions without understanding the situation.\n",
            "\n",
            "And so, Henny-Penny, Cocky-Locky, Ducky-Lucky, Goosey-Loosey, and Turkey-Lurkey lived happily ever after, a little wiser and much more cautious. The meadow returned to its peaceful state, and the friends cherished their days together, always ready to face any challenge with wisdom and courage.\n",
            "\n",
            "The end.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 899\n",
            "Lexicon Count: 638\n",
            "Sentence Count: 63\n",
            "Flesch Reading Ease: 78.14\n",
            "Flesch-Kincaid Grade Level: 4.9\n",
            "Gunning Fog: 5.48\n",
            "SMOG Index: 8.7\n",
            "Automated Readability Index: 8.0\n",
            "Coleman-Liau Index: 9.2\n",
            "Linsear Write Formula: 8.666666666666666\n",
            "Dale-Chall Readability Score: 6.88\n",
            "Text Standard: 8th and 9th grade\n",
            "Reading Time (seconds): 48.51\n",
            "\n",
            "Response from llama-3-70b-chat@fireworks-ai:\n",
            "What a delightful task! Here's a fairy tale about Henny-Penny, a beloved character from nursery rhymes:\n",
            "\n",
            "**The Quest for the Golden Acorn**\n",
            "\n",
            "In the cozy little village of Cluckville, nestled in the heart of the Whimsy Woods, Henny-Penny lived a simple life. She spent her days pecking at the earth, searching for tasty bugs and seeds to feed her brood of chirping chicks. But Henny-Penny's humble existence was about to take a dramatic turn.\n",
            "\n",
            "One day, while scratching in the underbrush, Henny-Penny stumbled upon a mysterious, ancient scroll. The parchment was worn and faded, but the words \"Quest for the Golden Acorn\" shimmered in golden ink, beckoning her to embark on a grand adventure.\n",
            "\n",
            "Intrigued, Henny-Penny gathered her chicks around her and shared the tale of the Golden Acorn. Legend had it that this treasured nut, hidden deep within the Whimsy Woods, held the power to bring prosperity and peace to all the creatures of the forest. The chicks, wide-eyed and excited, begged their mother to take on the quest.\n",
            "\n",
            "With a determined cluck, Henny-Penny set off on her journey. She packed a small bag with seeds, berries, and a few shiny pebbles, just in case she needed to barter or bribe her way past any obstacles. Her chicks, though initially disappointed to be left behind, promised to stay safe and vigilant, watching over the coop and the village.\n",
            "\n",
            "As Henny-Penny ventured into the Whimsy Woods, she encountered a cast of colorful characters. There was Foxy-Loxy, a cunning, bushy-tailed trickster who offered to guide her in exchange for a share of the Golden Acorn's magic. Henny-Penny wisely declined, sensing Foxy-Loxy's intentions were not entirely pure.\n",
            "\n",
            "Next, she met a wise old owl named Professor Hootenanny, who shared tales of the forest's ancient secrets and offered sage advice on navigating the treacherous paths ahead. Henny-Penny thanked the owl and continued on, her determination growing with each step.\n",
            "\n",
            "The journey was not without its challenges. Henny-Penny encountered raging rivers, steep cliffs, and dark, foreboding caves. But she persevered, using her quick wit and resourcefulness to overcome each obstacle.\n",
            "\n",
            "At last, after many days of travel, Henny-Penny arrived at the Heart Oak, a magnificent tree said to be the guardian of the Golden Acorn. The tree's ancient, gnarled branches seemed to whisper secrets to her as she approached.\n",
            "\n",
            "With a final, triumphant cluck, Henny-Penny reached the Heart Oak's hollow and retrieved the Golden Acorn. Its radiant glow illuminated the forest, and the creatures of the Whimsy Woods emerged from their homes to celebrate.\n",
            "\n",
            "Henny-Penny returned to Cluckville, the Golden Acorn held proudly in her beak. As she distributed its blessings to the villagers, the forest flourished, and peace and prosperity reigned. The chicks, overjoyed to see their mother again, chirped and cheeped with delight.\n",
            "\n",
            "From that day forward, Henny-Penny was hailed as a hero, and her legendary quest was told and retold around campfires and in cozy nests throughout the land. The Golden Acorn, now a symbol of courage and determination, remained a cherished treasure, reminding all who lived in the Whimsy Woods of the power of bravery and the unbreakable bonds of family and community.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 755\n",
            "Lexicon Count: 523\n",
            "Sentence Count: 29\n",
            "Flesch Reading Ease: 70.13\n",
            "Flesch-Kincaid Grade Level: 8.0\n",
            "Gunning Fog: 9.95\n",
            "SMOG Index: 11.1\n",
            "Automated Readability Index: 12.0\n",
            "Coleman-Liau Index: 11.25\n",
            "Linsear Write Formula: 9.0\n",
            "Dale-Chall Readability Score: 8.91\n",
            "Text Standard: 11th and 12th grade\n",
            "Reading Time (seconds): 39.77\n",
            "\n",
            "Response from llama-3-8b-chat@fireworks-ai:\n",
            "What a delightful character! Here's a fairy tale about Henny-Penny, the plump and proud hen who lived in a cozy little farmhouse with her human family.\n",
            "\n",
            "**The Tale of Henny-Penny's Great Fall**\n",
            "\n",
            "In the rolling hills of the countryside, where the sun shone bright and the air was sweet with the scent of fresh hay, lived a lovely hen named Henny-Penny. She was a plump and proud bird, with shiny golden feathers and a strong, sturdy beak. Henny-Penny loved nothing more than strutting about the farm, clucking loudly, and making sure everyone knew she was the most important chicken on the premises.\n",
            "\n",
            "One day, as Henny-Penny was preening her feathers in the farmyard, she became convinced that the sky was falling. She had seen a small stone fall from the roof of the farmhouse, and to her mind, it was a sign of the impending doom of the world. \"The sky is falling!\" she cried out to the other animals, flapping her wings wildly.\n",
            "\n",
            "The other animals, however, were skeptical. \"Oh, Henny-Penny, it's just a small stone,\" said the wise old cow, Mrs. Whiskers. \"The sky is not falling, dear.\"\n",
            "\n",
            "But Henny-Penny was undeterred. She ran about the farm, squawking and flapping, until she had gathered all the animals together. \"We must warn the world!\" she exclaimed. \"We must tell everyone that the sky is falling!\"\n",
            "\n",
            "The animals, tired of Henny-Penny's antics, decided to play a trick on her. They hid behind a bush and watched as Henny-Penny, convinced that the sky was falling, ran off to the village to spread the news. The villagers, thinking it was a silly hen, ignored her warnings.\n",
            "\n",
            "As Henny-Penny continued to shout and flap about the village, she failed to notice the narrow path behind her. In her haste, she lost her footing and tumbled down a steep hill, her feathers ruffled and her beak askew.\n",
            "\n",
            "The animals, who had been watching from the bush, couldn't help but burst out laughing. \"Henny-Penny, you silly hen!\" they chuckled. \"You were so busy warning the world that the sky was falling, you forgot to watch your own step!\"\n",
            "\n",
            "Henny-Penny, dazed and embarrassed, slowly picked herself up and dusted off her feathers. She looked up at the sky and saw that it was still there, shining brightly and untouched. She realized that she had been foolish and that the world was not, in fact, coming to an end.\n",
            "\n",
            "From that day on, Henny-Penny was known as the hen who cried \"The sky is falling!\" and then fell off a hill. She learned to be more cautious and to think before she acted. And although she still loved to strut about the farm, she never forgot the lesson she learned that day: that sometimes, the best thing to do is to take a moment to look before you leap.\n",
            "\n",
            "The end.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 621\n",
            "Lexicon Count: 474\n",
            "Sentence Count: 31\n",
            "Flesch Reading Ease: 81.33\n",
            "Flesch-Kincaid Grade Level: 5.7\n",
            "Gunning Fog: 7.05\n",
            "SMOG Index: 9.1\n",
            "Automated Readability Index: 8.0\n",
            "Coleman-Liau Index: 7.53\n",
            "Linsear Write Formula: 12.0\n",
            "Dale-Chall Readability Score: 6.63\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 32.2\n",
            "\n",
            "Response from mistral-7b-instruct-v0.3@together-ai:\n",
            "Title: The Courageous Henny-Penny and the Wisdom of the Owl\n",
            "\n",
            "Once upon a time, in a lush green valley nestled between the rolling hills, lived a cheerful little hen named Henny-Penny. She was known far and wide for her golden eggs and her joyful chatter.\n",
            "\n",
            "One sunny morning, as Henny-Penny was pecking away at the ground, a small acorn fell on her head. Startled, she cried, \"I'm as good as dead! An acorn has fallen from the sky! I'm surely doomed!\"\n",
            "\n",
            "The other animals, hearing her cries, gathered around her.\n",
            "\n",
            "\"I'm not surprised,\" said Cocky-Locky, the rooster, with a smirk. \"You always did make the loudest noises. The sky must be falling for you.\"\n",
            "\n",
            "\"Oh, woe is me!\" Henny-Penny wailed. \"I must find the wise old owl who lives in the ancient oak tree. Maybe he can tell me what to do.\"\n",
            "\n",
            "So, Henny-Penny, accompanied by Ducky-Lucky, the duck, and Goosey-Loosey, the goose, set off on their journey. Along the way, they met Cocky-Locky again, who joined them, although reluctantly.\n",
            "\n",
            "As they approached the ancient oak, they saw the wise old owl perched on a branch, his wise eyes twinkling in the sun. Henny-Penny shared her fears, her voice quivering with anxiety.\n",
            "\n",
            "\"Henny-Penny,\" the owl began, \"I have heard many tales of the sky falling, but I have never seen it with my own eyes. I believe you are worrying about nothing more than a simple acorn. But fear not, for I have a lesson for you and your friends.\"\n",
            "\n",
            "The four friends listened intently as the owl spoke. \"When one faces a problem, it is important to think clearly and not let fear cloud your judgment. If you allow fear to guide you, you may find yourself running from shadows rather than facing the truth.\"\n",
            "\n",
            "\"But what if the sky is truly falling?\" asked Henny-Penny, her eyes wide with fear.\n",
            "\n",
            "\"Then we will all face our fate together,\" the owl replied. \"But until then, let us not let fear control us. Now, go back to your home and live your lives without fear.\"\n",
            "\n",
            "With newfound courage, Henny-Penny and her friends returned to the valley. They lived out their days in peace, their lives filled with laughter and joy, and they never forgot the lesson the wise old owl had taught them.\n",
            "\n",
            "From that day on, whenever one of them encountered a problem, they would remember the wise words of the owl and face their fears with courage. And Henny-Penny, who was once known for her loud cries and fears, became a symbol of courage and wisdom in the valley.\n",
            "\n",
            "And so, the story of Henny-Penny and the wise old owl serves as a reminder to us all that fear should not control us, and that with courage and wisdom, we can face any challenge that comes our way.\n",
            "\n",
            "And they all lived happily ever after. The end.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 608\n",
            "Lexicon Count: 478\n",
            "Sentence Count: 34\n",
            "Flesch Reading Ease: 82.54\n",
            "Flesch-Kincaid Grade Level: 5.2\n",
            "Gunning Fog: 6.31\n",
            "SMOG Index: 8.2\n",
            "Automated Readability Index: 7.0\n",
            "Coleman-Liau Index: 6.95\n",
            "Linsear Write Formula: 5.875\n",
            "Dale-Chall Readability Score: 6.62\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 31.85\n",
            "\n",
            "Response from mistral-large@aws-bedrock:\n",
            "Once upon a time in a peaceful animal kingdom, lived a cheerful hen named Henny-Penny. She was not just an ordinary hen, but one with a vivid imagination and an adventurous spirit. Henny-Penny was known throughout the kingdom for her beautiful, glossy feathers and her delicious, golden eggs.\n",
            "\n",
            "One sunny morning, as Henny-Penny was pecking for food, an acorn suddenly fell from the sky and landed on her head. Startled, she exclaimed, \"Oh my! The sky is falling! I must warn the king!\"\n",
            "\n",
            "With a flutter of her wings, she set off to spread the news. Along the way, she met her friend, Cacky-Wacky, the duck. \"Cacky-Wacky, the sky is falling! Come with me to warn the king,\" she squawked. Cacky-Wacky, though initially skeptical, decided to join Henny-Penny on her quest.\n",
            "\n",
            "As they journeyed, they encountered Dazy-Lazy, the dog, who was lounging in the sun. Henny-Penny and Cacky-Wacky shared their news, and Dazy-Lazy, despite his lazy nature, decided to join them, fearing for his safety.\n",
            "\n",
            "The trio continued their journey, meeting Turky-Lurky, the turkey, and Buzzy-Wuzzy, the bee, along the way. Each animal, upon hearing the news, joined the group, and together, they set off to warn the king.\n",
            "\n",
            "Finally, they reached the palace and were granted an audience with the wise and kind King Lion. Henny-Penny, with her friends by her side, told the king about the falling sky. The king, however, was not alarmed. He asked Henny-Penny to describe what had happened.\n",
            "\n",
            "After listening to her story, the king smiled gently and said, \"My dear friends, the sky is not falling. An acorn fell from the tree, that's all. It is natural for acorns to fall from trees, especially on a windy day.\"\n",
            "\n",
            "Henny-Penny and her friends felt relieved but also a little embarrassed. They thanked the king for his wisdom and returned to their homes, their hearts filled with newfound knowledge.\n",
            "\n",
            "From that day forward, Henny-Penny learned to look more carefully at the world around her and to think before she acted. And whenever she heard a wild tale, she would remember the day she thought the sky was falling and smile.\n",
            "\n",
            "And so, the animal kingdom returned to its peaceful state, with Henny-Penny, Cacky-Wacky, Dazy-Lazy, Turky-Lurky, and Buzzy-Wuzzy living happily, wiser from their shared adventure. And they all lived happily ever after.\n",
            "\n",
            "The end.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 537\n",
            "Lexicon Count: 388\n",
            "Sentence Count: 29\n",
            "Flesch Reading Ease: 74.79\n",
            "Flesch-Kincaid Grade Level: 6.2\n",
            "Gunning Fog: 7.01\n",
            "SMOG Index: 9.8\n",
            "Automated Readability Index: 8.7\n",
            "Coleman-Liau Index: 9.27\n",
            "Linsear Write Formula: 5.666666666666667\n",
            "Dale-Chall Readability Score: 7.11\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 28.31\n",
            "\n",
            "Response from mistral-small@mistral-ai:\n",
            "Once upon a time, in a verdant green forest, lived a plump and chatty hen named Henny-Penny. Henny-Penny was known far and wide for her golden eggs and her love for gossip.\n",
            "\n",
            "One sunny morning, as Henny-Penny was pecking at the ground, she felt a sudden tap on her head. Startled, she looked up and saw an acorn falling from a tree. \"Oh, no!\" she cried, \"The sky is falling! The sky is falling!\"\n",
            "\n",
            "Henny-Penny, in her panic, decided to warn the king of the forest about the impending doom. She set off on her journey, chattering about the falling sky to anyone she met.\n",
            "\n",
            "The first to join her was Cocky Locky, a proud rooster who was always eager for an adventure. Then came Ducky Lucky, a lucky duck who was curious about the commotion. They were soon joined by Goosey Loosey, Goosey Slightly, and Turkey Lurkey, each more worried than the last.\n",
            "\n",
            "As they journeyed through the forest, they encountered many obstacles, but their fear of the sky kept them moving. They crossed a rushing river with the help of Ducky Lucky, climbed a steep hill with Goosey Loosey's strong wings, and even outsmarted a sly fox with Turkey Lurkey's quick thinking.\n",
            "\n",
            "Finally, they reached the king's castle. Panting and exhausted, Henny-Penny told the king about the falling sky. The king, wise and patient, asked Henny-Penny to show him where it was happening.\n",
            "\n",
            "Henny-Penny led the king to the spot where she had been when the acorn fell. The king looked up, plucked an acorn from the tree, and showed it to Henny-Penny. \"This, my dear Henny-Penny, is not the sky. It's an acorn.\"\n",
            "\n",
            "Henny-Penny was embarrassed, but the king, seeing her good intention, laughed and thanked her for her concern. He then invited all the animals to a grand feast in the castle.\n",
            "\n",
            "From that day forward, Henny-Penny was more careful with her words, and the forest animals learned to check their facts before causing a panic. And they all lived happily, knowing that the sky was not falling after all.\n",
            "\n",
            "And so, the tale of Henny-Penny serves as a reminder to us all: think before you speak and don't believe everything you hear.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 480\n",
            "Lexicon Count: 367\n",
            "Sentence Count: 25\n",
            "Flesch Reading Ease: 81.93\n",
            "Flesch-Kincaid Grade Level: 5.5\n",
            "Gunning Fog: 7.41\n",
            "SMOG Index: 9.5\n",
            "Automated Readability Index: 7.8\n",
            "Coleman-Liau Index: 7.76\n",
            "Linsear Write Formula: 6.125\n",
            "Dale-Chall Readability Score: 6.99\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 25.08\n",
            "\n",
            "Response from mixtral-8x22b-instruct-v0.1@deepinfra:\n",
            "In the heart of the countryside, there was a peaceful little farm where all the animals lived in harmony. Among them was a kind and gentle hen named Henny-Penny. She was loved by all the animals for her warmth and kindness.\n",
            "\n",
            "One sunny morning, as Henny-Penny was pecking for seeds, she felt something hard and heavy hit her head. She looked up and saw an acorn on the ground. Startled, she thought to herself, \"The sky is falling! I must warn the others.\"\n",
            "\n",
            "Henny-Penny hurried to tell her friends about the falling sky. Her first stop was to see her good friend Goosey-Loosey, who was taking a leisurely swim in the pond. \"Goosey-Loosey,\" she called, \"The sky is falling! We must warn the king!\"\n",
            "\n",
            "Goosey-Loosey was alarmed and agreed to join Henny-Penny on her journey to the castle. They soon met Cocky-Locky, the rooster, and Ducky-Lucky, the duck, who also agreed to join them. Together, they continued their journey, gathering more animals along the way.\n",
            "\n",
            "As they traveled, the animals met a cunning fox named Foxy-Foxy, who overheard their conversation. Foxy-Foxy saw an opportunity and said, \"I know a shortcut to the castle. Follow me.\"\n",
            "\n",
            "The animals, eager to warn the king, followed Foxy-Foxy into the dense forest. As they walked, Foxy-Foxy began to lag behind, and the animals realized they were lost. Suddenly, Foxy-Foxy lunged at Ducky-Lucky, trying to make a meal out of her.\n",
            "\n",
            "Henny-Penny, seeing the danger, quickly came up with a plan. She called out, \"Everyone, spread your wings and fly up into the trees!\" The animals, startled by Henny-Penny's command, did as they were told.\n",
            "\n",
            "Foxy-Foxy, seeing the animals fly away, growled in frustration. The animals, now safe in the trees, realized that Henny-Penny had saved them. They thanked her for her quick thinking and bravery.\n",
            "\n",
            "As they made their way back to the farm, Henny-Penny realized that the acorn had simply fallen from a tree and that the sky was not falling after all. She apologized to her friends for causing such a fuss, but they assured her that they were glad to have had the adventure.\n",
            "\n",
            "From that day forward, the animals of the farm knew that Henny-Penny was not only kind and gentle but also brave and clever. And they lived happily ever after. The end.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 528\n",
            "Lexicon Count: 384\n",
            "Sentence Count: 29\n",
            "Flesch Reading Ease: 75.0\n",
            "Flesch-Kincaid Grade Level: 6.1\n",
            "Gunning Fog: 6.43\n",
            "SMOG Index: 9.7\n",
            "Automated Readability Index: 7.8\n",
            "Coleman-Liau Index: 8.16\n",
            "Linsear Write Formula: 5.333333333333333\n",
            "Dale-Chall Readability Score: 6.64\n",
            "Text Standard: 6th and 7th grade\n",
            "Reading Time (seconds): 27.07\n",
            "\n",
            "Response from mixtral-8x7b-instruct-v0.1@aws-bedrock:\n",
            "Once upon a time, in a peaceful meadow filled with colorful wildflowers, there lived a cheerful little chicken named Henny-Penny. Henny-Penny was known throughout the meadow for her bright red feathers and her infectious laughter. She loved to play with her friends and explore the meadow, always curious and full of joy.\n",
            "\n",
            "One sunny afternoon, as Henny-Penny was pecking at the ground, she suddenly heard a loud *THUD* nearby. Startled, she looked up and saw an acorn had fallen from a tree and hit the ground just a few inches from her feet.\n",
            "\n",
            "\"Oh my!\" exclaimed Henny-Penny, \"I think that acorn is trying to tell me something!\" And with that, she became convinced that the sky was falling.\n",
            "\n",
            "Henny-Penny was so frightened that she decided to warn all her friends in the meadow about the impending doom. She gathered her friends Cocky-Locky, Ducky-Lucky, and Goosey-Loosey, and together they set off on a journey to find the wise old owl who lived in the forest.\n",
            "\n",
            "As they traveled, they encountered various creatures who offered to help them, but Henny-Penny was too focused on her mission to listen. A cunning fox offered to show them the way, but Henny-Penny refused, fearing he would lead them astray. A wise old tortoise offered them a ride on his shell, but Henny-Penny was too worried about the sky to accept.\n",
            "\n",
            "Finally, they reached the wise old owl's tree, and Henny-Penny excitedly told him about the falling sky. The wise old owl listened patiently, then gently explained, \"My dear Henny-Penny, an acorn falling from a tree is not a sign of the sky falling. It's just the natural way of things.\"\n",
            "\n",
            "Relieved and embarrassed, Henny-Penny realized her mistake. She thanked the wise old owl and returned to the meadow with her friends. From that day on, Henny-Penny learned to listen to others and to not jump to conclusions without understanding the facts.\n",
            "\n",
            "And so, the meadow returned to its peaceful ways, and Henny-Penny and her friends lived happily ever after, cherishing the wisdom they had gained on their journey.\n",
            "\n",
            "The end.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 484\n",
            "Lexicon Count: 345\n",
            "Sentence Count: 19\n",
            "Flesch Reading Ease: 69.92\n",
            "Flesch-Kincaid Grade Level: 8.0\n",
            "Gunning Fog: 9.25\n",
            "SMOG Index: 11.0\n",
            "Automated Readability Index: 10.6\n",
            "Coleman-Liau Index: 9.51\n",
            "Linsear Write Formula: 9.0\n",
            "Dale-Chall Readability Score: 7.74\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 24.72\n",
            "\n",
            "Response from qwen-2-72b-instruct@deepinfra:\n",
            "Once upon a time, in a quaint village nestled deep within a lush forest, lived a curious little hen named Henny-Penny. Henny-Penny was known far and wide for her quick wit and her endless curiosity. One sunny morning, as she pecked at the grass, she noticed the sky was a peculiar shade of orange and the leaves were whispering secrets under the gentle caress of the autumn breeze.\n",
            "\n",
            "As Henny-Penny continued her exploration, she suddenly saw a huge, ominous shadow pass over the sun. She turned around, her feathers fluffed up in alarm, and saw an enormous bird with a beak as sharp as a scythe. It was the Great Gnasher, the vulture of the forest, known for carrying off sheep and other small creatures. The Great Gnasher was hungry and, seeing Henny-Penny, saw his chance for a tasty snack.\n",
            "\n",
            "Henny-Penny, however, was not one to be taken down without a fight. She bravely ran towards the Great Gnasher, squawking at the top of her lungs. The Great Gnasher, taken by surprise, tried to peck at her, but Henny-Penny dodged, feinted left, and then darted right, leaving the Great Gnasher in confusion. \n",
            "\n",
            "In her frantic dash, Henny-Penny stumbled upon a wise old owl perched atop a tall oak tree. The owl, known for its keen eyesight and wisdom, watched Henny-Penny's antics with amusement and offered her some advice. \"Henny-Penny,\" the owl said, \"you must be brave and clever to survive. The Great Gnasher is a crafty foe. He may be scared away by your courage and quick thinking.\"\n",
            "\n",
            "With renewed confidence, Henny-Penny faced the Great Gnasher again. This time, she noticed the feathers on the Great Gnasher's wings were not as smooth as they seemed. She pecked at one, causing a flurry of feathers to scatter in the wind. The Great Gnasher, enraged by the sudden loss of his feathers, attacked Henny-Penny with all his might.\n",
            "\n",
            "Henny-Penny, clever as ever, outmaneuvered the Great Gnasher with her nimble feet and sharp beak. The Great Gnasher soon found himself in a flurry of feathers, unable to catch his prey. Realizing he was not as formidable as he seemed, and that he had been outwitted by a little hen, the Great Gnasher flew off into the distance, vowing never to return.\n",
            "\n",
            "Henny-Penny had saved the day, and her bravery became a legend in the village. The villagers, once afraid of the Great Gnasher, now celebrated their little hero. They built a statue of Henny-Penny and placed it in the village square, a reminder of the importance of courage, cleverness, and unity.\n",
            "\n",
            "And so, for many generations, the tale of Henny-Penny, the brave little hen, lived on, inspiring all to face their fears and stand up for what is right.\n",
            "\n",
            "Readability Metrics:\n",
            "Syllable Count: 626\n",
            "Lexicon Count: 456\n",
            "Sentence Count: 26\n",
            "Flesch Reading Ease: 70.63\n",
            "Flesch-Kincaid Grade Level: 7.8\n",
            "Gunning Fog: 8.67\n",
            "SMOG Index: 9.8\n",
            "Automated Readability Index: 9.8\n",
            "Coleman-Liau Index: 8.81\n",
            "Linsear Write Formula: 12.0\n",
            "Dale-Chall Readability Score: 7.69\n",
            "Text Standard: 7th and 8th grade\n",
            "Reading Time (seconds): 31.88\n",
            "Responses and readability metrics saved to Henny-Penny_readability_score.csv, Henny-Penny_readability_score.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/Henny-Penny_readability_score.csv')\n",
        "pivot_df = df.pivot(index='model', columns='metric', values='value')\n",
        "\n",
        "pivot_df.reset_index(inplace=True)\n",
        "pivot_df.to_excel('Henny-Penny.xlsx', index=False)"
      ],
      "metadata": {
        "id": "98M7-tGfq03K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w2r87h7KrDkC",
        "outputId": "492f1159-e05e-418c-e30a-fb95202677c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "metric                                   model Automated Readability Index  \\\n",
              "0                     claude-3-haiku@anthropic                         6.6   \n",
              "1                      claude-3-opus@anthropic                         6.8   \n",
              "2                  claude-3.5-sonnet@anthropic                         9.1   \n",
              "3                   gemini-1.5-flash@vertex-ai                         6.5   \n",
              "4                     gemini-1.5-pro@vertex-ai                         8.3   \n",
              "5                   gemma-2-9b-it@fireworks-ai                         8.9   \n",
              "6                      gemma-2b-it@together-ai                         6.9   \n",
              "7                         gpt-3.5-turbo@openai                        12.8   \n",
              "8                           gpt-4-turbo@openai                         6.8   \n",
              "9                                 gpt-4@openai                         8.1   \n",
              "10                               gpt-4o@openai                         8.0   \n",
              "11               llama-3-70b-chat@fireworks-ai                        12.0   \n",
              "12                llama-3-8b-chat@fireworks-ai                         8.0   \n",
              "13        mistral-7b-instruct-v0.3@together-ai                         7.0   \n",
              "14                   mistral-large@aws-bedrock                         8.7   \n",
              "15                    mistral-small@mistral-ai                         7.8   \n",
              "16       mixtral-8x22b-instruct-v0.1@deepinfra                         7.8   \n",
              "17      mixtral-8x7b-instruct-v0.1@aws-bedrock                        10.6   \n",
              "18                               original_text                        13.5   \n",
              "19               qwen-2-72b-instruct@deepinfra                         9.8   \n",
              "\n",
              "metric Coleman-Liau Index Dale-Chall Readability Score Flesch Reading Ease  \\\n",
              "0                    7.23                         6.46               85.59   \n",
              "1                    7.24                         5.99               84.37   \n",
              "2                    9.16                         7.04               74.08   \n",
              "3                     7.4                         6.84                86.2   \n",
              "4                    9.15                         7.95               76.01   \n",
              "5                    9.72                         7.31               77.84   \n",
              "6                    7.24                         6.71               83.36   \n",
              "7                   10.33                         7.59               65.46   \n",
              "8                    7.53                         6.94               84.88   \n",
              "9                    8.63                         7.29               83.66   \n",
              "10                    9.2                         6.88               78.14   \n",
              "11                  11.25                         8.91               70.13   \n",
              "12                   7.53                         6.63               81.33   \n",
              "13                   6.95                         6.62               82.54   \n",
              "14                   9.27                         7.11               74.79   \n",
              "15                   7.76                         6.99               81.93   \n",
              "16                   8.16                         6.64                75.0   \n",
              "17                   9.51                         7.74               69.92   \n",
              "18                  12.87                          1.4               65.83   \n",
              "19                   8.81                         7.69               70.63   \n",
              "\n",
              "metric Flesch-Kincaid Grade Level Gunning Fog Lexicon Count  \\\n",
              "0                             4.1        5.22           410   \n",
              "1                             4.5        5.73           344   \n",
              "2                             6.4        6.82           408   \n",
              "3                             3.8        5.44           453   \n",
              "4                             5.7        6.55           502   \n",
              "5                             5.0        5.67           611   \n",
              "6                             4.9        6.76           360   \n",
              "7                             9.7       11.25           362   \n",
              "8                             4.4         5.7           615   \n",
              "9                             4.8        6.41           430   \n",
              "10                            4.9        5.48           638   \n",
              "11                            8.0        9.95           523   \n",
              "12                            5.7        7.05           474   \n",
              "13                            5.2        6.31           478   \n",
              "14                            6.2        7.01           388   \n",
              "15                            5.5        7.41           367   \n",
              "16                            6.1        6.43           384   \n",
              "17                            8.0        9.25           345   \n",
              "18                            7.5        5.56           669   \n",
              "19                            7.8        8.67           456   \n",
              "\n",
              "metric Linsear Write Formula Reading Time (seconds) SMOG Index Sentence Count  \\\n",
              "0                        6.5                   28.7        8.0             37   \n",
              "1          5.555555555555555                  23.67        8.9             28   \n",
              "2                        7.0                  29.84        9.5             29   \n",
              "3                        7.0                  31.99        8.5             43   \n",
              "4                      6.125                  36.92        8.8             41   \n",
              "5          5.444444444444445                  47.92        8.6             59   \n",
              "6                       6.25                  24.28        8.9             27   \n",
              "7                       11.6                  25.85       12.2             16   \n",
              "8          8.833333333333334                  42.73        8.4             52   \n",
              "9                        7.0                   30.8        8.8             33   \n",
              "10         8.666666666666666                  48.51        8.7             63   \n",
              "11                       9.0                  39.77       11.1             29   \n",
              "12                      12.0                   32.2        9.1             31   \n",
              "13                     5.875                  31.85        8.2             34   \n",
              "14         5.666666666666667                  28.31        9.8             29   \n",
              "15                     6.125                  25.08        9.5             25   \n",
              "16         5.333333333333333                  27.07        9.7             29   \n",
              "17                       9.0                  24.72       11.0             19   \n",
              "18         4.636363636363637                  58.39       11.2             48   \n",
              "19                      12.0                  31.88        9.8             26   \n",
              "\n",
              "metric Syllable Count        Text Standard  \n",
              "0                 532    6th and 7th grade  \n",
              "1                 459    5th and 6th grade  \n",
              "2                 567    6th and 7th grade  \n",
              "3                 598    6th and 7th grade  \n",
              "4                 687    6th and 7th grade  \n",
              "5                 860    8th and 9th grade  \n",
              "6                 467    6th and 7th grade  \n",
              "7                 513  11th and 12th grade  \n",
              "8                 815    6th and 7th grade  \n",
              "9                 579    8th and 9th grade  \n",
              "10                899    8th and 9th grade  \n",
              "11                755  11th and 12th grade  \n",
              "12                621    7th and 8th grade  \n",
              "13                608    6th and 7th grade  \n",
              "14                537    6th and 7th grade  \n",
              "15                480    7th and 8th grade  \n",
              "16                528    6th and 7th grade  \n",
              "17                484    7th and 8th grade  \n",
              "18                979    7th and 8th grade  \n",
              "19                626    7th and 8th grade  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-882066f1-b6a8-4e3e-8538-0c62ed282dfe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>metric</th>\n",
              "      <th>model</th>\n",
              "      <th>Automated Readability Index</th>\n",
              "      <th>Coleman-Liau Index</th>\n",
              "      <th>Dale-Chall Readability Score</th>\n",
              "      <th>Flesch Reading Ease</th>\n",
              "      <th>Flesch-Kincaid Grade Level</th>\n",
              "      <th>Gunning Fog</th>\n",
              "      <th>Lexicon Count</th>\n",
              "      <th>Linsear Write Formula</th>\n",
              "      <th>Reading Time (seconds)</th>\n",
              "      <th>SMOG Index</th>\n",
              "      <th>Sentence Count</th>\n",
              "      <th>Syllable Count</th>\n",
              "      <th>Text Standard</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>claude-3-haiku@anthropic</td>\n",
              "      <td>6.6</td>\n",
              "      <td>7.23</td>\n",
              "      <td>6.46</td>\n",
              "      <td>85.59</td>\n",
              "      <td>4.1</td>\n",
              "      <td>5.22</td>\n",
              "      <td>410</td>\n",
              "      <td>6.5</td>\n",
              "      <td>28.7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>37</td>\n",
              "      <td>532</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>claude-3-opus@anthropic</td>\n",
              "      <td>6.8</td>\n",
              "      <td>7.24</td>\n",
              "      <td>5.99</td>\n",
              "      <td>84.37</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.73</td>\n",
              "      <td>344</td>\n",
              "      <td>5.555555555555555</td>\n",
              "      <td>23.67</td>\n",
              "      <td>8.9</td>\n",
              "      <td>28</td>\n",
              "      <td>459</td>\n",
              "      <td>5th and 6th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>claude-3.5-sonnet@anthropic</td>\n",
              "      <td>9.1</td>\n",
              "      <td>9.16</td>\n",
              "      <td>7.04</td>\n",
              "      <td>74.08</td>\n",
              "      <td>6.4</td>\n",
              "      <td>6.82</td>\n",
              "      <td>408</td>\n",
              "      <td>7.0</td>\n",
              "      <td>29.84</td>\n",
              "      <td>9.5</td>\n",
              "      <td>29</td>\n",
              "      <td>567</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gemini-1.5-flash@vertex-ai</td>\n",
              "      <td>6.5</td>\n",
              "      <td>7.4</td>\n",
              "      <td>6.84</td>\n",
              "      <td>86.2</td>\n",
              "      <td>3.8</td>\n",
              "      <td>5.44</td>\n",
              "      <td>453</td>\n",
              "      <td>7.0</td>\n",
              "      <td>31.99</td>\n",
              "      <td>8.5</td>\n",
              "      <td>43</td>\n",
              "      <td>598</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gemini-1.5-pro@vertex-ai</td>\n",
              "      <td>8.3</td>\n",
              "      <td>9.15</td>\n",
              "      <td>7.95</td>\n",
              "      <td>76.01</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.55</td>\n",
              "      <td>502</td>\n",
              "      <td>6.125</td>\n",
              "      <td>36.92</td>\n",
              "      <td>8.8</td>\n",
              "      <td>41</td>\n",
              "      <td>687</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gemma-2-9b-it@fireworks-ai</td>\n",
              "      <td>8.9</td>\n",
              "      <td>9.72</td>\n",
              "      <td>7.31</td>\n",
              "      <td>77.84</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.67</td>\n",
              "      <td>611</td>\n",
              "      <td>5.444444444444445</td>\n",
              "      <td>47.92</td>\n",
              "      <td>8.6</td>\n",
              "      <td>59</td>\n",
              "      <td>860</td>\n",
              "      <td>8th and 9th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gemma-2b-it@together-ai</td>\n",
              "      <td>6.9</td>\n",
              "      <td>7.24</td>\n",
              "      <td>6.71</td>\n",
              "      <td>83.36</td>\n",
              "      <td>4.9</td>\n",
              "      <td>6.76</td>\n",
              "      <td>360</td>\n",
              "      <td>6.25</td>\n",
              "      <td>24.28</td>\n",
              "      <td>8.9</td>\n",
              "      <td>27</td>\n",
              "      <td>467</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>gpt-3.5-turbo@openai</td>\n",
              "      <td>12.8</td>\n",
              "      <td>10.33</td>\n",
              "      <td>7.59</td>\n",
              "      <td>65.46</td>\n",
              "      <td>9.7</td>\n",
              "      <td>11.25</td>\n",
              "      <td>362</td>\n",
              "      <td>11.6</td>\n",
              "      <td>25.85</td>\n",
              "      <td>12.2</td>\n",
              "      <td>16</td>\n",
              "      <td>513</td>\n",
              "      <td>11th and 12th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>gpt-4-turbo@openai</td>\n",
              "      <td>6.8</td>\n",
              "      <td>7.53</td>\n",
              "      <td>6.94</td>\n",
              "      <td>84.88</td>\n",
              "      <td>4.4</td>\n",
              "      <td>5.7</td>\n",
              "      <td>615</td>\n",
              "      <td>8.833333333333334</td>\n",
              "      <td>42.73</td>\n",
              "      <td>8.4</td>\n",
              "      <td>52</td>\n",
              "      <td>815</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gpt-4@openai</td>\n",
              "      <td>8.1</td>\n",
              "      <td>8.63</td>\n",
              "      <td>7.29</td>\n",
              "      <td>83.66</td>\n",
              "      <td>4.8</td>\n",
              "      <td>6.41</td>\n",
              "      <td>430</td>\n",
              "      <td>7.0</td>\n",
              "      <td>30.8</td>\n",
              "      <td>8.8</td>\n",
              "      <td>33</td>\n",
              "      <td>579</td>\n",
              "      <td>8th and 9th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>gpt-4o@openai</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.2</td>\n",
              "      <td>6.88</td>\n",
              "      <td>78.14</td>\n",
              "      <td>4.9</td>\n",
              "      <td>5.48</td>\n",
              "      <td>638</td>\n",
              "      <td>8.666666666666666</td>\n",
              "      <td>48.51</td>\n",
              "      <td>8.7</td>\n",
              "      <td>63</td>\n",
              "      <td>899</td>\n",
              "      <td>8th and 9th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>llama-3-70b-chat@fireworks-ai</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.25</td>\n",
              "      <td>8.91</td>\n",
              "      <td>70.13</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.95</td>\n",
              "      <td>523</td>\n",
              "      <td>9.0</td>\n",
              "      <td>39.77</td>\n",
              "      <td>11.1</td>\n",
              "      <td>29</td>\n",
              "      <td>755</td>\n",
              "      <td>11th and 12th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>llama-3-8b-chat@fireworks-ai</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.53</td>\n",
              "      <td>6.63</td>\n",
              "      <td>81.33</td>\n",
              "      <td>5.7</td>\n",
              "      <td>7.05</td>\n",
              "      <td>474</td>\n",
              "      <td>12.0</td>\n",
              "      <td>32.2</td>\n",
              "      <td>9.1</td>\n",
              "      <td>31</td>\n",
              "      <td>621</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>mistral-7b-instruct-v0.3@together-ai</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.95</td>\n",
              "      <td>6.62</td>\n",
              "      <td>82.54</td>\n",
              "      <td>5.2</td>\n",
              "      <td>6.31</td>\n",
              "      <td>478</td>\n",
              "      <td>5.875</td>\n",
              "      <td>31.85</td>\n",
              "      <td>8.2</td>\n",
              "      <td>34</td>\n",
              "      <td>608</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mistral-large@aws-bedrock</td>\n",
              "      <td>8.7</td>\n",
              "      <td>9.27</td>\n",
              "      <td>7.11</td>\n",
              "      <td>74.79</td>\n",
              "      <td>6.2</td>\n",
              "      <td>7.01</td>\n",
              "      <td>388</td>\n",
              "      <td>5.666666666666667</td>\n",
              "      <td>28.31</td>\n",
              "      <td>9.8</td>\n",
              "      <td>29</td>\n",
              "      <td>537</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>mistral-small@mistral-ai</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.76</td>\n",
              "      <td>6.99</td>\n",
              "      <td>81.93</td>\n",
              "      <td>5.5</td>\n",
              "      <td>7.41</td>\n",
              "      <td>367</td>\n",
              "      <td>6.125</td>\n",
              "      <td>25.08</td>\n",
              "      <td>9.5</td>\n",
              "      <td>25</td>\n",
              "      <td>480</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>mixtral-8x22b-instruct-v0.1@deepinfra</td>\n",
              "      <td>7.8</td>\n",
              "      <td>8.16</td>\n",
              "      <td>6.64</td>\n",
              "      <td>75.0</td>\n",
              "      <td>6.1</td>\n",
              "      <td>6.43</td>\n",
              "      <td>384</td>\n",
              "      <td>5.333333333333333</td>\n",
              "      <td>27.07</td>\n",
              "      <td>9.7</td>\n",
              "      <td>29</td>\n",
              "      <td>528</td>\n",
              "      <td>6th and 7th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>mixtral-8x7b-instruct-v0.1@aws-bedrock</td>\n",
              "      <td>10.6</td>\n",
              "      <td>9.51</td>\n",
              "      <td>7.74</td>\n",
              "      <td>69.92</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.25</td>\n",
              "      <td>345</td>\n",
              "      <td>9.0</td>\n",
              "      <td>24.72</td>\n",
              "      <td>11.0</td>\n",
              "      <td>19</td>\n",
              "      <td>484</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>original_text</td>\n",
              "      <td>13.5</td>\n",
              "      <td>12.87</td>\n",
              "      <td>1.4</td>\n",
              "      <td>65.83</td>\n",
              "      <td>7.5</td>\n",
              "      <td>5.56</td>\n",
              "      <td>669</td>\n",
              "      <td>4.636363636363637</td>\n",
              "      <td>58.39</td>\n",
              "      <td>11.2</td>\n",
              "      <td>48</td>\n",
              "      <td>979</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>qwen-2-72b-instruct@deepinfra</td>\n",
              "      <td>9.8</td>\n",
              "      <td>8.81</td>\n",
              "      <td>7.69</td>\n",
              "      <td>70.63</td>\n",
              "      <td>7.8</td>\n",
              "      <td>8.67</td>\n",
              "      <td>456</td>\n",
              "      <td>12.0</td>\n",
              "      <td>31.88</td>\n",
              "      <td>9.8</td>\n",
              "      <td>26</td>\n",
              "      <td>626</td>\n",
              "      <td>7th and 8th grade</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-882066f1-b6a8-4e3e-8538-0c62ed282dfe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-882066f1-b6a8-4e3e-8538-0c62ed282dfe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-882066f1-b6a8-4e3e-8538-0c62ed282dfe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4b020012-83e5-4f9b-aaf9-b4c169d31649\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4b020012-83e5-4f9b-aaf9-b4c169d31649')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4b020012-83e5-4f9b-aaf9-b4c169d31649 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_483e091b-dd41-4eff-aa0a-a8172b8ca83f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pivot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_483e091b-dd41-4eff-aa0a-a8172b8ca83f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pivot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pivot_df",
              "summary": "{\n  \"name\": \"pivot_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"claude-3-haiku@anthropic\",\n          \"mixtral-8x7b-instruct-v0.1@aws-bedrock\",\n          \"mistral-small@mistral-ai\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Automated Readability Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"6.6\",\n          \"6.8\",\n          \"8.9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coleman-Liau Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"7.23\",\n          \"7.24\",\n          \"8.63\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dale-Chall Readability Score\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"6.46\",\n          \"7.74\",\n          \"6.99\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flesch Reading Ease\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"85.59\",\n          \"69.92\",\n          \"81.93\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flesch-Kincaid Grade Level\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"4.1\",\n          \"4.5\",\n          \"5.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gunning Fog\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"5.22\",\n          \"9.25\",\n          \"7.41\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lexicon Count\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"410\",\n          \"345\",\n          \"367\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Linsear Write Formula\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"9.0\",\n          \"5.875\",\n          \"6.5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading Time (seconds)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"28.7\",\n          \"24.72\",\n          \"25.08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMOG Index\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"8.0\",\n          \"8.9\",\n          \"8.6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence Count\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"37\",\n          \"28\",\n          \"59\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Syllable Count\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"532\",\n          \"484\",\n          \"480\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text Standard\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"5th and 6th grade\",\n          \"7th and 8th grade\",\n          \"8th and 9th grade\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "df = pd.read_csv(\"/content/Henny-Penny_readability_score.csv\")\n",
        "\n",
        "metric_directions = {\n",
        "    \"Syllable Count\": \"lower\",\n",
        "    \"Lexicon Count\": \"higher\",\n",
        "    \"Sentence Count\": \"higher\",\n",
        "    \"Flesch Reading Ease\": \"higher\",\n",
        "    \"Flesch-Kincaid Grade Level\": \"lower\",\n",
        "    \"Gunning Fog\": \"lower\",\n",
        "    \"SMOG Index\": \"lower\",\n",
        "    \"Automated Readability Index\": \"lower\",\n",
        "    \"Coleman-Liau Index\": \"lower\",\n",
        "    \"Linsear Write Formula\": \"lower\",\n",
        "    \"Dale-Chall Readability Score\": \"lower\",\n",
        "    \"Text Standard\": \"lower\",\n",
        "    \"Reading Time (seconds)\": \"lower\"\n",
        "}\n",
        "\n",
        "pivot_df = df.pivot(index='model', columns='metric', values='value')\n",
        "if 'Text Standard' in pivot_df.columns:\n",
        "    pivot_df = pivot_df.drop(\"Text Standard\", axis=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "normalized_df = pd.DataFrame(scaler.fit_transform(pivot_df), columns=pivot_df.columns, index=pivot_df.index)\n",
        "\n",
        "for metric, direction in metric_directions.items():\n",
        "    if direction == \"lower\" and metric in normalized_df.columns:\n",
        "        normalized_df[metric] = 1 - normalized_df[metric]\n",
        "\n",
        "normalized_df['Composite Score'] = normalized_df.mean(axis=1)\n",
        "original_text_score = normalized_df.loc['original_text', 'Composite Score']\n",
        "\n",
        "# differences from the original text\n",
        "normalized_df['Difference'] = (normalized_df['Composite Score'] - original_text_score).abs()\n",
        "\n",
        "# ranking based on similarity to the original text\n",
        "ranking_df = normalized_df[['Composite Score', 'Difference']].sort_values(by='Difference')\n",
        "ranking_df['Rank'] = ranking_df['Difference'].rank()\n",
        "\n",
        "print(\"Ranking of models based on similarity to the original text:\")\n",
        "print(ranking_df)\n",
        "\n",
        "ranking_df.to_csv(\"model_ranking_based_on_similarity_to_original_text_Henny-Penny.csv\")\n",
        "\n",
        "# rankings for each metric independently\n",
        "metric_rankings = {}\n",
        "\n",
        "for metric in pivot_df.columns:\n",
        "    metric_rankings[metric] = normalized_df[[metric]].sort_values(by=metric, ascending=False if metric_directions[metric] == \"higher\" else True)\n",
        "    metric_rankings[metric]['Rank'] = metric_rankings[metric][metric].rank(ascending=False if metric_directions[metric] == \"higher\" else True)\n",
        "\n",
        "    print(f\"\\nRanking based on {metric}:\")\n",
        "    print(metric_rankings[metric])\n",
        "\n",
        "    # Save each metric ranking to a CSV file\n",
        "    metric_rankings[metric].to_csv(f\"model_ranking_based_on_{metric}_Henny-Penny.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWE_O1y5rIwB",
        "outputId": "b9442f4c-319d-4fd5-9387-0662a6a3c730"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking of models based on similarity to the original text:\n",
            "metric                                  Composite Score  Difference  Rank\n",
            "model                                                                    \n",
            "original_text                                  0.437774    0.000000   1.0\n",
            "qwen-2-72b-instruct@deepinfra                  0.412266    0.025507   2.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock         0.387851    0.049923   3.0\n",
            "claude-3.5-sonnet@anthropic                    0.551988    0.114214   4.0\n",
            "llama-3-70b-chat@fireworks-ai                  0.306714    0.131060   5.0\n",
            "mistral-large@aws-bedrock                      0.569965    0.132191   6.0\n",
            "llama-3-8b-chat@fireworks-ai                   0.585920    0.148146   7.0\n",
            "gemini-1.5-pro@vertex-ai                       0.605874    0.168101   8.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra          0.620941    0.183167   9.0\n",
            "gpt-4o@openai                                  0.640567    0.202794  10.0\n",
            "mistral-small@mistral-ai                       0.641490    0.203716  11.0\n",
            "gemma-2-9b-it@fireworks-ai                     0.644618    0.206845  12.0\n",
            "gpt-3.5-turbo@openai                           0.220658    0.217116  13.0\n",
            "gpt-4@openai                                   0.657731    0.219958  14.0\n",
            "gemma-2b-it@together-ai                        0.702079    0.264305  15.0\n",
            "gpt-4-turbo@openai                             0.714798    0.277024  16.0\n",
            "mistral-7b-instruct-v0.3@together-ai           0.724691    0.286918  17.0\n",
            "claude-3-opus@anthropic                        0.743477    0.305703  18.0\n",
            "gemini-1.5-flash@vertex-ai                     0.760501    0.322728  19.0\n",
            "claude-3-haiku@anthropic                       0.774661    0.336887  20.0\n",
            "\n",
            "Ranking based on Automated Readability Index:\n",
            "metric                                  Automated Readability Index  Rank\n",
            "model                                                                    \n",
            "original_text                                          1.110223e-16   1.0\n",
            "gpt-3.5-turbo@openai                                   1.000000e-01   2.0\n",
            "llama-3-70b-chat@fireworks-ai                          2.142857e-01   3.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                 4.142857e-01   4.0\n",
            "qwen-2-72b-instruct@deepinfra                          5.285714e-01   5.0\n",
            "claude-3.5-sonnet@anthropic                            6.285714e-01   6.0\n",
            "gemma-2-9b-it@fireworks-ai                             6.571429e-01   7.0\n",
            "mistral-large@aws-bedrock                              6.857143e-01   8.0\n",
            "gemini-1.5-pro@vertex-ai                               7.428571e-01   9.0\n",
            "gpt-4@openai                                           7.714286e-01  10.0\n",
            "gpt-4o@openai                                          7.857143e-01  11.5\n",
            "llama-3-8b-chat@fireworks-ai                           7.857143e-01  11.5\n",
            "mistral-small@mistral-ai                               8.142857e-01  13.5\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                  8.142857e-01  13.5\n",
            "mistral-7b-instruct-v0.3@together-ai                   9.285714e-01  15.0\n",
            "gemma-2b-it@together-ai                                9.428571e-01  16.0\n",
            "claude-3-opus@anthropic                                9.571429e-01  17.5\n",
            "gpt-4-turbo@openai                                     9.571429e-01  17.5\n",
            "claude-3-haiku@anthropic                               9.857143e-01  19.0\n",
            "gemini-1.5-flash@vertex-ai                             1.000000e+00  20.0\n",
            "\n",
            "Ranking based on Coleman-Liau Index:\n",
            "metric                                  Coleman-Liau Index  Rank\n",
            "model                                                           \n",
            "original_text                                -2.220446e-16   1.0\n",
            "llama-3-70b-chat@fireworks-ai                 2.736486e-01   2.0\n",
            "gpt-3.5-turbo@openai                          4.290541e-01   3.0\n",
            "gemma-2-9b-it@fireworks-ai                    5.320946e-01   4.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock        5.675676e-01   5.0\n",
            "mistral-large@aws-bedrock                     6.081081e-01   6.0\n",
            "gpt-4o@openai                                 6.199324e-01   7.0\n",
            "claude-3.5-sonnet@anthropic                   6.266892e-01   8.0\n",
            "gemini-1.5-pro@vertex-ai                      6.283784e-01   9.0\n",
            "qwen-2-72b-instruct@deepinfra                 6.858108e-01  10.0\n",
            "gpt-4@openai                                  7.162162e-01  11.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra         7.956081e-01  12.0\n",
            "mistral-small@mistral-ai                      8.631757e-01  13.0\n",
            "llama-3-8b-chat@fireworks-ai                  9.020270e-01  14.5\n",
            "gpt-4-turbo@openai                            9.020270e-01  14.5\n",
            "gemini-1.5-flash@vertex-ai                    9.239865e-01  16.0\n",
            "gemma-2b-it@together-ai                       9.510135e-01  17.5\n",
            "claude-3-opus@anthropic                       9.510135e-01  17.5\n",
            "claude-3-haiku@anthropic                      9.527027e-01  19.0\n",
            "mistral-7b-instruct-v0.3@together-ai          1.000000e+00  20.0\n",
            "\n",
            "Ranking based on Dale-Chall Readability Score:\n",
            "metric                                  Dale-Chall Readability Score  Rank\n",
            "model                                                                     \n",
            "llama-3-70b-chat@fireworks-ai                               0.000000   1.0\n",
            "gemini-1.5-pro@vertex-ai                                    0.127830   2.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                      0.155792   3.0\n",
            "qwen-2-72b-instruct@deepinfra                               0.162450   4.0\n",
            "gpt-3.5-turbo@openai                                        0.175766   5.0\n",
            "gemma-2-9b-it@fireworks-ai                                  0.213049   6.0\n",
            "gpt-4@openai                                                0.215712   7.0\n",
            "mistral-large@aws-bedrock                                   0.239680   8.0\n",
            "claude-3.5-sonnet@anthropic                                 0.249001   9.0\n",
            "mistral-small@mistral-ai                                    0.255659  10.0\n",
            "gpt-4-turbo@openai                                          0.262317  11.0\n",
            "gpt-4o@openai                                               0.270306  12.0\n",
            "gemini-1.5-flash@vertex-ai                                  0.275632  13.0\n",
            "gemma-2b-it@together-ai                                     0.292943  14.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                       0.302264  15.0\n",
            "llama-3-8b-chat@fireworks-ai                                0.303595  16.0\n",
            "mistral-7b-instruct-v0.3@together-ai                        0.304927  17.0\n",
            "claude-3-haiku@anthropic                                    0.326232  18.0\n",
            "claude-3-opus@anthropic                                     0.388815  19.0\n",
            "original_text                                               1.000000  20.0\n",
            "\n",
            "Ranking based on Flesch Reading Ease:\n",
            "metric                                  Flesch Reading Ease  Rank\n",
            "model                                                            \n",
            "gemini-1.5-flash@vertex-ai                         1.000000   1.0\n",
            "claude-3-haiku@anthropic                           0.970588   2.0\n",
            "gpt-4-turbo@openai                                 0.936355   3.0\n",
            "claude-3-opus@anthropic                            0.911765   4.0\n",
            "gpt-4@openai                                       0.877531   5.0\n",
            "gemma-2b-it@together-ai                            0.863067   6.0\n",
            "mistral-7b-instruct-v0.3@together-ai               0.823529   7.0\n",
            "mistral-small@mistral-ai                           0.794118   8.0\n",
            "llama-3-8b-chat@fireworks-ai                       0.765188   9.0\n",
            "gpt-4o@openai                                      0.611379  10.0\n",
            "gemma-2-9b-it@fireworks-ai                         0.596914  11.0\n",
            "gemini-1.5-pro@vertex-ai                           0.508679  12.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra              0.459981  13.0\n",
            "mistral-large@aws-bedrock                          0.449855  14.0\n",
            "claude-3.5-sonnet@anthropic                        0.415622  15.0\n",
            "qwen-2-72b-instruct@deepinfra                      0.249277  16.0\n",
            "llama-3-70b-chat@fireworks-ai                      0.225169  17.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock             0.215043  18.0\n",
            "original_text                                      0.017840  19.0\n",
            "gpt-3.5-turbo@openai                               0.000000  20.0\n",
            "\n",
            "Ranking based on Flesch-Kincaid Grade Level:\n",
            "metric                                  Flesch-Kincaid Grade Level  Rank\n",
            "model                                                                   \n",
            "gpt-3.5-turbo@openai                                      0.000000   1.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                    0.288136   2.5\n",
            "llama-3-70b-chat@fireworks-ai                             0.288136   2.5\n",
            "qwen-2-72b-instruct@deepinfra                             0.322034   4.0\n",
            "original_text                                             0.372881   5.0\n",
            "claude-3.5-sonnet@anthropic                               0.559322   6.0\n",
            "mistral-large@aws-bedrock                                 0.593220   7.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                     0.610169   8.0\n",
            "gemini-1.5-pro@vertex-ai                                  0.677966   9.5\n",
            "llama-3-8b-chat@fireworks-ai                              0.677966   9.5\n",
            "mistral-small@mistral-ai                                  0.711864  11.0\n",
            "mistral-7b-instruct-v0.3@together-ai                      0.762712  12.0\n",
            "gemma-2-9b-it@fireworks-ai                                0.796610  13.0\n",
            "gemma-2b-it@together-ai                                   0.813559  14.5\n",
            "gpt-4o@openai                                             0.813559  14.5\n",
            "gpt-4@openai                                              0.830508  16.0\n",
            "claude-3-opus@anthropic                                   0.881356  17.0\n",
            "gpt-4-turbo@openai                                        0.898305  18.0\n",
            "claude-3-haiku@anthropic                                  0.949153  19.0\n",
            "gemini-1.5-flash@vertex-ai                                1.000000  20.0\n",
            "\n",
            "Ranking based on Gunning Fog:\n",
            "metric                                   Gunning Fog  Rank\n",
            "model                                                     \n",
            "gpt-3.5-turbo@openai                    1.110223e-16   1.0\n",
            "llama-3-70b-chat@fireworks-ai           2.155887e-01   2.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock  3.316750e-01   3.0\n",
            "qwen-2-72b-instruct@deepinfra           4.278607e-01   4.0\n",
            "mistral-small@mistral-ai                6.368159e-01   5.0\n",
            "llama-3-8b-chat@fireworks-ai            6.965174e-01   6.0\n",
            "mistral-large@aws-bedrock               7.031509e-01   7.0\n",
            "claude-3.5-sonnet@anthropic             7.346600e-01   8.0\n",
            "gemma-2b-it@together-ai                 7.446103e-01   9.0\n",
            "gemini-1.5-pro@vertex-ai                7.794362e-01  10.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra   7.993367e-01  11.0\n",
            "gpt-4@openai                            8.026534e-01  12.0\n",
            "mistral-7b-instruct-v0.3@together-ai    8.192371e-01  13.0\n",
            "claude-3-opus@anthropic                 9.154229e-01  14.0\n",
            "gpt-4-turbo@openai                      9.203980e-01  15.0\n",
            "gemma-2-9b-it@fireworks-ai              9.253731e-01  16.0\n",
            "original_text                           9.436153e-01  17.0\n",
            "gpt-4o@openai                           9.568823e-01  18.0\n",
            "gemini-1.5-flash@vertex-ai              9.635158e-01  19.0\n",
            "claude-3-haiku@anthropic                1.000000e+00  20.0\n",
            "\n",
            "Ranking based on Lexicon Count:\n",
            "metric                                  Lexicon Count  Rank\n",
            "model                                                      \n",
            "original_text                                1.000000   1.0\n",
            "gpt-4o@openai                                0.904615   2.0\n",
            "gpt-4-turbo@openai                           0.833846   3.0\n",
            "gemma-2-9b-it@fireworks-ai                   0.821538   4.0\n",
            "llama-3-70b-chat@fireworks-ai                0.550769   5.0\n",
            "gemini-1.5-pro@vertex-ai                     0.486154   6.0\n",
            "mistral-7b-instruct-v0.3@together-ai         0.412308   7.0\n",
            "llama-3-8b-chat@fireworks-ai                 0.400000   8.0\n",
            "qwen-2-72b-instruct@deepinfra                0.344615   9.0\n",
            "gemini-1.5-flash@vertex-ai                   0.335385  10.0\n",
            "gpt-4@openai                                 0.264615  11.0\n",
            "claude-3-haiku@anthropic                     0.203077  12.0\n",
            "claude-3.5-sonnet@anthropic                  0.196923  13.0\n",
            "mistral-large@aws-bedrock                    0.135385  14.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra        0.123077  15.0\n",
            "mistral-small@mistral-ai                     0.070769  16.0\n",
            "gpt-3.5-turbo@openai                         0.055385  17.0\n",
            "gemma-2b-it@together-ai                      0.049231  18.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock       0.003077  19.0\n",
            "claude-3-opus@anthropic                      0.000000  20.0\n",
            "\n",
            "Ranking based on Linsear Write Formula:\n",
            "metric                                  Linsear Write Formula  Rank\n",
            "model                                                              \n",
            "qwen-2-72b-instruct@deepinfra                    1.110223e-16   1.5\n",
            "llama-3-8b-chat@fireworks-ai                     1.110223e-16   1.5\n",
            "gpt-3.5-turbo@openai                             5.432099e-02   3.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock           4.074074e-01   4.5\n",
            "llama-3-70b-chat@fireworks-ai                    4.074074e-01   4.5\n",
            "gpt-4-turbo@openai                               4.300412e-01   6.0\n",
            "gpt-4o@openai                                    4.526749e-01   7.0\n",
            "gpt-4@openai                                     6.790123e-01   9.0\n",
            "gemini-1.5-flash@vertex-ai                       6.790123e-01   9.0\n",
            "claude-3.5-sonnet@anthropic                      6.790123e-01   9.0\n",
            "claude-3-haiku@anthropic                         7.469136e-01  11.0\n",
            "gemma-2b-it@together-ai                          7.808642e-01  12.0\n",
            "gemini-1.5-pro@vertex-ai                         7.978395e-01  13.5\n",
            "mistral-small@mistral-ai                         7.978395e-01  13.5\n",
            "mistral-7b-instruct-v0.3@together-ai             8.317901e-01  15.0\n",
            "mistral-large@aws-bedrock                        8.600823e-01  16.0\n",
            "claude-3-opus@anthropic                          8.751715e-01  17.0\n",
            "gemma-2-9b-it@fireworks-ai                       8.902606e-01  18.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra            9.053498e-01  19.0\n",
            "original_text                                    1.000000e+00  20.0\n",
            "\n",
            "Ranking based on Reading Time (seconds):\n",
            "metric                                  Reading Time (seconds)  Rank\n",
            "model                                                               \n",
            "original_text                                     1.110223e-16   1.0\n",
            "gpt-4o@openai                                     2.845622e-01   2.0\n",
            "gemma-2-9b-it@fireworks-ai                        3.015553e-01   3.0\n",
            "gpt-4-turbo@openai                                4.510369e-01   4.0\n",
            "llama-3-70b-chat@fireworks-ai                     5.362903e-01   5.0\n",
            "gemini-1.5-pro@vertex-ai                          6.183756e-01   6.0\n",
            "llama-3-8b-chat@fireworks-ai                      7.543203e-01   7.0\n",
            "gemini-1.5-flash@vertex-ai                        7.603687e-01   8.0\n",
            "qwen-2-72b-instruct@deepinfra                     7.635369e-01   9.0\n",
            "mistral-7b-instruct-v0.3@together-ai              7.644009e-01  10.0\n",
            "gpt-4@openai                                      7.946429e-01  11.0\n",
            "claude-3.5-sonnet@anthropic                       8.222926e-01  12.0\n",
            "claude-3-haiku@anthropic                          8.551267e-01  13.0\n",
            "mistral-large@aws-bedrock                         8.663594e-01  14.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra             9.020737e-01  15.0\n",
            "gpt-3.5-turbo@openai                              9.372120e-01  16.0\n",
            "mistral-small@mistral-ai                          9.593894e-01  17.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock            9.697581e-01  18.0\n",
            "gemma-2b-it@together-ai                           9.824309e-01  19.0\n",
            "claude-3-opus@anthropic                           1.000000e+00  20.0\n",
            "\n",
            "Ranking based on SMOG Index:\n",
            "metric                                  SMOG Index  Rank\n",
            "model                                                   \n",
            "gpt-3.5-turbo@openai                      0.000000   1.0\n",
            "original_text                             0.238095   2.0\n",
            "llama-3-70b-chat@fireworks-ai             0.261905   3.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock    0.285714   4.0\n",
            "qwen-2-72b-instruct@deepinfra             0.571429   5.5\n",
            "mistral-large@aws-bedrock                 0.571429   5.5\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra     0.595238   7.0\n",
            "claude-3.5-sonnet@anthropic               0.642857   8.5\n",
            "mistral-small@mistral-ai                  0.642857   8.5\n",
            "llama-3-8b-chat@fireworks-ai              0.738095  10.0\n",
            "claude-3-opus@anthropic                   0.785714  11.5\n",
            "gemma-2b-it@together-ai                   0.785714  11.5\n",
            "gpt-4@openai                              0.809524  13.5\n",
            "gemini-1.5-pro@vertex-ai                  0.809524  13.5\n",
            "gpt-4o@openai                             0.833333  15.0\n",
            "gemma-2-9b-it@fireworks-ai                0.857143  16.0\n",
            "gemini-1.5-flash@vertex-ai                0.880952  17.0\n",
            "gpt-4-turbo@openai                        0.904762  18.0\n",
            "mistral-7b-instruct-v0.3@together-ai      0.952381  19.0\n",
            "claude-3-haiku@anthropic                  1.000000  20.0\n",
            "\n",
            "Ranking based on Sentence Count:\n",
            "metric                                  Sentence Count  Rank\n",
            "model                                                       \n",
            "gpt-4o@openai                                 1.000000   1.0\n",
            "gemma-2-9b-it@fireworks-ai                    0.914894   2.0\n",
            "gpt-4-turbo@openai                            0.765957   3.0\n",
            "original_text                                 0.680851   4.0\n",
            "gemini-1.5-flash@vertex-ai                    0.574468   5.0\n",
            "gemini-1.5-pro@vertex-ai                      0.531915   6.0\n",
            "claude-3-haiku@anthropic                      0.446809   7.0\n",
            "mistral-7b-instruct-v0.3@together-ai          0.382979   8.0\n",
            "gpt-4@openai                                  0.361702   9.0\n",
            "llama-3-8b-chat@fireworks-ai                  0.319149  10.0\n",
            "llama-3-70b-chat@fireworks-ai                 0.276596  12.5\n",
            "mistral-large@aws-bedrock                     0.276596  12.5\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra         0.276596  12.5\n",
            "claude-3.5-sonnet@anthropic                   0.276596  12.5\n",
            "claude-3-opus@anthropic                       0.255319  15.0\n",
            "gemma-2b-it@together-ai                       0.234043  16.0\n",
            "qwen-2-72b-instruct@deepinfra                 0.212766  17.0\n",
            "mistral-small@mistral-ai                      0.191489  18.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock        0.063830  19.0\n",
            "gpt-3.5-turbo@openai                          0.000000  20.0\n",
            "\n",
            "Ranking based on Syllable Count:\n",
            "metric                                  Syllable Count  Rank\n",
            "model                                                       \n",
            "original_text                                 0.000000   1.0\n",
            "gpt-4o@openai                                 0.153846   2.0\n",
            "gemma-2-9b-it@fireworks-ai                    0.228846   3.0\n",
            "gpt-4-turbo@openai                            0.315385   4.0\n",
            "llama-3-70b-chat@fireworks-ai                 0.430769   5.0\n",
            "gemini-1.5-pro@vertex-ai                      0.561538   6.0\n",
            "qwen-2-72b-instruct@deepinfra                 0.678846   7.0\n",
            "llama-3-8b-chat@fireworks-ai                  0.688462   8.0\n",
            "mistral-7b-instruct-v0.3@together-ai          0.713462   9.0\n",
            "gemini-1.5-flash@vertex-ai                    0.732692  10.0\n",
            "gpt-4@openai                                  0.769231  11.0\n",
            "claude-3.5-sonnet@anthropic                   0.792308  12.0\n",
            "mistral-large@aws-bedrock                     0.850000  13.0\n",
            "claude-3-haiku@anthropic                      0.859615  14.0\n",
            "mixtral-8x22b-instruct-v0.1@deepinfra         0.867308  15.0\n",
            "gpt-3.5-turbo@openai                          0.896154  16.0\n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock        0.951923  17.0\n",
            "mistral-small@mistral-ai                      0.959615  18.0\n",
            "gemma-2b-it@together-ai                       0.984615  19.0\n",
            "claude-3-opus@anthropic                       1.000000  20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/Henny-Penny_readability_score.csv\")\n",
        "\n",
        "metric_groups = {\n",
        "    \"Count Metrics\": {\n",
        "        \"metrics\": [\"Lexicon Count\", \"Sentence Count\"],\n",
        "        \"direction\": \"higher\"\n",
        "    },\n",
        "    \"Ease of Reading Metrics\": {\n",
        "        \"metrics\": [\"Flesch Reading Ease\"],\n",
        "        \"direction\": \"higher\"\n",
        "    },\n",
        "    \"Grade Level Metrics\": {\n",
        "        \"metrics\": [\n",
        "            \"Flesch-Kincaid Grade Level\", \"Gunning Fog\", \"SMOG Index\",\n",
        "            \"Automated Readability Index\", \"Coleman-Liau Index\",\n",
        "            \"Linsear Write Formula\", \"Dale-Chall Readability Score\"\n",
        "        ],\n",
        "        \"direction\": \"lower\"\n",
        "    },\n",
        "    \"Time Metrics\": {\n",
        "        \"metrics\": [\"Reading Time (seconds)\"],\n",
        "        \"direction\": \"lower\"\n",
        "    },\n",
        "    \"Syllable Count Metrics\": {\n",
        "        \"metrics\": [\"Syllable Count\"],\n",
        "        \"direction\": \"lower\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "pivot_df = df.pivot(index='model', columns='metric', values='value')\n",
        "pivot_df = pivot_df.drop(columns=['Text Standard'], errors='ignore')\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "normalized_df = pd.DataFrame(scaler.fit_transform(pivot_df), columns=pivot_df.columns, index=pivot_df.index)\n",
        "\n",
        "group_composite_scores = {}\n",
        "for group_name, group_info in metric_groups.items():\n",
        "    group_metrics = group_info[\"metrics\"]\n",
        "    direction = group_info[\"direction\"]\n",
        "\n",
        "    group_metrics = [metric for metric in group_metrics if metric in normalized_df.columns]\n",
        "    group_df = normalized_df[group_metrics]\n",
        "\n",
        "    if direction == \"lower\":\n",
        "        group_df = 1 - group_df\n",
        "\n",
        "    group_composite_scores[group_name] = group_df.mean(axis=1)\n",
        "\n",
        "\n",
        "composite_scores_df = pd.DataFrame(group_composite_scores)\n",
        "# the overall composite score as the mean of group composite scores\n",
        "composite_scores_df[\"Composite Score\"] = composite_scores_df.mean(axis=1)\n",
        "\n",
        "# the difference from the original text's composite score\n",
        "original_text_score = composite_scores_df.loc['original_text', 'Composite Score']\n",
        "composite_scores_df['Difference'] = (composite_scores_df['Composite Score'] - original_text_score).abs()\n",
        "\n",
        "composite_scores_df['Rank'] = composite_scores_df['Difference'].rank()\n",
        "composite_scores_df = composite_scores_df.sort_values(by='Rank')\n",
        "composite_scores_df = pd.concat([composite_scores_df.loc[['original_text']], composite_scores_df.drop(['original_text'])])\n",
        "\n",
        "print(composite_scores_df)\n",
        "composite_scores_df.to_csv(\"grouped_composite_scores_with_difference_and_rank.csv\")\n",
        "\n",
        "fig = px.bar(\n",
        "    composite_scores_df,\n",
        "    x=composite_scores_df.index,\n",
        "    y='Difference',\n",
        "    title=\"Comparison of Models by Similarity to the Original 'Henny-Penny' Text\",\n",
        "    labels={'Difference': 'Composite Score Difference'},\n",
        "    hover_data={'Rank': True},\n",
        "    text='Rank',\n",
        "    color='Rank',\n",
        "    color_continuous_scale=px.colors.sequential.Viridis\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Model',\n",
        "    yaxis_title='Composite Score Difference',\n",
        "    xaxis_tickangle=45,\n",
        "    showlegend=False,\n",
        "    plot_bgcolor='white'\n",
        ")\n",
        "\n",
        "fig.update_layout(title_font_size=24, title_x=0.5)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P_2npiIPrepv",
        "outputId": "30eee646-6c0b-4237-ff47-98fc3eafd940"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        Count Metrics  \\\n",
            "model                                                   \n",
            "original_text                                0.840426   \n",
            "llama-3-70b-chat@fireworks-ai                0.413682   \n",
            "gpt-3.5-turbo@openai                         0.027692   \n",
            "qwen-2-72b-instruct@deepinfra                0.278691   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock       0.033453   \n",
            "gpt-4o@openai                                0.952308   \n",
            "gemma-2-9b-it@fireworks-ai                   0.868216   \n",
            "gemini-1.5-pro@vertex-ai                     0.509034   \n",
            "claude-3.5-sonnet@anthropic                  0.236759   \n",
            "mistral-large@aws-bedrock                    0.205990   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra        0.199836   \n",
            "llama-3-8b-chat@fireworks-ai                 0.359574   \n",
            "gpt-4-turbo@openai                           0.799902   \n",
            "gpt-4@openai                                 0.313159   \n",
            "mistral-7b-instruct-v0.3@together-ai         0.397643   \n",
            "mistral-small@mistral-ai                     0.131129   \n",
            "gemma-2b-it@together-ai                      0.141637   \n",
            "gemini-1.5-flash@vertex-ai                   0.454926   \n",
            "claude-3-opus@anthropic                      0.127660   \n",
            "claude-3-haiku@anthropic                     0.324943   \n",
            "\n",
            "                                        Ease of Reading Metrics  \\\n",
            "model                                                             \n",
            "original_text                                          0.017840   \n",
            "llama-3-70b-chat@fireworks-ai                          0.225169   \n",
            "gpt-3.5-turbo@openai                                   0.000000   \n",
            "qwen-2-72b-instruct@deepinfra                          0.249277   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                 0.215043   \n",
            "gpt-4o@openai                                          0.611379   \n",
            "gemma-2-9b-it@fireworks-ai                             0.596914   \n",
            "gemini-1.5-pro@vertex-ai                               0.508679   \n",
            "claude-3.5-sonnet@anthropic                            0.415622   \n",
            "mistral-large@aws-bedrock                              0.449855   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                  0.459981   \n",
            "llama-3-8b-chat@fireworks-ai                           0.765188   \n",
            "gpt-4-turbo@openai                                     0.936355   \n",
            "gpt-4@openai                                           0.877531   \n",
            "mistral-7b-instruct-v0.3@together-ai                   0.823529   \n",
            "mistral-small@mistral-ai                               0.794118   \n",
            "gemma-2b-it@together-ai                                0.863067   \n",
            "gemini-1.5-flash@vertex-ai                             1.000000   \n",
            "claude-3-opus@anthropic                                0.911765   \n",
            "claude-3-haiku@anthropic                               0.970588   \n",
            "\n",
            "                                        Grade Level Metrics  Time Metrics  \\\n",
            "model                                                                       \n",
            "original_text                                      0.507799  1.110223e-16   \n",
            "llama-3-70b-chat@fireworks-ai                      0.237282  5.362903e-01   \n",
            "gpt-3.5-turbo@openai                               0.108449  9.372120e-01   \n",
            "qwen-2-72b-instruct@deepinfra                      0.385451  7.635369e-01   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock             0.350083  9.697581e-01   \n",
            "gpt-4o@openai                                      0.676058  2.845622e-01   \n",
            "gemma-2-9b-it@fireworks-ai                         0.695953  3.015553e-01   \n",
            "gemini-1.5-pro@vertex-ai                           0.651976  6.183756e-01   \n",
            "claude-3.5-sonnet@anthropic                        0.588588  8.222926e-01   \n",
            "mistral-large@aws-bedrock                          0.608769  8.663594e-01   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra              0.688893  9.020737e-01   \n",
            "llama-3-8b-chat@fireworks-ai                       0.586274  7.543203e-01   \n",
            "gpt-4-turbo@openai                                 0.753570  4.510369e-01   \n",
            "gpt-4@openai                                       0.689294  7.946429e-01   \n",
            "mistral-7b-instruct-v0.3@together-ai               0.799945  7.644009e-01   \n",
            "mistral-small@mistral-ai                           0.674642  9.593894e-01   \n",
            "gemma-2b-it@together-ai                            0.758794  9.824309e-01   \n",
            "gemini-1.5-flash@vertex-ai                         0.817586  7.603687e-01   \n",
            "claude-3-opus@anthropic                            0.822091  1.000000e+00   \n",
            "claude-3-haiku@anthropic                           0.851531  8.551267e-01   \n",
            "\n",
            "                                        Syllable Count Metrics  \\\n",
            "model                                                            \n",
            "original_text                                         0.000000   \n",
            "llama-3-70b-chat@fireworks-ai                         0.430769   \n",
            "gpt-3.5-turbo@openai                                  0.896154   \n",
            "qwen-2-72b-instruct@deepinfra                         0.678846   \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock                0.951923   \n",
            "gpt-4o@openai                                         0.153846   \n",
            "gemma-2-9b-it@fireworks-ai                            0.228846   \n",
            "gemini-1.5-pro@vertex-ai                              0.561538   \n",
            "claude-3.5-sonnet@anthropic                           0.792308   \n",
            "mistral-large@aws-bedrock                             0.850000   \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra                 0.867308   \n",
            "llama-3-8b-chat@fireworks-ai                          0.688462   \n",
            "gpt-4-turbo@openai                                    0.315385   \n",
            "gpt-4@openai                                          0.769231   \n",
            "mistral-7b-instruct-v0.3@together-ai                  0.713462   \n",
            "mistral-small@mistral-ai                              0.959615   \n",
            "gemma-2b-it@together-ai                               0.984615   \n",
            "gemini-1.5-flash@vertex-ai                            0.732692   \n",
            "claude-3-opus@anthropic                               1.000000   \n",
            "claude-3-haiku@anthropic                              0.859615   \n",
            "\n",
            "                                        Composite Score  Difference  Rank  \n",
            "model                                                                      \n",
            "original_text                                  0.273213    0.000000   1.0  \n",
            "llama-3-70b-chat@fireworks-ai                  0.368638    0.095426   2.0  \n",
            "gpt-3.5-turbo@openai                           0.393901    0.120689   3.0  \n",
            "qwen-2-72b-instruct@deepinfra                  0.471160    0.197947   4.0  \n",
            "mixtral-8x7b-instruct-v0.1@aws-bedrock         0.504052    0.230839   5.0  \n",
            "gpt-4o@openai                                  0.535631    0.262418   6.0  \n",
            "gemma-2-9b-it@fireworks-ai                     0.538297    0.265084   7.0  \n",
            "gemini-1.5-pro@vertex-ai                       0.569921    0.296708   8.0  \n",
            "claude-3.5-sonnet@anthropic                    0.571114    0.297901   9.0  \n",
            "mistral-large@aws-bedrock                      0.596195    0.322982  10.0  \n",
            "mixtral-8x22b-instruct-v0.1@deepinfra          0.623618    0.350405  11.0  \n",
            "llama-3-8b-chat@fireworks-ai                   0.630764    0.357551  12.0  \n",
            "gpt-4-turbo@openai                             0.651250    0.378037  13.0  \n",
            "gpt-4@openai                                   0.688771    0.415559  14.0  \n",
            "mistral-7b-instruct-v0.3@together-ai           0.699796    0.426583  15.0  \n",
            "mistral-small@mistral-ai                       0.703779    0.430566  16.0  \n",
            "gemma-2b-it@together-ai                        0.746109    0.472896  17.0  \n",
            "gemini-1.5-flash@vertex-ai                     0.753115    0.479902  18.0  \n",
            "claude-3-opus@anthropic                        0.772303    0.499090  19.0  \n",
            "claude-3-haiku@anthropic                       0.772361    0.499148  20.0  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f9728b8a-4587-4d7b-b912-e0b5ae14479f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f9728b8a-4587-4d7b-b912-e0b5ae14479f\")) {                    Plotly.newPlot(                        \"f9728b8a-4587-4d7b-b912-e0b5ae14479f\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[1.0],[2.0],[3.0],[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0],[11.0],[12.0],[13.0],[14.0],[15.0],[16.0],[17.0],[18.0],[19.0],[20.0]],\"hovertemplate\":\"model=%{x}\\u003cbr\\u003eComposite Score Difference=%{y}\\u003cbr\\u003eRank=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0],\"coloraxis\":\"coloraxis\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0],\"textposition\":\"auto\",\"x\":[\"original_text\",\"llama-3-70b-chat@fireworks-ai\",\"gpt-3.5-turbo@openai\",\"qwen-2-72b-instruct@deepinfra\",\"mixtral-8x7b-instruct-v0.1@aws-bedrock\",\"gpt-4o@openai\",\"gemma-2-9b-it@fireworks-ai\",\"gemini-1.5-pro@vertex-ai\",\"claude-3.5-sonnet@anthropic\",\"mistral-large@aws-bedrock\",\"mixtral-8x22b-instruct-v0.1@deepinfra\",\"llama-3-8b-chat@fireworks-ai\",\"gpt-4-turbo@openai\",\"gpt-4@openai\",\"mistral-7b-instruct-v0.3@together-ai\",\"mistral-small@mistral-ai\",\"gemma-2b-it@together-ai\",\"gemini-1.5-flash@vertex-ai\",\"claude-3-opus@anthropic\",\"claude-3-haiku@anthropic\"],\"xaxis\":\"x\",\"y\":[0.0,0.09542561125060567,0.12068850288412242,0.19794738844564436,0.23083922875002616,0.26241765718791676,0.2650841472595553,0.29670776112196096,0.29790101385202816,0.3229819933029806,0.3504054507143961,0.35755072902053586,0.3780368564409573,0.41555860647237775,0.4265832515558139,0.43056598727717543,0.4728959333878462,0.47990173354163335,0.4990901652386157,0.4991478920513951],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Model\"},\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Composite Score Difference\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Rank\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Comparison of Models by Similarity to the Original 'Henny-Penny' Text\",\"font\":{\"size\":24},\"x\":0.5},\"barmode\":\"relative\",\"showlegend\":false,\"plot_bgcolor\":\"white\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f9728b8a-4587-4d7b-b912-e0b5ae14479f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}